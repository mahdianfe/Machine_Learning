{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\" نکته برداری از سایت های:\n",
    "https://faradars.org/courses/machine-learning-using-python-fvpht0091\n",
    "و چت جی پی تی و جیمینی\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# مدلهای خطی\n",
    "\"\"\"\n",
    "1. در بیشتر موارد، وقتی در حوزه یادگیری ماشین و آمار از \"مدل خطی\" صحبت می‌شود، منظور \"رگرسیون خطی\" است\n",
    " \n",
    "2. اگرچه رگرسیون خطی به ظاهر یک مدل پیش‌بینی است، اما در پس زمینه آن، الگوریتم‌های بهینه‌سازی برای یافتن بهترین پارامترهای مدل در حال کار هستند. بنابراین، آموزش مدل‌های خطی در پایتون بدون پرداختن به این مباحث، کامل نخواهد بود\n",
    "\n",
    "\n",
    "3. برای درک بهتر مدل‌های خطی، مباحث را به ترتیب زیر می‌توانید دنبال کنید:\n",
    "\n",
    " مفهوم رگرسیون خطی:\n",
    " \n",
    "            رابطه خطی بین متغیرها\n",
    "            متغیرهای مستقل و وابسته\n",
    "            هدف رگرسیون خطی\n",
    "            انواع رگرسیون خطی (ساده، چندگانه)\n",
    "                 \n",
    "تابع هزینه (Cost Function):\n",
    "\n",
    "            اهمیت تابع هزینه\n",
    "            انواع توابع هزینه (میانگین مربعات خطا)\n",
    "            هدف کمینه کردن تابع هزینه\n",
    "             \n",
    " \n",
    "الگوریتم‌های بهینه‌سازی:\n",
    "\n",
    "            گرادیان کاهشی (Gradient Descent)\n",
    "                انواع گرادیان کاهشی (بچ، تصادفی)\n",
    "            معادله نرمال (Normal Equations)\n",
    "            انتخاب الگوریتم مناسب\n",
    "            \n",
    "\n",
    "پیاده‌سازی مدل‌های خطی در پایتون:\n",
    "\n",
    "            استفاده از کتابخانه‌های Scikit-learn\n",
    "            آموزش مدل\n",
    "            ارزیابی مدل\n",
    "            \n",
    "مباحث تکمیلی:\n",
    "     \n",
    "            بایاس و واریانس (Bias-Variance Tradeoff)\n",
    "            بیش‌برازش و کم‌برازش\n",
    "            منحنی‌های یادگیری\n",
    "    \"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "مفهوم رگرسیون خطی\n",
    "\n",
    "    رگرسیون خطی یک روش آماری است که برای مدل‌سازی رابطه بین یک متغیر وابسته (که می‌خواهیم پیش‌بینی کنیم) و یک یا چند متغیر مستقل (که برای پیش‌بینی استفاده می‌کنیم) به کار می‌رود. هدف اصلی این روش، یافتن یک رابطه خطی است که بهترین برازش را با داده‌ها داشته باشد.\n",
    "\n",
    "رابطه خطی بین متغیرها\n",
    "\n",
    "    در رگرسیون خطی، فرض بر این است که بین متغیرهای مستقل و وابسته یک رابطه خطی وجود دارد. این رابطه به صورت یک خط مستقیم نمایش داده می‌شود. به عبارت دیگر، تغییرات در متغیر وابسته به صورت خطی با تغییرات در متغیرهای مستقل مرتبط است.\n",
    "\n",
    "متغیرهای مستقل و وابسته\n",
    "\n",
    "    متغیر وابسته (Dependent Variable): متغیری است که می‌خواهیم مقدار آن را پیش‌بینی کنیم. این متغیر معمولاً با نماد \"Y\" نشان داده می‌شود.\n",
    "    متغیرهای مستقل (Independent Variables): متغیرهایی هستند که برای پیش‌بینی متغیر وابسته استفاده می‌شوند. این متغیرها معمولاً با نماد \"X\" نشان داده می‌شوند.\n",
    "\n",
    "هدف رگرسیون خطی\n",
    "\n",
    "هدف اصلی رگرسیون خطی، یافتن بهترین خطی است که رابطه بین متغیرهای مستقل و وابسته را توصیف می‌کند. این \"بهترین خط\" به گونه‌ای انتخاب می‌شود که خطا بین مقادیر پیش‌بینی شده و مقادیر واقعی کمینه شود.\n",
    "\n",
    "انواع رگرسیون خطی\n",
    "\n",
    "    رگرسیون خطی ساده (Simple Linear Regression): در این نوع رگرسیون، تنها یک متغیر مستقل برای پیش‌بینی متغیر وابسته وجود دارد. رابطه بین این دو متغیر به صورت یک خط مستقیم نمایش داده می‌شود.\n",
    "    رگرسیون خطی چندگانه (Multiple Linear Regression): در این نوع رگرسیون، بیش از یک متغیر مستقل برای پیش‌بینی متغیر وابسته وجود دارد. رابطه بین متغیرها به صورت یک ابرصفحه (hyperplane) در فضای چندبعدی نمایش داده می‌شود."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\"\"\"\n",
    "_________________\n",
    "# بهینه‌سازی (Optimization):\n",
    "    فرآیندی برای پیدا کردن بهترین مقدار (ماکزیمم یا مینیمم) برای یک تابع تحت شرایط مشخص.\n",
    "    هدف فقط کاهش خطا نیست، بلکه یافتن پارامترهایی است که عملکرد کلی مدل را بهبود بخشد\n",
    "    \n",
    "____________________\n",
    "\n",
    "#  کمینه‌سازی (Minimization)\n",
    "    \n",
    "    کمینه‌سازی (Minimization) به فرآیند پیدا کردن کمترین مقدار یک تابع گفته می‌شود. به عبارت دیگر، هدف از کمینه‌سازی، یافتن مقادیر ورودی (متغیرها) است که باعث می‌شود تابع به کمترین مقدار ممکن برسد.\n",
    "    \n",
    "نوع خاصی از بهینه‌سازیه که به‌جای ماکزیمم، دنبال کمترین مقدار تابع می‌گردیم     بهینه‌سازی مفهوم گسترده‌تری است و می‌تواند شامل بیشینه هم شود\n",
    "     \n",
    "____________________\n",
    "\n",
    "# روش‌های کمینه‌سازی:\n",
    "\n",
    "معادله نرمال (Normal Equation):\n",
    "\n",
    "    این روش، همانطور که قبلاً توضیح داده شد، یک روش مستقیم برای محاسبه پارامترهای بهینه در رگرسیون خطی است.\n",
    "    برای مجموعه‌های داده کوچک تا متوسط، سریع و کارآمد است.\n",
    "    محاسبه معکوس ماتریس در این روش، برای مجموعه‌های داده بزرگ، بسیار پرهزینه است.\n",
    "\n",
    "گرادیان کاهشی (Gradient Descent):\n",
    "\n",
    "    این روش یک الگوریتم تکراری است که با حرکت در جهت منفی گرادیان تابع، به سمت کمینه آن حرکت می‌کند.\n",
    "    انواع گرادیان کاهشی:\n",
    "        گرادیان کاهشی دسته‌ای (Batch Gradient Descent): از کل مجموعه داده برای محاسبه گرادیان استفاده می‌کند.\n",
    "        گرادیان کاهشی تصادفی (Stochastic Gradient Descent - SGD): از یک نمونه تصادفی در هر تکرار استفاده می‌کند.\n",
    "        مینی بچ گرادیان دیسنت (Mini-batch Gradient Descent): از یک دسته کوچک از نمونه‌ها در هر تکرار استفاده می‌کند.\n",
    "        یعنی مثلا بج های صدتا صدتایی \n",
    "        \n",
    "\n",
    "الگوریتم‌های بهینه‌سازی پیشرفته:\n",
    "\n",
    "    - L-BFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno):\n",
    "        این الگوریتم یک روش شبه-نیوتن است که برای کمینه‌سازی توابع غیرخطی استفاده می‌شود.\n",
    "        L-BFGS نسبت به الگوریتم نیوتن-رافسون، حافظه کمتری مصرف می‌کند و برای مجموعه‌های داده بزرگ مناسب‌تر است.\n",
    "        این الگوریتم از تخمین‌هایی از ماتریس هسین (Hessian) استفاده می‌کند تا جهت حرکت به سمت کمینه را تعیین کند.\n",
    "        \n",
    "    - SAG (Stochastic Average Gradient):\n",
    "        این الگوریتم یک روش گرادیان تصادفی است که برای کمینه‌سازی توابع هدف محدب استفاده می‌شود.\n",
    "        SAG نسبت به SGD، همگرایی سریع‌تری دارد و برای مجموعه‌های داده بزرگ مناسب است.\n",
    "        این الگوریتم میانگین گرادیان‌های محاسبه شده در تکرارهای قبلی را ذخیره می‌کند.\n",
    "\n",
    "    نکته جالب:\n",
    "     L-BFGS یا Newton روش‌هایی هستن که نه‌تنها شیب رو حس می‌کنن، بلکه شکل منحنی رو هم بررسی می‌کنن و تخمین می‌زنن که دقیقاً پایین دره کجاست هوشمندتر حرکت می‌کنن\n",
    "\n",
    "        \n",
    "    - SAGA (Stochastic Average Gradient Algorithm):\n",
    "        این الگوریتم بهبود یافته SAG است که برای توابع هدف غیر محدب نیز قابل استفاده است.\n",
    "        SAGA نسبت به SAG، همگرایی پایدارتری دارد و برای مجموعه‌های داده بزرگ مناسب است.\n",
    "        \n",
    "\n",
    "    - Newton-Raphson:\n",
    "        این الگوریتم یک روش تکراری است که از مشتقات اول و دوم تابع برای پیدا کردن کمینه استفاده می‌کند.\n",
    "        Newton-Raphson نسبت به گرادیان کاهشی، همگرایی سریع‌تری دارد، اما محاسبه مشتقات دوم می‌تواند پرهزینه باشد.\n",
    "        \n",
    "\n",
    "    - Conjugate Gradient:\n",
    "        این الگوریتم یک روش تکراری است که برای کمینه‌سازی توابع درجه دوم استفاده می‌شود.\n",
    "        Conjugate Gradient نسبت به گرادیان کاهشی، همگرایی سریع‌تری دارد و برای مجموعه‌های داده بزرگ مناسب است. \n",
    "           \n",
    "________________________________________\n",
    "\n",
    "\n",
    "\n",
    "# وقتی می‌گوییم \"پر هزینه\" در محاسبات:\n",
    "\n",
    "، منظورمان این است که انجام آن محاسبات به منابع محاسباتی زیادی (مانند زمان پردازش، حافظه و توان محاسباتی) نیاز دارد. در مورد معادله نرمال، \"پر هزینه\" بودن به چند عامل بستگی دارد:\n",
    "\n",
    "1. معکوس ماتریس:\n",
    "\n",
    "    معادله نرمال شامل محاسبه معکوس ماتریس (X^T * X)^-1 است.\n",
    "    محاسبه معکوس یک ماتریس، به ویژه برای ماتریس‌های بزرگ، از نظر محاسباتی بسیار پرهزینه است.\n",
    "    هرچه اندازه ماتریس (تعداد ویژگی‌ها) بزرگتر باشد، زمان و منابع مورد نیاز برای محاسبه معکوس آن به طور قابل توجهی افزایش می‌یابد.\n",
    "\n",
    "2. اندازه مجموعه داده:\n",
    "\n",
    "    وقتی مجموعه داده بسیار بزرگ باشد، ماتریس X (ماتریس ویژگی‌ها) نیز بزرگ می‌شود.\n",
    "    این امر باعث می‌شود محاسبه (X^T * X) و معکوس آن بسیار زمان‌بر و پرهزینه شود.\n",
    "    به عبارت دیگر، با افزایش تعداد نمونه‌ها (ردیف‌های داده) و تعداد ویژگی‌ها (ستون‌های داده)، هزینه محاسباتی معادله نرمال به طور تصاعدی افزایش می‌یابد.\n",
    "\n",
    "3. محدودیت‌های حافظه:\n",
    "\n",
    "    برای مجموعه‌های داده بسیار بزرگ، ذخیره ماتریس X و محاسبه معکوس آن ممکن است به حافظه بسیار زیادی نیاز داشته باشد.\n",
    "    این امر می‌تواند باعث ایجاد مشکلات حافظه و کاهش عملکرد سیستم شود.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\"\"\"\n",
    "# گرادیان چیست:\n",
    "    \n",
    "     گرادیان به ما می‌گوید که با حرکت در کدام جهت، مقدار تابع با بیشترین سرعت افزایش می‌یابد.\n",
    "     \n",
    "    ___________________________\n",
    "    تعریف ریاضی گرادیان:\n",
    "\n",
    "    گرادیان یک تابع چند متغیره، برداری است که از مشتقات جزئی آن تابع نسبت به هر یک از متغیرها تشکیل شده است.\n",
    "    این بردار، جهت بیشترین افزایش تابع و نرخ تغییر آن در آن جهت را نشان می‌دهد.\n",
    "      گرادیان به ما می‌گوید که یک تابع در جهات مختلف چگونه تغییر می‌کند\n",
    "      \n",
    "    فرض کنید یک تابع چند متغیره مانند f(x, y) داریم.\n",
    "    مشتق جزئی این تابع نسبت به x، نرخ تغییر تابع را نسبت به x نشان می‌دهد، در حالی که y ثابت است.\n",
    "    به طور مشابه، مشتق جزئی نسبت به y، نرخ تغییر تابع را نسبت به y نشان می‌دهد، در حالی که x ثابت است.\n",
    "    گرادیان، برداری است که از این مشتقات جزئی تشکیل شده است. به عنوان مثال، گرادیان f(x, y) به صورت (∂f/∂x, ∂f/∂y) نشان داده می‌شود.\n",
    "    \n",
    "جهت و نرخ تغییر:\n",
    "\n",
    "    بردار گرادیان، جهتی را نشان می‌دهد که در آن، مقدار تابع با بیشترین سرعت افزایش می‌یابد.\n",
    "    اندازه بردار گرادیان، نرخ تغییر تابع در آن جهت را نشان می‌دهد.\n",
    "    به عبارت دیگر، هرچه اندازه گرادیان بزرگتر باشد، نرخ تغییر تابع در آن جهت بیشتر است.\n",
    "\n",
    "    ___________________________\n",
    "        \n",
    "     # کاربردهای گرادیان:\n",
    "    \n",
    "        بهینه‌سازی:\n",
    "            در الگوریتم‌های بهینه‌سازی مانند گرادیان کاهشی (Gradient Descent)، از گرادیان برای پیدا کردن کمینه یک تابع استفاده می‌شود.\n",
    "            با حرکت در جهت منفی گرادیان، به سمت کمینه تابع حرکت می‌کنیم.\n",
    "            \n",
    "        یادگیری ماشین:\n",
    "            در یادگیری ماشین، از گرادیان برای به‌روزرسانی پارامترهای مدل و کاهش تابع هزینه (Loss Function) استفاده می‌شود.\n",
    "            این امر باعث بهبود عملکرد مدل می‌شود.\n",
    "            \n",
    "        پردازش تصویر:\n",
    "            در پردازش تصویر، از گرادیان برای تشخیص لبه‌ها و تغییرات شدت روشنایی در تصاویر استفاده می‌شود.\n",
    "__________________________________________\n",
    "\n",
    "#  گرادیانتدیسنت:\n",
    "گرادیان دیسنت یک الگوریتم بهینه‌سازی است که برای پیدا کردن کمینه یک تابع استفاده می‌شود.\n",
    "\n",
    "خود به تنهایی به معنای کمینه‌سازی نیست، بلکه به فرآیند حرکت به سمت کمینه یک تابع اشاره دارد.\n",
    "دیسنت به معنای \"فرود\" یا \"کاهش\" است\n",
    "دیسنت، فرآیند حرکت به سمت کمینه یک تابع است.\n",
    "\n",
    "گرادیانت دیسنت قلب تپنده‌ی بسیاری از الگوریتم‌های یادگیری ماشینه، اما تفاوت‌هایی که بین ابزارهای مختلف مثل Scikit-learn و TensorFlow وجود داره گاهی آدم رو گیج می‌کنه.\n",
    "\n",
    "مفهوم تابع هزینه:\n",
    "loss function\n",
    "\n",
    "    تابع هزینه، که به آن تابع زیان یا تابع خطا نیز گفته می‌شود، معیاری است که نشان می‌دهد مدل شما چقدر خوب عمل می‌کند. به عبارت دیگر، این تابع تفاوت بین مقادیر پیش‌بینی شده توسط مدل و مقادیر واقعی را اندازه‌گیری می‌کند. هدف این است که پارامترهای مدل را طوری تنظیم کنیم که این تفاوت (یا هزینه) به حداقل برسد.\n",
    "شینه‌سازی (Maximization) نیز باشد \n",
    "\n",
    "#_________________\n",
    "\n",
    "\n",
    "مفهوم گرادیانت دیسنت (Gradient Descent) چیست؟\n",
    "\n",
    "    گرادیانت دیسنت یه روش عددی برای کمینه کردن تابع هزینه (loss function) هست.\n",
    "    مثلاً تو می‌خوای یه مدل خطی بسازی که به بهترین شکل ممکن داده‌ها رو پیش‌بینی کنه؛ یعنی می‌خوای پارامترهای مدل (مثل شیب خط یا وزن‌ها) رو طوری تنظیم کنی که خطات کم بشه\n",
    "    \n",
    "تشبیه شهودی گرادیانت دیسنت:\n",
    "    \n",
    "    فرض کن وسط یه دره تاریک وایسادی و دنبال پایین‌ترین نقطه‌ی دره‌ای. ولی نمی‌تونی دور و برت رو ببینی. فقط یه کار بلدی: پا رو یه ذره بذاری در جهت سراشیبی.\n",
    "    \n",
    "    هر بار پا رو می‌ذاری اونجایی که زمین شیب داره. اگه دائم این کارو بکنی، کم‌کم میری به پایین‌ترین نقطه‌ی دره. اون پایین‌ترین نقطه یعنی: کمترین مقدار تابع هزینه.\n",
    "    \n",
    "    گرادیانت دیسنت دقیقاً همینو تو دنیای ریاضی انجام می‌ده:\n",
    "        تابع شیب‌دار = تابع خطا (Loss)\n",
    "    \n",
    "        جهت شیب = گرادیانت (مشتق تابع)\n",
    "    \n",
    "        هر قدم به سمت پایین = آپدیت پارامترهای مدل\n",
    "\n",
    "\n",
    "فرمول کلی گرادیان دیسنت در ریاضی:\n",
    "θ := θ - α * ∇J(θ)\n",
    "\n",
    "    توضیح اجزای فرمول:\n",
    "        θ: پارامترهایی که می‌خواهیم یاد بگیریم (مانند وزن‌ها). و درواقع مقادیری هستند که رفتار و عملکرد مدل را تعیین می‌کنند.\n",
    "        \n",
    "        تنظیم برای دقت: هدف از یادگیری، یافتن مقادیری برای تتا است که مدل را تا حد امکان دقیق و کارآمد کند.\n",
    "        یادگیری خودکار: الگوریتم گرادیان دیسنت به طور خودکار این پارامترها را از داده‌ها یاد می‌گیرد.\n",
    "        به زبان ساده، تتا مثل پیچ‌های تنظیم یک دستگاه است که با تنظیم آن‌ها، عملکرد دستگاه را بهینه می‌کنیم.\n",
    "\n",
    "\n",
    "        α: نرخ یادگیری (learning rate)، که اندازه قدم‌هایی که در جهت گرادیان برمی‌داریم را \n",
    "        تعیین می‌کند. که یک پارامتر مهم است که باید با دقت انتخاب شود. یک نرخ یادگیری خیلی بزرگ می‌تواند باعث شود که الگوریتم همگرا نشود، و یک نرخ یادگیری خیلی کوچک می‌تواند باعث شود که الگوریتم خیلی کند همگرا شود.\n",
    "        \n",
    "        ∇J(θ): گرادیان یا شیب تابع هزینه (loss function) نسبت به پارامترها. \n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\"\"\"\n",
    "# انواع گرادیانت دیسنت:\n",
    "#________________\n",
    "\n",
    "✅ a) Batch Gradient Descent\n",
    " گرادیانت کاهشی دسته ای یا گرادیانت دیسنت معمولی\n",
    "\n",
    "    کل دیتاست رو استفاده می‌کنه برای هر قدم\n",
    "    دقیق، ولی کند و حافظه‌بر برای دیتاست‌های بزرگ\n",
    "\n",
    "📦 مثال: مثل اینه که قبل از برداشتن هر قدم در دره، کل نقشه رو ببینی و با دقت حساب کنی کجا بری.\n",
    "\n",
    "    اما سایکیت لرن از بچ استفاده نمیکنه چون:\n",
    "     اگه نقشه کامل دره رو داری، لازم نیست با قدم قدم رفتن پایین بری. یه خط‌کش برمی‌داشتی، دقیق حساب میکنی که پایین‌ترین نقطه کجاست. تا زمان کمتری صرف بشه\n",
    "     بنابراین به جای بچ گرادیانت دیسنت از  معادله نرمال (Normal Equation) استفاده می‌کنه:\n",
    "     مثل اینه که به‌جای اینکه بری پله پله به پایین دره، یه فرمول داری که مستقیم می‌گه پایین‌ترین نقطه‌ی دره کجاست! اما باز هم برای داده های کوچک و متوسط قابل استفاده است\n",
    "     \n",
    "________________________\n",
    "\n",
    "✅ b) Stochastic Gradient Descent (SGD)\n",
    "گرادیان کاهشی تصادفی \n",
    "\n",
    "    هر بار فقط یک داده از دیتاست رو استفاده می‌کنه\n",
    "\n",
    "    خیلی سریع، ولی نویزی\n",
    "    \n",
    "    📦 مثل اینه که چشم بسته فقط با یه حسگر کوچیک قدم برمی‌داری، سریع میری جلو، ولی شاید مسیرت خیلی صاف نباشه.\n",
    "________________________\n",
    "\n",
    "✅ c) Mini-batch Gradient Descent\n",
    "\n",
    "    بین این دو تاست: هر بار یه \"بَچ\" کوچک از داده‌ها رو استفاده می‌کنه (مثلاً 32 تا، 64 تا ...)\n",
    "\n",
    "    تعادل خوبی بین دقت و سرعت داره\n",
    "    سرعت بالا (تقریبا مانند SGD)\n",
    "    البته کمی کندتر هست اما اگر مینی بچ سایز مناسبی را انتخاب کنید میتونه تقریبا برابر استوکستیک باشه چون از محاسبات برداری استفاده میکنه\n",
    "      \n",
    "    همگرایی پایدارتر (نسبت به SGD)\n",
    "    نوساناتش کمتر از استوکستیک است\n",
    "    \n",
    "    📦 مثل اینه که یه گروه راهنما همراهت هستن که منطقه کوچکی رو می‌گردن و بهت می‌گن کجا بری.\n",
    "\n",
    "    یعنی مثلا بج های صدتا صدتایی\n",
    " \n",
    "    در دیپ لرنینگ این روش رو زیاد میبینیم\n",
    "    در داخل کتابخانه سایکت لرن نداریمش\n",
    "    برای الگوریتم های مبتنی بر شبکه عصبی که در سایکیت لرن موجود نیستند، از کتابخانه های دیگری مانند tensorflow و pytorch استفاده میشود.\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Batch Gradient Descent\n",
    "\"\"\"\n",
    "####وقتی تعداد داده ها خیلی زیاد باشه از گرادیانت دیسنت استفاده میکنیم\n",
    "که خانواده ای از الگوریتم بهینه سازی هستش که کارشون ایجاد راه حل های اپتیمال است\n",
    "\n",
    "مشکل در اینجا اهسته بودنش است بنابراین به سراغ استوکستیک گرادیانت دیسنت میرویم\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#  سایکیت لرن به‌جای Batch Gradient Descent چی کار می‌کنه؟\n",
    "\"\"\"\n",
    " گزینه‌های Scikit-learn برای یادگیری مدل‌های خطی:\n",
    "1. Normal Equation (برای LinearRegression)\n",
    "    فقط برای داده‌های کوچک و مدل‌های خطی ساده\n",
    "    دقیق و تحلیلی\n",
    "\n",
    "2. حل‌های عددی مثل sag یا lbfgs:\n",
    "\n",
    "(برای LogisticRegression, SGDClassifier, Ridge, Lasso)\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\"\"\"\n",
    "آیا این مفاهیم Gradient Descent و... در Classification مطرح نمی‌شن؟»\n",
    "✅ جواب: اتفاقاً دقیقاً همین‌جاها خیلی زیاد مطرح می‌شن!\n",
    "\n",
    "🔹 الگوریتم‌هایی مثل:\n",
    "\n",
    "    Logistic Regression\n",
    "\n",
    "    Neural Networks\n",
    "\n",
    "    Support Vector Machines (در حالت‌های خاص)\n",
    "\n",
    "    و حتی بعضی مدل‌های غیرخطی دیگه\n",
    "\n",
    "همه‌اشون برای یادگیری، باید یه تابع هزینه (loss function) رو کمینه کنن.\n",
    "برای کمینه کردن، باید گرادیانت بگیری → یعنی Gradient Descent دقیقاً وسط ماجراست.\n",
    "\n",
    "📌 پس حتی اگه مدلت Classification باشه، الگوریتم بهینه‌سازی (Gradient Descent یا مشتقاتش) همچنان استفاده می‌شه.\n",
    "\n",
    "#----------\n",
    "\n",
    "    توی Classification مهم‌ترین بحث، انتخاب تابع هزینه (Loss Function) درسته: مثلاً\n",
    "    \n",
    "        Binary Cross-Entropy (برای دودویی)\n",
    "        Categorical Cross-Entropy (برای چندکلاسه)\n",
    "\n",
    "    ولی کمینه کردن همون تابع هزینه با Gradient Descent انجام می‌شه.\n",
    "\n",
    " تشبیه: تو Classification داری یه نقشه مسیریابی انتخاب می‌کنی (loss function)، اما ماشینت که حرکت می‌کنه با موتور Gradient Descent حرکت می‌کنه.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kl9or6Rt9tc-",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:09.340569Z",
     "start_time": "2025-04-12T19:24:07.477717Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "m = 2000\n",
    "X = np.random.rand(m, 1)\n",
    "y = 5 + 2*X + np.random.randn(m, 1)"
   ],
   "metadata": {
    "id": "923YQ3kk5K22",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:09.618352Z",
     "start_time": "2025-04-12T19:24:09.342109Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(X, y, \"r.\")\n",
    "# عبارت \"r.\"یعنی نقاط قرمز"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "QbAnF_ZQKyPm",
    "outputId": "cb34c4bc-25d4-4adb-a831-874d0e56094e",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:09.898949Z",
     "start_time": "2025-04-12T19:24:09.619374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x268058caed0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfnFJREFUeJztfQvUbVVV/773IqAJJBoJXLgqIppkDqEUfCXDZISZ/ktlJC+TAvIxxARRUW9DRQhQYpQYeAlqYCo4RPORRAEyfAVqGj4iUNHvJj4aGZAJwr37P+b5WrLuYs655lx77X32Puf3G+OM7/vOd87ea6/HnL81X2tN27ZtAwAAAAAAUAFra1wEAAAAAACAAGIBAAAAAEA1gFgAAAAAAFANIBYAAAAAAFQDiAUAAAAAANUAYgEAAAAAQDWAWAAAAAAAUA0gFgAAAAAAVMN2zcDYunVr893vfrfZaaedmjVr1gx9ewAAAAAACkD1NO+4445mjz32aNauXTseYkGkYq+99hr6tgAAAAAAVMDKykqzfv368RALslSEhu28885D3x4AAAAAgALcfvvtM8NA0OOjIRbB/UGkAsQCAAAAAKaFXBgDgjcBAAAAAKgGEAsAAAAAAKoBxAIAAAAAgGoAsQAAAAAAoBpALAAAAAAAqAYQCwAAAAAAqgHEAgAAAACAagCxAAAAAACgGkAsAAAAAACoBhALAAAAAACqAcQCAABgHti8uWmuvnr1JwAsEEAsAAAAhsaFFzbNhg1Nc8ghqz/pbwBYEIBYAAAADAmyUBx3XNNs3br6N/08/nhYLoCFAYgFAADAkLjppntJRcCWLU1z883NUgOuoYUBiAUAAMCQ2HffplmbiN5165rmkY9slhY1XUMgKHMHiAUAAPUB4S5j/fqmueCCVTJBoJ/nn7/6/jKipmto7LErm5djXYBYAABQF2MX7mPAscc2zS23rCoZ+kl/LytquYbGHrtyYcG6mCgRAbEAAKAexi7cxwSyUPz6ry+vpaK2a6iUoAyhvDcXrIsJE3QQCwAA6gGBicC8XEMlBGUo5X2Tc11MnKCDWAAAUA8ITATm5RryEpQhlfe+znUxcYLuJhZ33HFHc+KJJzYbNmxo7n//+zcHH3xwc/311/fTOgAApgUEJgLzdA15CMqQynu9c11MnKCvadu29Xzh8MMPb77yla8073rXu5o99tijueSSS5pzzjmn+drXvtbsueee2e/ffvvtzS677NLcdtttzc4779yl7QAAjBW06yMBTYIQpAIY6xwl90dMLkh5EyHpa85udqwLcsuQBYXITiAicw7ytepvF7H4yU9+0uy0007Nhz/84ebZz372z94/4IADmt/8zd9s3vrWt1ZrGAAAAAD0ihEq7zETdKv+3s5z0XvuuafZsmVLs+OOO27zPrlEPvWpT7Hfueuuu2avuGEAAAAAUE35kluD3Ade5Usk4tBDR6W8twG1Z2xtqh1jQdaKgw46qHnLW97SfPe7352RDHKFfPazn21uvfVW9junn376jOGE11577VWr7QAAAMAyo0ZWx9TTfjePr9aFO8biG9/4RvOSl7ykufbaa5t169Y1T3jCE5pHPepRzRe+8IXm61//usliQeQCrhAAAABgUjESY7POXHjhvZktFOxJAaI9unKsrhB3Vsg+++zTfPKTn2z+53/+p1lZWWmuu+665u67724e8YhHsJ/fYYcdZg2IXwAAAADQCRNPyexsnTn77NHWuiiuY/FzP/dzze6779786Ec/aq644ormuc99bt2WAQAALBo4s/UITdmTwMRTMl3gam6ccspoiZUreJNAJIK8J/vtt19z8803NyeffHLz6Ec/uvn93//9floIAACwCODM1oQBTdkLhVAbIs3qWEQ3yE2MdYb+XrOmaeJohpEQK3eMxaWXXtq87nWvazZv3tzsuuuuze/+7u82p5122szvYgHSTQEAWDpI8QD0d6oYFjlGYAlSMgedP6ef3jSve929xIr+PvDAsgyZedWxGLJhAAAA1dML5wVydZBv3PpZylIAAEvNjUCsPv/5e90jPVm/QCwAAFg8DBwFXw2wWAB9WmcGypDpLSsEAABgLpjyiY/SWRHvfjfOVQG619wYWYaMO3gTWDJM0ewMLCY04ZnOzTHOW6nKY/xecIWMqd3AdDJktm4dRSAnLBZAv1XtAGDo9MIxz1tuxxneu+KK8bYb8GHzwCnENIeOOmrb9448cm7kFDEWAI9lrGoHlGFI60Du0Kipztupthu4L84+2x5EWWvtIMYCmARG5rMDRoqhrQMkoElY0m6QfqYCe6rzdqrtBrbFWWc1zckn2+KAaq6dkc0fWCwAHthBAVOcI2Ns0yK3G9h2DPfee9ssHymFuPZ4w2IBTAJSFDuEHDDSXdKk5+1U271I6BoXQeuBIxVr1943DkhaO5/97ELMH1gsAB3LUNUOWLxd9lTnraXdY8x4mTpq1Efh1kNwj5x0UmP6bNfaLD3PexTIAvKAgAL6DqYE6mKqBcKWhSDH62Ht2qY544zVmAvps3Fdlq73HgAgFoAOCChg2a0DUyPuY7YQTRlSufXS0uqbHevh0kub5vDD6927ZyDGAljMCobAdKoBLjP6yJYZY0yLBWM/Fr728evrHevh4IMX8uh3EItlxFQFFABMQXH2RdxrK8AhMOZiZWMIfFw/rqDLWoArZBkBkyowJBY5lodzKT7iEXVN67VjWoYaj6nJmXm69DZPw50IVwiwdCwZGCGmsGMthWSZeOAD+7Ms5AqEjWk8pmYZnadLb/3/3ZswZreREbBYLDMmwpKBiWJqO9aaQX/f+Mb4smWGHo9FH/++rV9/+qf3TVOdM2CxAPJA0B3QJ6a2Y60Z89DVstBHgOTQ41HbMjp0EOiQ99vMWL8oTZVqYEwQIBYAAPSDKQYb1lScQxF3q3tjHuNRi2D16cLhCMTQLrybGNJHeO1rJ+kWgSsEAID+sAwFtEpdijWCKL3uhimMR9ovfbpUuODbQw8d3oWzWajEObKaFnCFAAAwf9TYsY69DkKJZaLGjpj6gwosedwbQ7tovOD6pS8XjhR8+5nPDO/CW79+NaYixUQtfCAWAAD0iy4ugUXMKqlR5yL0y6tf7VdGY42tGjrLRiIsa9bMx4V30klNc+aZ9957wtl6IBYAAIwTi1ohtusOPO2XGBNWRmK//PjH/aTHSzEnBx3E34/Qt+Xs5JOb5tvfHq9FyQgQCwAAxolFzSrpGkQpBfqdc86kldHgWTZa8G16P8JQlrP1I7UoOYDgTQAAxolFroPQJYgS/TJs8O0i97cTCN4EAGDa0HaUYw/ozKHLDnyRK+fOI7g0ZyEY0nK2eeLz+v8AiwUAAOM+7yPdUU6gQuEgQOXc7vOZAkP/53/0eT2UxeLCC5vmD/+waUglUwDpu9+tE6s5rEmz/m4Hxm233UZEZvYTAIAJYNOmtl27lsTd6k/6e15YWbm3LfHrzDPn1ybgvmN01VWrP8c+n8MrN6/pf+vWrX6WfnrWwErSH1z/0O9r1mzbJvpb6sM5rUmr/gaxGDvGvkiBxQanyEmwzms+0lpISUUQrlgj88eYSKiHmFrmNf3v6qt982xT0h/HHMP3z/vfz7fp0ktHtSat+hsxFmPGIubwA+NG6uMdS2ZGaBdX04BAbZx6tsgY4fH5TyE9WMqoscxrb7bGZqY//vqvu/fPWNakAhCLsWIKixRYfCI7hvM+4nY96UlN85u/yX/u859vJoGpBOh5NzYTUHjsfO5rXt+kkJi0fw4+eDWuIga1k2pqpJDW5M/93GjmFYjFWDGFRQosPpElzDMDgWvXxz7WNM94xjQPbMop67GQjpKNzRhIqDejJqCPeb3vvvclCylC/9B9jz562//9xm/Ys4KOPHKVdI/Fut0ODMRYTNS3DSw2pNgF8ilL/uUh4n+kdqWBbml7xxinlFvTY4pPyM2HPoIcu8IzzmE+X3edP27Cet8VJiAz9EsY4xB0LMV+0PelPoyfYSBd0Uvw5j333NO+4Q1vaB/2sIe1O+64Y/uIRzyiffOb39xu3bq1esOAOS9SYLngJbJDKUEt2M7S3qkoa0//D0GUumxsSoIcu2Je46zd9yphvE844b7fkT5r6XfpuyedNA1icdppp7UPfvCD249+9KPtt771rfayyy5rH/jAB7bnnntu9YYBc1ykwDjRt0KxEtmhrWlnncULW3pfa+/YrH60O5WUhtVCMKQC7XtjU2s+z2ucc/ddYf5Pf3Pf4awOHPmULCPcd3vIlOqFWDz72c9uX/KSl2zz3u/8zu+0RxxxRPWGARPBWMzMi44hLQQ5IltqJu+qlMPzx0pOa2/Xdtac25LwJ3JEIMWSms1T5TgPBdrXxqbmfJ7HfLTcd2Vl1WoQP+fxx8vfiYlcOsbx/Of6i+4zQB/0ZrHYsGFDe+ONN87+/tKXvtTutttu7SWXXFK9YcAEMCYz8yITp7HtvOe5Q/QouS7trD23NSXEFWziLATzUqBjnz9jtFhsisaUCGMgjfSeRiBTMhIsc7nn4+I5euiDXojFli1b2lNOOaVds2ZNu912281+vu1tb1O/c+edd84aEV4rKysgFouAsSm7PojAWIiTR6EMRYSmEv9T0s4+5rZ0Tc4ETn/T+0O0y9r2mnPKMp+995zXfEzvSyTg/e/X3RqxO0Rqa0yiPW6ynvugF2Lx3ve+t12/fv3s57/+67+2f/M3f9Puuuuu7cUXXyx+Z+PGjbOGpC8Qi5Htir0Y4+6pJhGQ/KPzGCOrQvE8f405N4/4n5J2W9sZri1VQew6tznB771XzdLS8yLXufLVpfecVzxauG/srmgyL6qoaW2rN7C3xz7ohVgQqfiLv/iLbd57y1ve0u63337id2CxmMiueOoWC297ckJ2wEhrE3IKxfP81jk3NsLLtdvaxtzn0mv3ZVaOBT/nArHcq0R5lMiZvtY4RywCaS+9Z+lc7TOAtBFeJX04EgthL8SCrBPnnXfeNu+RK2Tfffet3rClwNiUsxcjmexuC4pFyHLCb97jUyNQsQ/rxxDg2k3jY2lj7lly0ft9ZURIkfxD3Cv163PKtbZV0mIRKrmndT2nzzhEAGnDyI/S+8zLItM3sTjmmGPaPffc82fpph/84AfbhzzkIe1rXvOa6g1bCozRnTDBye5SmB4yN1CkdRVYn8vq3x4b4bUI7tLxlq7tMVfXeh7u0Km+7pUGjqbKteY8kIIZ0+uWWB5zn5csXTUtI1aLxaU9jO/UicXtt9/evvKVr2z33nvvnxXIOvXUU9u77rqresOWAmMU4FOGxYLiDYSc0vhYd26linaehMoquNM2jpVIDXlPT+BoLkOhZLctWZvitUrxCUFhS+uYU+qWlE/uGa2xLfE94+wMbn2l7V7Tf5bG0MCx6VPBmNwJi4CcBcUr0Kc0PlbTbs14jSERt9saB+Fx/Qw9zto9a8e3cPfyWDKIYJS2JWcRSgugBYtCvI6luZ0bX+3eHkuH1S2axtCsm4jsMALEYkoYizthWeBd8F3HZ4ggyBITsvZMYxWKJYLbU1F06HHm7tlXfEt6r1JLRi2LBcXr0b04xR/fKze3cwRNqzXh+Z7FwpE+9/vfv0piFkS2g1gAgIYuSsSjQIYKguzDfeHpI65P4vf6IlfWNvZN3mlcw65WOzgqh6GtRV5LRo37WF7vepffnSWNb45AcN+zxPRo6eebFAvLmDKtnACxAIA+4K0VMW8/+hACjOsTrfLgWKwftZCry8B9XlIufWVikGVAuqfVktHVkvORj8in0qavjRu3/X7X9niJpcViEcqxW767zlCWewIAsQCA2vAKuKGDIOfhvsilanKvMcRr1IQUCMhlAJSkvtbIxIjHxjIvuIqSMTGx7rxzcQrSK608GgdOcu0ZIqYnbWM48ty67tdMP5gTxAIAasNLFOaVbTBkvI41f9/TZ1MzFVuJhSeQNP5ciWtF23Fb52CYS+lO+5hj7AXWrEWj4hddX+oP6ovDDhvOAhb6QDp9lLNarAhke6hNRo9rCMQCWB4MpYxKiMJYgyBrQQrMK7FYeONRxkJCOFcI53/3FDHrurvNET7PCa85ciBlR7z97TYiQc9KbhJyf1BAZy5ws5QodYHUn+k4hzl51ln3tfgMscnoOaYLxKILxiKwgDyGrhBZQhTGlPXTx9zmAvPSqphBUUp95iVtY6oMaq33YH3GGi60GhYLrS1a26RS5eHeZHFILRTSeFrv/4539G8JlFw5ocx/+gxnnnnflNk+NxkDWEhBLEoxJoEF9LOQuirXMRGFscxtMhVzu/aQahf3Gdf/8y5cVjonUjP9CSd0t2DVej6O8HkVmtdikCM03M7dW4lTevUtr4koaBYXy5itrKyuCXKf1ZYfA8R0LS+x6KI05hlZD/jR17kCiwjr3C5dP56jnUsKHZXcy4rSOSEpPSmoz0NMa+1u4xiBUjKctoUsDFLbpLE555x755aFJMTj6UlV7VteH3+8vf2NY/7XACwWPRGLroM2xlLGAXDPdF9Iy0wcLXO7y/qxKNlc/3sKWdUaR+laWnqm1+9eijFZxlKLk1T4KTc2VgtEOp7h/pzFwyuvu24+PdktZ5557/1qFx7j0LO7ZfmIRQ1hM1bFs6i77BpkybOQxkgcS/vA+z3LuRBd535amjm9RtdCR30I0FxqYGnWwxg2I/OSRbmxyVkgcgWlpAwNC6mrIUu1GBJuHq2N7jfEXOmRkC4fsailNMYWxT9WsuMBJxxqkiXrQhpLX8aR49Y+iPvQ23ecILSasD3rp/RAqHnGunhjCLxkapHgGb/c2IRYAy4tM9Sw0Oa5RE5IkUvxCzXnnxRTZCEbTcH9Uxk6Jwv28hGL2ubRsZggx7jL9oATDvNU8PMmjrmIea4P0j60Hr4lmV9j4T20xW/e/V9SCCm33uI6D2N5phwkxaQpMOuJoB5I88Eyl6T2SIRbkqUhq6Nr2+N50Cgvaa5IY5LKjKc97b4WtYGIxvIRi7EKra4Yyy67Ztv7EFBTII6W3TFX08AirKRYCckfzPV1qmBzQYgcLGbwGmdqcASqRqZPqR98TJuRHCRLQPp+XAiLy9yoJYu4vtNOJbWuDS5Og/t8l5iYNPbk0EP1dRrid6wHz1nWf7zZ6NlVvpzEYmoLfNEJU5cjixcRuYh4T02D9BUsEDVM+11dVNIarE2Su5SsXsT1ZoE0BlrcgqbQ+uobaR6TAiXCG7sFtXiNlECTdcJKtC1tjNvBEa+1UXn7kvTiksq2PcrS5SUWi4qpEaZgOpXM9ossvCVoSt8jdDTBqGUq5PpaUzo1zKw13Xq5vuxjF90XapmxLdeRxoAKTHkVGHcWSk1YgzxDvAYX88C5/Gqc2ZFzTzbJSa3UvzH5j8dJWxdcey2vnqy/IBZDYk6BNKNFaoqXqi5OjSzVAOeX9dY00ASoRg5y9+mSIWFBTYtFrZLV80atIGarpamWxaJk3ErkpBZHkbaDIyJcX3Td1FjJfsNkhXDnrOTWhVSYSyNcfRTgArEYEIuaCloKaZFwOe/LSt5KCFX8nZwALRWcpFz6UCgxuLaVjG3fFoshUItocYpHu440P9L3n/98WXF5TxfNyUktmNQTl2SNkemyqbG6J9ZmLBlx23Jrlvo7vpZ03Xgj14M+ArEYAlMOrJxSFktt8rYIJIVLd0vrUngFZ8m5ECVISVLp2HIEa0putVpnguTOsPDGwYT3JWvBM59pV17hOpqczM0BzSWSytshsug4uZ8q9JNOyltb0rbl1mxw+YSS4BKx6FEfgVgMgamngk6BbPUZ8DdlC1Mfc69r4GeN+5WkuHYtWT0v1Hh+jQx2yXYgWBWjJU1amqvWPgjjnJ4aGlu8aA7kSEytzUWaQRWTirPO6r6e0vZxf3OByz3rIxCLIQCLBY+agZl9B/xNdbz6ehbPuRBTJOZ9Wau81w2fJzdGn/5+r/UjVV7WwEFvmnQu60Frt2Tx4uIapJTnLpuLmMhwQaPronWonS0ijXfaPkphldKDc3U0YLFYUCW6CGb3EtQKzBwi4G+qFqa+MmvSsesryHZooteXtSoNViYzeC4YN24H7XDT/rXKDSnNUcqK6FLbwrPr1iwp9PkQo+GJiUj7QyMv9H7JWSbefpLSV9/xDvlcExovyhSRLBWe/g7ukRCs2XO2HYjFkJAE76KY3eeNWotlCEU2NJHsS+kPhaHSjvsae0kRSOvd0g6r3LAoIYvcybUpKK+uzxmUfbyzDpkSuaJqXH/kYoLoXulatG4urEQmrlPhea0V+s0a50TERYpR6lEmgFjMG4tkdh+DMq21WPpUZGMgklO0kA1BjvqyVuV25mkNkFrnqdDfb3+7TQnl5I7nyPt47eQsM6eeet9Uc869EqdDp/2l9YdGrNI0T62SpZXYaSXBtXobjUIuLKX1pRdXDbVnHQNiMW8smtl9zMrUA2tJaU1BW3czQxNJr0l+mYjM0BaLWPinu0mtHd7j7Tll5ZU7nr6xkkCyQsTXo9TVXOVLTpbk+kNKvZbIS4hrkWSWl8jE/yspMraWOesj7bsRFS4DsZg3xqBo+sbUntHaXo0seXczQ55/Ipmq+yIY8yAyY7RWWeIQ4rmmtUM6LTUoRa2QVYhd8KzJoNC4bItSYinVQ/nIR+Q5yj0XzSlLDEYgO8Hqcd55OunSaj14iEzaTx5rQyMQIelMFs+rxhk8AkAslsl/PC/MW5n20d4uO5Z5kqycb7a2sPHGFowFfQaixibxnOWAa4fUp4cdti2Z5a57zjn3Xssqd1KSbKkCG4M+zyloyUXz0pfy71O/SfOXMiI8clQLZtUUe1y5Nv0+/c0RGa6f0jTUpuGrbtZ6xS6fAWQPiMVYMPXgOg3zVqZ9tFcjH112M/N4tj6FTS62wHufqbhUrOv99a+39Uv83JKbIPcqqSwpxTqkClQaE8myQp/1WCzCd7jrxd+jrIdc9V6N7FoUtBQDQt/3zMuV5MTTeBxKDnvj2hrLmAFPiwaxqI1FEXy14VWm8+5HS3pwF6tEDSJZ2kcWk3wtYZMjMp77zCtOxxtH07VvQuEkyZXkUS7he6UENnfKpzYm2tiHTIy0HDjt1gmxqya4briiVpwi5eIRLGSXUjutrqohlPSZSYwH97xc8a3UhaMV4oLFYgKYWoDi0LAq07H0Y669GvnoYpWwKKtU2ZAQ8iDsfIcwj0pExuLTD//v80RVrb9jMz79pEJGcS2A0nlK35dcATmXm4dUdKk0qu3sLQRas1bFio+yQshFE9wMMamgzxH58PaBlO1BkCwl9L5UKZMjRn0q6U1CQS8ueya2ekjtigNSB7CWglgsq7l/GfpxCKuHRj5KrBIWZWXd6VraTkryhBO672xLYguk9nqi/uPPlQSFav2tmd2lFL7caZGhH7RiVfE1rPUKuJd3PqTQ0iZLU2K5V5cTOq0vT0ZNvG6J9HDXIkUdE/OaRQ9XMgfnkWVFmmeWdcIVWqsMEItlDVBc9H4s2U0GRdvTUcLVSJUmPKzt7hqQpz2DJkylQL74+9KOy+MDt7bV486yvqT5lnNBcVkIXDukQLz4/14Llrd/tP/H68eaCRPmnsfVQ9d9znPa9rTTbN/z1gCR5lxsQeEIbWoN9FqzrsqQSe26GhnWnrUyQCxqARaL8fRjyTW4KPGh0yI91f4kQWohYH3NVam6XyAalvtqfWDdzVqfpSQA1/riYmo0BfsHfyAHSXJuNcnHf/jh972vZdcsfS7n0pNcB4Gs0jUpqFJT/OE5PX0eXCixyyS+dy7gVHqu0A6P5SQm9HSdrsp8xUFqrSnGJXJibMRiw4YNs4umr5dSGlHlho0KloC/eQUkzvPeXnTNmvBaPbSFPHSQoFXhc4KvhkItDVrM7azDzi53X440lSiergTLItxzloO4DaVERUo75dqXWqysVrvc53IuveDbl8gDvf+sZ21LAjgXgtdKxH2WYmDoOmnwp+RSjJ/Lal3hXvT8UuxGiTLfJBT00vrB03br2TBjIhY/+MEP2ltvvfVnryuvvHJ2k6sdHTtJYqEtQmnxDqHwxxIM6UFJfEL8XU8J25zQH9Ly5CFVFuFZSmC0OcO5MyyKk+7BpejFQi61HMWujRKfPffsYXeXK/gUjwXX7mCRkZRqHONgMVF75523CJOUblrDemUZ/9htYJGTXlIR3k+DPy1uoS6ur0BoLFYZj7xf+b+5RYW8AnHp0sapWyxSvPKVr2z32WefduvWrdUbNhrkdnfc4o0XQC2Fb9lJDqko+yZO3PU15SRdI7dgPbv5IUlVKQErVUpaxUeL0HvhC/mdthRPwBGPXNS+pEg4pZXGl3DrJ4265+okaBakEqXliQvixj8XeJn7nHe+53brHtmTc53Q6xWv0PvOe8+uri9tfMNYejd4m5jML6mwVvxKZd/A54QMQizuuuuu9sEPfnB7GgXYKLjzzjtnjQivlZWV6RCL3ITJRerWGnBPNP0QQaW1LSWpcJN8+iX9qu2UPLv5KcGrlKSTK8N8sqbqST5wKW4gtVqEIkieWgKaco9jGUqtipoit67/+H2PqZprn/S8qbskt17SLBYudkZ7fmkeSf1ptVhI522Uxh51yUYha4X0v1Bu3CuXVpTMr7BupTLm9D5ljrzpTfdNoR2oIF/vxOL9739/u27duvY//uM/1M9t3LiRjcsYPbGwTBhpJ1ayALztsNTQ7wO1LSVcFgN3/S6Fa8KOlNIvu5qYPRjCHeaB9IxS38bKKiYrnJ84p3A05Z8WDJLmANePlqOzuWtpB1Hl+ix8R7LmHHDAffvH69LilH6AJaaFICkeScnHxDDc0+rq0epLWC07Wp/GAZ3W9Zm7L7U5pGjGdSDCHNS+H0ixd4N3lTHzixs7acOVxuj0KHN6JxbPetaz2t/6rd/Kfm6yFovSo4Q9QrFrO+bAWKtZSsIOlfNxexSEt1+9u/kSQhgUQyqESlBbUHBzRhKgVJZacwNaTnPkrAackE6/Yz0UK2ex0Kwl1rmkKXLJdE9m//hgLKkPOXcf9zyptcHafk7xWN039DltzGIlp7XHYvWI10hqIQsuMOnE1C7pnelGMR0rjUSXbPBWHJlfqbuuS/zUFIjFLbfc0q5du7b90Ic+1FvD5g7PDjadkDUVvsWkOeRZJDV29jmzqHT9PomUR1iXPFt6kJH3WjUFRU6A0r1e8IL8vS1KKg50JCFsrWcQ2scd1MUpY8lCUMOqKM0NbTdPFSc1WN19UvtK10LXmIPQXlLqubEMx3fndv5k3k/XhpUQpcXC4vlhmZ9Wi6dEoks2eGcWZH6VFC3rwYLdK7Eg98ZDH/rQ9u677+6tYaNAF0VWU+HPwzLRV3tyiz23W+2LSHF56t5+zj1bELSl16opKEjJU+np2Oef8/GW+M41C582B3L34sztkoUgna/eo8W5a8QZNNwr7VdL4LVkXQnPS1YQKQDVCs21w73HkTItwDJ9hWwRjfzl2kvPbHHXpfODLByWjI55bPDOcmZ+5e4/UMxdb8Riy5Yt7d57792ecsopvTZsNBjaIjDWdoQFHhdt4dqTM93ndkzB7GndrVruaXm2XFqh5V4Wf78VHkHhff7UpBwOiCq9tyS8JcGtKVBJyGqC1fL8mlWRrmspmhZfQ3uGgw/WYyVKgmhTZdplc5GSJGojzXUu44ojZSUHpsXxANZzTlKiIF0/XCvXd1KdDSty66Zvmb6pQhryWInFFVdcMbvwjTfe2GvDgBFBSudLF6bFdG8196bKQrp27p4WpaP54T0+TO3ZUn9uDlZB4XWXaAc1ee+dC0bzxEXQ39qx2Fp2Rvy313oWl2im8eYIBjeHctYFqf5Bzi9vSTusoTRipZYbb2ovZSJQ3QXtubWXt70aYeWua3Xx0ByzKHOrlcnyTCsV46Q0MjKAZRslvRcBNSdk6f21I41TU2BX87mUHiiZrnMme6vS1YSl14cpmXzpGbxjmTOXlgg76eRNqp6ruQ+8JCGXVukVgtKzcs/SxbydzhUtVdW7c4/nVG73SZ/JKXEtJsQz13IB4tbn5II4U6VuBZEY6TrxSaBxYS6LtYfcSTlwY17qathUMU6qxDJXGSAWU0WYPLWLbHndCNa887CwvOmgYbdoyVCQ2vFHfyTf06N0JSURWxm87oHY5JumNlpIRtz/UpXBkhLnmsCW4hYsJuuSnVJXU/ARR/DPQcGAFmi73BxxLSUWHr+8piwlN1CJIpPWirciJKVz57J/LO3h4p00i1B4znh+aGXItTZ4+qIk3XVdoaXJM649bkhBLKYIbVF2MX163QhW9p9LJcylXXGxGpKwtwrxnGlUUrrpziwVQKU+/px7xOou4lwp0rW52JCUqFgUn9eypbkyahLhMF/e+Eb+GTZutN9Dm+daJkCJS0Abb62wlBT0mK7fLqnuHDnUiFc6h2K3Yepi6qqMLfcP1+Wsm5421Ezvv0q5lkf5l1qDa2xIE4BYTA2WBVVaU4FTUrRz7XIolGZhyE3qXHQ/t4g4oSm1SbtOTqhJpZ1Du1PBklvIJeeVWMs2a6lrcZAt586iv48+uvs860OQWaw11ngRz73SPnz2s/nrx6m4qbLTdutcu6xxSWnQo8eyl1NkEsnX1ralzkhJUTtrzYsuwa9aG7Q5ZSHQcT+vGGSZZc1YCUpNC4kAEIupxTOUHpiVa7c3b11yI4TgOquFgV7e6H5NgedMz1Q3QIt36BLMlC5eT9EaD2EMKaDSmQoeEmKx8JDLQBKi1n6pJchi5Wa1wtSK1Ofccp6UylhBaFbHtOR1l/6zjntqyUgVGUds4vmePk9ahj1eC6R06dXl+SzrRTonw2pFKrFYxBYYiQxwfXkMU9SrlkslHVdrRdYOALHwoGfzUSeBqinFGlkY0gTvErxXogi1qnPa93IL0+vH9/SxpzprLiUzFUC/9Ev2fvL4weP7SvEW1iC7WrnzlrRCzhUUQGuHiGWNczio7SUplXGfcWs5Dmy0BASmZNZyZkh8D00Jh77krsGV5rZY8iQ3IpeuaokvysVKxIfeadZT+h/FY6TptZq84PqVu66FRK1hxqNkzXD9aG0nLBZzwADmI9GqkApUUi7x5Mmdzujxu0kR9PF3uawDb755iSK09LekQHtKqzK11fosOXeRZH61VgK1piimfSbt8KzEostYeqojWoVvqaslVjSe6qCpok7vEa9lbiylgMB4JxoTA87akCpMa5tJ2UoZQp7xlCyJXJCqxwVA5eQt/Z6SBGlDFKxSUl9qY3fccXIbgqvOYxle4yjHLhVE0ywrNay0AkAsrJAGiAK30h1CiavEEyAZhA1XOTC9RklGgOaDlPzYVnAC2aIIPZO/pKiRhlI3klRaWWqTVhCJIAl42pVp/cS5aDTLV+zOClYyaTdrhXcs44qVmvmWe3ksEhI0kpdajawvLvYl3EsL9OQCAnPBh5yrLeeaK3mmdJ6WFIWL14mHhFoPPpOuEa+F0vgD+i7pADr8zEI0pUPSuM/S9XJWnJw1WnuerlZaBSAWVmg7Js5vGgKXLCRDG/yuATmlp5tK1osaVhqPkimd/LUWjUb44r7nhEpKwsJuSBIEuSDDXMAY97zarlsaY1KcnJWsqxswkNbYNMyBUxic+dZq/SpByVkZ1L8XXVR+EJ7F8pXbiWoKO003TdeglbzlXClcqqbFYqH1u8e1R7VWrPMineee+APNAqv1HXdC6kkn6YW6OCuOlQTViiFzAMTCA81VwAm++H/aYObIQ9eAnNKJ1eUI8hx6ZMvVIPnAyeQZ76al8yDSXX1OEFiEKgV1WU9uzLlWwjNy1gjOp64pjnA/zsfPBfhp1SuldZSab0vO8tDaam2HxSIhBRbnasSklq2YnHpcQ/Hc08ix90RTStGlmBtaA1q8C3eYXhqT4t1hWyu5WjdT0r0sFtWS+REHQ6f1NU5Vjnvn7kV/a/JZco/E1pkeAWLhhfUYaG/goLYQrAE52m7XqshzO3GPCbzULdQ3LO3SAik5YSb9LyYFXU8e5HZIGmnVdrVBAJeeYsll6KTKyxJsSX0cZ3Jo7aEsmDSNr4Q0W4OwcweIpc8hmdpTUhWsmVJb0qJ39Ddn6dJ2zIHk5EzhnGld2zylz0z3sQT3pm0lxSqtPy4mxKrYaczStSuNcZf4A0t2niX+o0k2Cdx9pXs9/enydbj5PWDyAYhFCSQGmWOw2k4/JyC9ZlDLPXN+bS7q3Xqs9zwzaDTUzpCJ+4V7Lz5p0kIcpKj5nCuOG5Pcc9D1Od+wZS7Hc0taD57gxvhQOY2EcOPmsX55zMda+7UiadZMLlI8pf0W2pzbnZekRQaXXfqMUjskYhEqm1r7PO27XBBlat0heSXNRe5ekmuRI7Bc+6Q+idtqKcTVRN/jYue0e1leXVzihQCx8CIIi7TwS42jdz1WBW6SWO/J7VQkv3YJWSkRJEOgq5lVG9tc6mGICtei0bn+JsVvaZOUoeH1A4c2pUJbiyEptXpIwt8SlFc6n3IBst6Mj9TiwvV7jiiVvsI61DYlJeZ+7ju5sz0kYq1lFWlyxLpWU5npCVbX3CnhZ8jk4OYaV3QukIMYnuqrlwrr2BO87K0O2wNALDxIhUVI85R2JH0GzKTCJCU26W6X83NrQUBdBHqtugW1YRVwkmDV4hWsfRh2VWl6sCZ8aJ7lrq+lfobdX659qVCM20lVJLm5QJ/XzhXxvOJxsLghalWYjfvZ4wKT1oRnPZX66aWsD86Hbk03Df3pKaYW2iERWGnd5OSIJ4izNL3eO06cDM8dAFjrPisdYjpgsRgxsdAmrLYL6hKgmIsFiIWJtANJiURJJbr4lMBcBodk+u3bYpHrK0nwSbsgzs+q+X6tu/Z4Z27Z1cbf4XZInhRLy05cOixNc8OUCDtJ+IUxpN+POkr/fOl80uIIupxEGmCdC8HSFVuGrN/j1mFMirgzbHJlvnPKORd8ad2Za+XXtTlnietJx1dT9jRO5I7yni/EXSsn57U51xjvkz7XwQfz303rHIWNT8+1K2KAWFhRkrnRRZF6YhS0VCWLsMp9jp4ld3AUl54omfxrB3SW5HKnnw3tSosOpYFjkhDx7CikOaMJOPpOLhjTGrioKVWOoNRwdcQ5+ZIwjPtdu5Y3Zieec+H3EiuLNL4Wi0UI5uN2t/EGIUcwpZosnB9ei4fS4nnSeZK2VaquqRHfkjHMZchoMldT9iVpovE6LEVok1SKv1HqI6XXkDLWuGB9SzZWZYBYWCFN5JCTXzNXuIY5j96z7CBiy4bGqEv8oWkgUklAZ46IWKwjOb+6Jmg8BNGyK8lZuY48Uv5Ojrx4Ui0lv7hEzDw7eWnXJKW2kqC1CHopQ0CbJ6lQjYMBLc9Cn6MgxND/oZR3bq1zmVzcAV7WTQJ3xk0Maa1LR8NzGQuSe8U6p7zK2jJf0wyZXKZESfxXzfZK9/Rk3zTMWkyvocm0WufMdACIRYBlJy0FtMV+9hq1GWoEIAUBzLFayScoKZwa/tCSCZ4jIpo/3Hpvi6DRqpRK50gEBRLnp4csjFybYqtJOkZdCKBlzLhx4Xa3XN49/R3vZNP1oFWvzQn1l73M5uZKhbE2tl0sI5a1XlKimiNx2jrJWWC4jBUtONZ7VHdXq1ZpAKenVoVFIXOvE07ovlnUZNgKQ1S5tWgtjsWd3zKneDcQC+9OulT5DmmxiD/LWVJiociZib3H9Vra6z1Rz2Lq9FgZJIuSJR89Z07NKaA03zycrJmL5pcUlzYHrQVwckrXUlvDa6XTLFs5ckc7bM81NatQqjyke1tTqzWUxBtZ+1WyxmhzWBt3+n7srvG4nKTrBsVYckKuNH5Uwp6zfKXZOV0C1eONR+lm0UMSV5T6SFr8HLfRjT9HGwCrTKsIEIuSnXQNFpjbFXiEdu6z0uKQBJN2oJH0DDklaTmAyLKzyEWue3eZOYJijdCWyIwkuOIy3SRQSs634DKDPEpBcwHlUklDP+by/S1+c0smRizog0tB26kTkZXqFKRKT7u3dL6H9VktFjUOOYWW27F6102u30vG1hLc7LVYaK+ctcrq9q0V2FhjM7U2M55hnkiuMOn7PQZuEkAsrGb8mn4ry27XK7S9zNqzaCWlye0GuDZo7hrtWlz7wq5EWoReBU3X4UpFa31pnTOawiKfeUnMiSeYyzIn6f+0a5fGnAvIk8yzVqR+c2v8hiVl1hpjRP/n3DmWuW8dlxpxOyUxFdouOUe2cvM6B4kol8pMTzZFuCb1TS61PF43IRg1F/9Sa/y5uifSZoErYCe5fKykpNYcVLCcxCI1/+dcCZwALQnWDGSBu198MFMthVNyIqdFuHiFhDTpc/0vKTXNzeNBabS0xU3zxjfq/ckFLHZZ7F2saFogGCectHMNSvrO8opjg6wva1aUde7n1pSlT2ucECxZQiwuKk+xJmlcpX7IyS0tdkgD3YfcH552c66hAVwARTFMKQLpifsr/q7mGovHnfu+VzYUYvmIBTf5JROeRYFYGa4lxSmYhjn/oefwGKtFpNRiYY1I7hLjoKVXxqlY1hMzLc9favaNn8cyzoHE1Fzs2vPkFKL0XUkJdaniVxLkF7JBvN+jnWG6tkvuHZS1N+6o1A2Suy73HKnrId6RB9eRx+KTzuuSQFltg6bt2j19mVtnXYMvS5GTr1K9mKuUDa9kkU2/l2bicRYfWCwqEouc8E3r59NBOTUEg0eJa4FVFqHmUZjxpIv9s+kiDsGG2j24uAzOhWSJcbBkbMSksMS6UytOxns6JNdf0jh5dsgS2eEEOpfJEs/9OMiXG5suBdAkgRnfO7iiYtN0iaUjDcDTMidyxYUki5uGnMWtBLmqmKlVtYRM0bU4F6y2Vvus8yNd+znPWZXRmquka5HCLpD63+JaPsm48bBuIrn13SOWi1h4J78mrGrct/SltcGrMGPlSIL8TW+yLwRtQaepT2Q+91ozcvfhzONdFFxfQl/ro/TQtyCkrTEMGnkrIWapO0izzKRWPqtVjbumJYg1Nxdy8147LCsliJY02fgEUem5LSWfPbDIKWumTToXc3OtlDx0JfG5jUwgGSVpun0TjqDUc8H1axWyLT2PV4Z5LOwdsVzEQhpALdiHE8Y17iulh1mFQWmapoTc7oa7n+ewplwfapPee1S9VWB1jdGwzi8uoC4V6NqckMYwt1vJER2rH1oam3Qn5Fkn8TU9qbu0Tqk/iSSkFkXtWaS4BEtKKf1fGhMLAeyS+ZMifQ5pvnjWSyAilrocOXcHt55KZFKq+NNrS2NpIXE1Ytis7Y7fl1y2VzmOb4+vP9YzmZaOWHDm/5ip55SkdtCT576aAqfJJKWB5hZlvNv1KMzcLki6X6klJo1TsdZd4GJPuHaHIlQW1GbxXWIvPEGEUhBwbkfjvU+u6qmVCGkC1xIbYo1dsSq2+DsW0q3dU3vumkpM2qBY3VVS+z1typFxaT15SLwWx6GlVobP5447r22p5NqdnoeizYOVzBoIhCTNpuoSRN0zlo9YEMJgWcxPNQcs3NdayCbe0eUWJedLtyrMXASztoPk+stC0qhtHqHL7dToPel8gjg4jHMX9GkGlYSr1zzNzQ2vZakkXS/cRzrQKlw39yyhLdo4a7s1jVxLr9Stod1D6rN0LDV3knY97XBA73zSTsCVTO2WsQ8WW0+bSsm45XsWxZ8jzNoJqDV3+fF1pTYF92bumTZV2JAMHaCqYDmJBSF3Imm660+D3jzKyTKxc4o15yqwMtfQhtgfLn3fUkNDyqjRygZLOypJyGnPp/UnZ2b3FpGqDa4SnlVglFiWgnWDi52R5iBnHYp39hZLiBaAG7dTCnAsPWWUG9McOSip/hjIO3fdI47QU/08SiydvxJR0dxVIRBWc4/MYy1wsCp+a2Bk2n9SCqeXJFmDLYNMszzTSsdg8BqutkpYXmJhZcZcrX9OOUlEI04flYSRJNys5KXLYgzt7xJvIPmQtTxsz0md2vNpBX8sdQz6MB2m5C38TI+dlgREaFdqdcrtvNP6CDmXmiSYJEEYXIGWMuhh/EoCpqVsLOsrkEpP4Gdqmram/WkEuut8k+5tiSOwXq/vteCFd5OUWmtoDeQ2TJZD5Lxt1Ky0RDRL+voqp6u5S5XYylheYkGwKFMLa+QOf5GETpj8ki+Y8ylbrBldzIe5XU+uD7V2BtJx0UX3ko+wi7YKuVKLhbUYUM1gp66xFJwpv8QELPnjJeEXn8WRIxaSYKWiX550YmnsqA+4tnOffdKT7EJWO7aaczVZSLdH+FutAjnXR6gU6XVhWNwjObcQR5hrkxHvJieMaxqDoKVsxrELOddM+ozSmHOEWJq3L3hBvh88Fot4Do8Ay00sCDllWlrQhxNe6cROC5lYTJ6li7GLn7mU0HBKNj2TxKooPRHnmm+zz8XoFQQlysdqAs7VO9Duy7lCQp/mxiPtD2pHfLCVZezo3mk9idyZHp5x9VQatbgaLGOec7lI48vJgS7l1EsPUtQIc+wCrYXYhVN6qF5s3UmfkYtJi69FhIOIApeGK92L3n/+8+3rfMVY7NATIzWCjBACiEWOndZQFrkJZb1H7khjjSRZLBaefqlVF4Q+w+1QPWmPaZxHcAkEU2ms1LgCSB5o/V+rXgmXFZG2QQrYC98pjeXIxT5wrkKuLzRFFPe5JDgDOY9dbF2EbFAW9JIKfFl94Sly7hAuVVCaW7k1c9hh3WIEUquoFEeWcwfVyDDJwWO19aZscs+TOxAv3TSlweRSzI1lfmqwpvUvg8Vi8+bN7RFHHNHuuuuu7Y477tjuv//+7fXXX1+9YYNM4nQBxspJ861xL2LBVgWdTprU1OddxJxg7pL6RYJY2vV4SjCHDBGvwk+Fn2YB0sodWxdjTtDVJKHxcd7SWGvPXPrKnYKppVzHpnKtHSm5lhS6tFu01GjIKQFrhU2rsE4tKmEX7KnV0YWYWpQU14Ywh2IrSJqG71nLqQuz1FXiHQvt8+k60ax5ufUTp2JzVouSfsohF48Wz+GRoBdi8V//9V/thg0b2he/+MXtP//zP7ff/OY32yuuuKK9+eabqzesCjjTbyr80skZ/53umKVJK1W3y5nxUvMnt3A0KwZXmbG0IE6aPx0/VyygrWQrFUSaxSUtmCMJaotQ8uyGrNcs2VVbXyFmRCJDFlJjPZpcu560K00DRT2K0JKGGzKJJOKi1bCQiimlJcNDgG2JRSsQbbK+pdlUlrkjEfVaSiqneHNE0KM0ifh1ddeUpIVaNyelG4C4n72uxvQ63qDbNcKhc5oc70LsxkgsTjnllPYpT3nKIA2rglywmgWxwrYEzXGKjttBxe4Pro3p+SappUXyI1pg3UFRe0mghkCoHMNOiUgO3pSxnFAq2Zl6BF1K3uhnbIFIrV4lyiQda0umBtdv2o5Hc1PkFGeu7SVWlngOSBYHTw2LsL65+aWRbg/JtcydEkuTd6dacthf/Hr607tZw7xm+lLrkbY5ybmvtHVo3bxoacZaYHYONN/T66VnOMXwbpymQCwe85jHtCeeeGL7/Oc/v/2FX/iF9vGPf3x7wQUXqN+58847Z40Ir5WVlWkRixgpSbAeKJPbsVuCk+KdreRHtMJjeYitMRSsx9VBCDs56+LXnls79TQnlEp2Q5JVy+JO4fy2sSIsKY2ePpOm3GPFywlMrV6JJe7Aa8LPBW9an91qdZP6lgS9V4FxZN1ijfBYCywmeXp5zmfpYrFI20brO8xbaoN17noDC7ukwFuQHuMuyWk6sp2zEEoHe3U5pM9rsbDqioHjL3ohFjvssMPs9brXva794he/2J5//vmzOIuLL75Y/M7GjRtnDUlfc3OFWEr95q6pHQblHehUOeV8n1r0v/W+nCIqVQKlQkFLJ5Xez6UISsJci9rXTOrxfa3fsxAdyys+Qj595nTnXXJUu9WMz30mdpnRT7LaWK0JlrG2KiopuFJbQ5Ilips3lu9L81GLZckVNZPS3CVoayL+n8dlZrW2lCo2zyZkKDnNpbVqLtGSmLEY2jrh5ukIzhDphVjc7373aw866KBt3nvFK17RPolyzsdosRjCdJTGYXjcEpoiLNnxWSfYoYeWKzxr8a/cjksifbEvXBJiqVCKFy5nRQjxA9wCtwbYpgr37W/Pj4O0Y6SdoaXIVzxfJUEs3cNCNC1CMjXVBjNtzgqXe66wK+9KzKU0QKlv47oeJa5B6Xk9dT48FkNrn2jjQc/skSEeS0daV2SO/v9Oc92SLVVCijYp+kc6tmDZLBZ77713e+yxx27z3nnnndfuscce1RtWFX2z47QKp5W8aPEV3mBBa+lXSvWzXtMihGJI9S2sO/6gDLUMgXgnL/nRJQuENXdde9bcTi5d6OkuSKoZIb1yBCF39HdO2GsndHYRZMcdx7eLjsFOx6/ULF7icuH60+KyKrHOpaSMSFD83J62l+5KPenJ3syvtC/n5f+3khmNnFstVN52rXW6qWJ5yT1X326keRCL3/u937tP8CbFXKRWjBoNmwy6CN+cOZ1elp1tvNBzKabSAnrGM3i/suZ6iZWRJuQ595OkELV4ivQ5uc9Y+8pr9rUU5kpJVJpRwcXBWM580HaFufmXS7dOSU98XckqYxG2ktWCWxulxD93yJ5FWVjGfuNGf9ukuZIWbAqVJTViU7orlXbE9DrnHL5SsDRuweXFxR5IFXclq2ZN0lCDzOTOJSpt61UFgbVS4HHq8u1zozw0sbjuuuva7bbbrj3ttNPam266qX3Pe97TPuABD2gvueSS6g2bO8JiyZWG7er3sviCtXobVsGdK7UdSnJzypImO+eiiCd8zpxMdT7SNnniKbjnzNVJyL1CH1vO+tDulwoF6flyCiJHNCWBI+1iSnZMuVecHpqa/tP3SmI/PJDOkwn9IpXej11olj4oCfb2KCutHaW7Um0XHrchVVLSmAVym35e26yEtWhpP40lEdmYiOTq+9RyDVhIYA7pujwp4+rzrs2BXR6DF8j6yEc+MiuKRUGcj370o7NZIaUNmyu4wjue3GlJuXOnqFr9zOmC1twFJAjDvSwlk0N9+1wWjdRWej9HXDirRY445NwiFP3PvU/m33T8pLRgbVfH9YOmAOLnsxLOdF7kzkHgnoP6/7zzVoMCY8HcNRWRe0buoD5pd1VbQFp3hDQvpAyB+DArSx94d60l5nWpHWRVKFGS2nkkWgaZZp7n2qE9o2fMuTgeS8xD6aaO2zSmsXLeLDup345RKgJL62YEQZoSUNK7FNIk0QRMzu+VTqBUOJeWo+6S0pYqTJrMpJw0QZ0rHpM7aZMrXa4Rh/B56VRM7nTB+HvhUCf6Xaon4i34xZEhbswsSpUTLNr3JNLBkeAgPKXn0E6PlZScVMsl54qp4RO29lXcB+F7af+Ea+RKNacbipxZ3hJYKm0aahCwtI+4uU2ku0u8TgzrYYBhTXLwzsPcgXy5ftM2jX255K4T0qeHIuQVAWJRCm8KUIA0KS3mVm7yWYVYyrS9dRNixZA7yMryLPT/I4/kn1Gq2ictJG+N/nBdaXdFgjCu7eDJBuB8nLl6C97UWI68lJAgaSxjIeq1WFAwZqki6eoT5voq+O+1yPpcdhV9RjtcKp5LXl++NF7STpirkeP173N9FLc5twv3KjTrfNAsuG98Y7e17SGuJZtGC3Lk6GpjinMfhLwyQCxKUXvyWQW4FFBmFWL0fetCj3dtXGqm5OdP3SqSoiPlHZ8gKJEEbSFple5yz9ZlZ2ApopP2fS6tllOqWvBqcC3FJMij1C0C3hpfwM0bz3284PpTs9RoGQyWs0dyzxQUvHcHWVKcL1ilPBlmgTBLCpru5yF1OTKcWhtLsmm8GTHhRcGjUh9YnlFbQ13cDDmLxQrTLou7o4SQe61qToBYdEE68a0BSNygWi0WmsC3khrLvUhh54iIVMCHIyHa56gtpJhDsF9O0MYLqdbBTZ6dQfrK9btkni+tmMjdP8w7yR3UpW+8Kc25tvbl7siVZNbODNH62KLc6DMlp6NK34njPyxzQiMwucDJUoLHKTSJnEuuwfigttwzpi+yItUsbBgImxYs3kURa5vRTR1j8zwYIN0XxKIrUh99Dlw9Be4Y4xwT9/o5uXaEe6UV/NIoZ4nEUKwF936p0gmFr3L+8FzbLK+SAC9JCWh9zrWvS8VE7XlKC6ZZFE3q1pHibNLnlOZGsCJ4BaQkaC2WGlo/XBvD2pP6Lg3y9QTt5pRALmOFI6Dec2typMJi7ehaNtx7AKIWcBvieHJxEJaMpIBaWSu5/kmPcT/JsAZy7g6P9WGguIzlJhY9m4PY+2lsOAgSyRKQ7to99eMt5WytcQCxGyRWkpIrI/bhWpRanDdveTbO7xyElxQYVxJEyfnpc7uYkoqd0ljlTPa5/1NbSbmScJbGw2pJyBG6MBdycT0WgR2vU82ilbM65CwK2v9zxaC4uBe6p6Y4cqZ+iYB6rJXa/LNkk+R2t5axsW52PFlwWh9IqdbSc+Tm8qte1V1HxPencaV1+P5MiYK0X9KTeKVn1fTaQJkky0ssPAumFgGxnEAZ7idVm4zRd/5/7JsNB5txApz+ji02HMNO38tlhVjNyrEgspRLDsF8HKSy1NK1LDnsVouKtZiURgg4YRwsS6lFLVWAoXy4R9hpipH6JbcL5BSGxcInjWn6TKmSzsXvaOQy1/epotJOHfbMC6mtXByTZNHLFdeTZJvFPZgbm9A2y7xKle+zniW7zjwEk5M38XPk5HIoWleqAywbyloZPTlrKCwWPRILz4LhSjzHyswz2SzCJC4JnTN/cTUhtMhq7+ThTI2ek1pTRRVYt1YzQxPkljTMGF6TsXa/LkyfO/KYU4xdSi8HgiNl/3C7mXgXVOp31YIPPYrTMyZaEbbY3M59l2JQtKDD1FQd/58jUpxFwjJ3S2OD6NkkwibNo/Tzll281kZqA1fyP/SvNs89sQThO54+trjo0jnnOb6gJCbBuqHMoSsZDRggk2Q5iYW2YHKDx7FEz2TLBQEGy4C0C+eIj8Tq08962in1g1T/Ik1RK8mw4AR5SRpm7jPp7ilXljqQOG3XI5E3acdYIrA0C0AaiEqKPbebCWTEs4tJn1PrY+k5uXGPSXq4h2a14s7tiEmpdvgbvUKwMDdfpfgPbiy5frJG8ufGh/v/RRfl5ZNkuYhjwbqsHyqUJ92fm3e5/sqNl9UFSgRess5I42a1qlnaU2NDqaELGU0Rbyp6wHISC21RlQ6eh3WGFMF458Wlb1pNWakrwvKcOWj9wAXBWU3K3uqB0gKwWhC0HXww12tEJz76Ox6jmOho5M1SrMoyNjlCZu2f9BVMvJaUR0vEf+gXaQ6QMo/dBEEhSBZCSSFo/nzrri62cljWiadKqkVpc+s93kyUZuPk5lGOtEnrh35qJ6BycSa5e1hTSiXFq1mo4vlonaPWV3wycc4anFrCPONlkf0aGe3BzWHBchILbTdsOcHQO/k1wRx2Elal4THJdzHfa4tOMneG6+YsQjVSxLy7bGknpaXCSoGfMYnL7Zyl6592mm9sNAtAl2wZah+ZgiXrlGZp4iL+478ltwL9L5QWl+7NCc70GpqQtb4060pqYfBYrVJCm8biWNdm6SnD3DxK5Q/3PbofN5fC2GqWhdSimMuSsc5Ri3K0kOP0hF7tnBbtnCX6v9V9yFnCpAKAFsRxQjFB4shoT24OC5aXWHDCUDq1Mx7IXGyAdi9pkeVS5UrK04br5hZ27kRAqzKm+5BQykV0Szu1ElbtcfN0qXfBjUdQnNpntHty5Ewz+Ur+5/Tk2Hg843gMqaBZuI5UWTJnIcgpsNStwMXt5PpbKt7EZQNJp45q95EUYHDPxHLBY7WKY4nS+WldxzmXDteHkjywKPHcOtKqR+bcFXTt2GUqzanf+i2/cszJFWlTx5HTsKYCOeL625K1IhHR3KFpEtJ1pZ3lMqdTTQOWm1jE4FIJwwSSGGE8WXKTQzPden2SOVZqicGwKmVPMFS8OGPzdmgH3aNmupOHWHQxe6bPljuwLWex4EyWUoaJ1O70edO+OPjg+35H841rfSPFHlkVmBaQm3tZCHuchifdWyNnVI2SSFjqr9esiLHVymo94YKPcwpUUuQxYbGcIeQh1rk+P/RQ3xqWFKk2t6XCWdo8kCyh0viQ4ueOhLf0m3ZuUc69U+KeXhnvuSAcQCwImsmay8GO/Xq5yR92exLDzVUL1KKorRXrQgxGHBRqnaSlJaIlfx+X1eBZILn+1K7DHY9NbfT4seOYC+kVzxkuIt+TJmytRGrdjZKPPFcJVepTiyIsPSmV8xOXmHJzAb+xeyZ9XrLaUL9yhd+0sfIo7TRuxbK7TLOKuHWVk0WSXLAEA1vIjuaG1NappIS9SrPLvNNIjNR+7QRnD6loDP2de74RAsSCkJt41lTAFOkuMt1Z5IrueP1vueqQOf9qSeU+70u6luU5U0tMyUJLj8cOJlHpaPW4EBgpZUvOe9glpfU/PBH5ARYC5VVsErkjAculJVoJrUT4whrSdqixYuxqyuW+H7uJtPEu8flzhFWK9yhZ0wTqHwpwliyIFgXDkS4vQeeIgEYAu1S09SjNLpayHImRyCr3fu48EK7Wx7oKFoucW3tggFgQchOvRBhoTDcIPUsJ5hBcZpkwWn675T6aMOEyK7RXDZN3qgy6PEN6XU5xcQWyUjOuduhZ8HumhJErXpT2KZfeaBXiHheDFGsR/LXeEvU5Ap32DVfTo48As3jucC4zS+yC1oc5cz49q7QeLVkbHsuDdd7H7YmfwRrwl4tJ4NpvaW8tM3/6HLR2rccl5EiMRqjToGXuWXIFBC3QCE5JzEaPWD5iIS1cq9/cihxT55RGqVskPJe0Q6Kcfema1smdizOx3rP05FbJuuN5Bs/OUNphB4EVkwJKvw3pw5pfnhNKUoVG7t4hg8MidLgYC0vfe3c+Uh/lsj3i8fNU+0zvnSox+jsmfxyRCu2z9o1mqs9lQHkUmVVBpLIjJa7cGFp2vKXnd3AyLW6/RZFqpMCD8Bxc5kUgzX3HKliet9Qqt2IkMnO2XCwXsdAmvkUIenOXPaY5LWrfMmFKsh6o2E6cfuVBWKSU3RD3KQV25foy51OV+o7rHzLre4O8gosi952c0sgtcOl7mhUmp7DoJZ0/kbaJxvXoo/PzgAtwtO58vMFt2pzwHErGWUk8VjLqp1xFVHodcYTudisZQ/o8RzKtCoLe0wo+cWNYw0fvlWnhf3FgvFYeWyMFHuT6klP8tV0JHuKw0uHeI429WB5iobkmPH5Vj/CVmGuto75zz5d7SalwFnAphZa+DJk2aZGk+P5S/0gpmnG1Us2EnGbgcC6KGFb/M/2dM62n/lXNChPMpl0sWFrKWxywGgvWkp0PVzAprKuS+Z0bk9K5Lj1XLnbBkl7O1RbQ2nnAAd0UhKeMukXxe+CVaVwxPW0OW10n2lq3Vj6VytmXWktKsKlDZeTSIPYBsDzEosvOqovwTYuydBGMuTiE1G/vuTa3i5Ig9YMlgyS+j8TqJaX0ohfZrs/FM2g1HLjntsY3WKxdQVh54iByrrnc3EuJX5ppkfZ9ycmUXNAiveh9zQ1QMs9jlBDznMuMm9PSeEnWTq62gHS2S2oltMoWLW4jFwRZ6tvn+sp64J93Dpe6W0rOUJLarcmSmlhxpHDHRCeXFIAYi4lYLGhXVmJ20hZBvMglP3Aux5q7flj02nNJ76epcBJKj67O9Vfu+tZXzq1S4qKgvy3KIH3Fpl/PM1hJiOfwLikgU7JshPZzbiPt2XMpfpbg3zCHyRIUCq/FFgLvnLC4Wjg/P2ftiQso5RSDZMkiK0nu/tYgXc/Gx2Oi9yJtfy7rjZvD2jNoVW45kmeJv6p1QFgJrjLoE86aIumxORfFWk5iYU0bkoSS15xo+Wy8K5UWgiQIJOUXfy59XrofXUsqJ33kkXy/BQFvEaiadcC6UHNuAI+wygmOdLFqLopUiUvXluoMeJ/JuttLdzSlVTJz/WRxV8VrpXQM6bm4Yl5aVg7VoOBIQMnci9NetWqOln6WrG9SXJOm+C01TWpZJUqR9l9ubklWmfQZtHkqxbrQ37nsJuvGQ/puF5fJiiGg1mpFG1k9i+UiFjlFrZ3MR+6M1N1QwoTjANCShZC7fmq65p5XO3fCkoJJkPpBW6iB3OQWY46c1LJYBGsCt7hLyyRr1iDPM6XXoe9SYGwaIxIHLcZWK6uJ1eMyS/tVS1v1jmHsqtEOutL61/IsYR1bULKGuX6W1pAXXJ+Huinp58aye9WsS5r8tBIUS3ZODtrGUiKjtVI8Nyn6xLNxGcNYLzWx6LIQUneDlwnHE6BrNK8k2DlBw31XekbPbovrB+m5XvrSbatWhr60WEOkBc/VS0gXOZfSSUGggcBpBM1CIC1xLZr/m/sO5xoLrhirFcNCgEtcTrGvOyU52jHsuTbHptxcIGxpfI80R7rUYLBuNOI0Zg3aLjhnQRkjvKcZp9DmQzyOHmuydJ+QkZIbz673ku69YswUsrRxzgCx4KAVQfJMIE3oWFwZGuhzdFiPpdyzVLcj92we/7D2XNIrFZJEFCyui/ScBqkWBFcLw9MP1p1fsHZJ80WzInD1HqT+o9NALf0a76i9ZZ5z7SByWEqatf6JoWWUhNgHS1aLVq6dIwipLzu8b1E0NSwEuV3wSFMLVXRRwpr7g4t56jM4dV7jsEmxDKfp7qi8OXJiQaBJ+0d/1H0CaZNU2/VpyPnFA7HICSopTS7uA+76aTAd1z4tZkV7aYWVrAFtksIOO9ucm8QyBulClnbMVDqa65fwLFZzp6XOiUdox23i+oDekzIajjtOXhdaICiXiii1lasxkYs9kuoTaAdGafMgrkYam+X7EOAWBVx7pzwUShR+zv3ByYGQftm3G2jocVjJEJ1abpmKALHwKm4pSr4E0uIhge79TqwQJL+k5GfnhGb4PQ2io4qOnE+fq/TnLZJEL6rYyRET6Zhgq2JO+0hT6jniyC1kiViQ8pT622rupP9Lpdq5GAsvpLZL4xcHGsdttqbUpmMpKevgPiCSGLJE0vnJzWci1jkCabGwcMHQfQlw61zkArKH2Kl2JVReq47UHxs33lf+zkOx9hEku2Io526tqJqr69MzQCxSWKP3g7m0y+BpJmNOiea+E5v7u6TGxrtjeu/lL1+NkaBKnZy5WVrUGgnSiJsltcxyD+0VrBrc/7i00ly1TMm6Y9nJ5MydkuKXgje90J5J6lsiTLG1S3MfpuMe969VKWjzM03j9ro0tDnkDdTU+rjWGSBhXkjHkXvvnUNtxW1pj+QqTsd9nlacWi4wi9tWGgONFNcarwKAWJSk3nGDaDGfp9B8yVK8hbTgSNDHi07Kd7Ze00MG0nvEOwop5ZX+/9jHysLcmzKZC6DkXtJ5JrEyiat1hgXPfYcCQnPXKxVSnroNpUJVUrzSUfMp6bOcDZOuE49VTRvXOCbG6tKw9HGtYGsPebLugq19lxIyT9l0z336IClpf3AbjRono84bK8K8DVVotTGwyO45uMuWm1jkdqLel2RlkJALctOsC6mylszplkXctSCVpEQ0f7jU315XTny9XGGw9FraIpQqX9K1PfNEIohWlMzLUqEqKd50HnVJBY5LdluVtWV+amTUOgbxc1qsGhaBXTqPpQ1AkFfWstXSGrPuYmsGKpb0Yc5qN8ShYiXwWImuyhy17qmomrO8DYTlJRYpc+bOofC+6Dqe+AtNaVgXnCZkpGwJTzu6vLRnsNThKPVj5oJHNcsDvZ+zEHhObrWk/0pBaPTTk0bZp1DNCfiSNlrTJ7taLDyCVVPsJfOxlmLmXDw5hZpTWJZ5UtNi0aUvtHb0Ee/QBamVKLaYSXFBazPB+Lkx0DZWsFgMRCz6UqSxcOyiBL2LQ3KPeCZY3A4uOK/0JZWc5jIHPMGlpbEyVF00HFrG9VnO4hFiDzy7dqsS4VxxmoWA2lJ6ToCnL72WvVCvQQveDWNqKfgU+oYLZk2fOefSGNqvXkMxl9YzyBFkz7z0zDGPAvX0RS5OZgxFwaT1QZVhtU3eJmEzVEKeRkC0lpNYlJr+aUKECHUpFa9kwcRss3RxpJPJWpaaa0dQICFATPNz5vpLi+BOg/A0V5LFN2sxFcfX4JRybm6QZStd6DXmgaawY5KYxqmk49aHnzv9rBaLFD8vRxziz3h3sOn8TLM/LC6NeaBUMeesVqEvrMWVupIbyxzLza2uSm8sBKKrbpE2UScppz57nn3O/dQLsdi4cePsovFrv/3266Vhg1ssYqGXi4RP/Z19pv8EK0AoHiVZMeIKl54da3zEsCVQkovc59oUKx6NMOR2OhZTMbe4UzJnmRvxMfEp+dJ2010EEo1rjYI4nl2j9tmg2CloWFMUaa2WNPbGGryZPmtOgY1NAXHtyT0Xt5asxCCXPVaaPVQjs6VkbPqWn7UgkelSAj1R9EYsHvvYx7a33nrrz14//OEPe2lYMbQdp2R+lhYJdw5E/FlOCKYLRVs4uUUlCVnuGcNO3bpj5RCe+bzzeFM2FYXiBIzFPx8rLmugmsVU7PG9W7ODuABVIhsxwavhYkj7xBqUy8FqJaB7SZVXLefRcPOF65PcDlZaO334kYdUXtbniteV1+ohKTjrKca59g5VkXIedSq6gKvma9ElC4TeiMWv/MqvDNKwYqQ7qXSXGcxSXfxawYqg+c1zit6yM9OErJbSGrfHM8lzilcKbrQeFMWd7aE9oybQYoXv2anTuD3nOT4B0dXFIPnESVBZ3Q85WJSylBFTOl9qn5XQR4rhkMrL+1zx+rGWmKc1wblrSxSaxxJRm/D1RSL7RlrVuDQWqi/0TKJ7IxYPeMAD2t133719+MMf3r7oRS9qv/3tb/fSsKqTNd1Rpe4F7XppOdnSmhix4LYsKkmphlMcpVgLTmilz8NZU6yuAqnduX7hgk7j68a/e03qFv9uqmAsfScd2+x1MXhS6rxKNR5DrR+sNTOGSF/TjgmvqWy43T1HnmoJY89zeZ8vnb9x0GCpQiutKVNDgc7jfJRa45wS5rG4ODb1T6J7IRYf//jH20svvbT98pe/3H7iE59oDzrooHbvvfdub7/9dvE7d95556wR4bWysjJ88GY8Wa2dL5k0u+T604sIQZdc9dAeazuk80VSa4qVqKSVGeP+k7IqtKDTnLC1CjRtcXN9qRGd8KLn8QTLSuNa6kLKKR2uQqPk87eQKc5d1Qc0slZTgWmErg9hbH2u+H+W+0nX7Xp+Ru6UY64dtRTo0BaLqbldRtqfg2SF/OhHP2p33nnndpMySFzA5+AWi5hZdjH91aqJIaVEcpkWlgwF6RVS/CyKxaJo02CzkEkRg7NckAneqtw4xd1VoGk7SS6OJv6/NSZHmjdSim/Ig9d2spx7LCh8yym2uecP34nvV0MAW4iJdlBeLQWWIxbcRqGrMLakTnoJQV+7+3mfqtpH+iQ39xYhdmckYzlYuumBBx7Yvva1rx2HxSI3WbtWBOxqrYjvF7dTyrQIbpiSQ79ipWBNlYpjT0ruI+2CwiK2muNrM21NsGjpq5JiSoMcpfmXsyzR/8lfHs9X6iNO6VhdOVJ9Ee47gfDFqZ5dBbCFmKSpyd7Ktlbk6mmUpG5b71vTNO4dF6vCq61wSxRtzb6S5l4uVquEHIzNArKyQBaLO+64o33Qgx7UnnvuudUb1gnSZLWa/iTTeS2yEVds4/yvqUI64gh/XEd8rLfFhRObwanvyIdrvZclzoLIkaSon/a0vL/YKwDSz0uEM6d0ubGxCGxPNUs6rpzmgXRyodXak7Ytjb9IY1nSc3A0y04t4Sb1aa2Tha0KQOpTb0XVoWDd3XsVXi2rwbwVrTb3pP+VZmEN7caZpwVoCGLx6le/ur3mmmvab33rW+2nP/3p9pnPfGb7kIc8pP3BD35QvWG9oEuwkmS2fv3rdXO6poi1NnV9pUGb3M5NU+beKpSWQERuB59aa7hD3yxpvbnPh36QrAGxlSFuQ5fF6nH/aCd7WudI2u64D6T5mx5zLilby3Nb1lcfdRhy4MZds0rOW0GU7u5LFV5Xq0FfFhUPcnMvXceewxy995onalvLhiAWhx9++CwjZPvtt2/33HPP2d8333xzLw3rBSULIFQBJEXLxVjEu3VOaUpxGWESWnKjva9056rtRCVFK5EKKebAujuPYznoezkft7TDlZSwZ4xjAactyC6L1XOCqdTmHEFJ3Qkei1s6V6S4HquC4u4bWwRzz+Ld+ZUqKc2KNwYFUYJ5KTzvhq0Py4bVWpY7h6nr+SYLjtuWsqR3DrnSqpz52LLj1NIStToLnh2t9cXtLq0LQTrrI30erg6I51kCobHULbDs1q21L+Zluk1NrqXVYK2FkaTYAasi7VJPgiMmaf/mgpJLzmApGUNPAOwUMC+Fl7tvkKl9HqRlke2eNmvfC8XsxlS/YiCAWOSEEE1CbqceB5VZXAFhMmqBYJI5XVKC1uwT6fhvjjDkioJZ6lDkIvctWSzeLB1LfEisjEr9/H0L4NBfVhdTmnKrZY9Y+os+Zy2s1LV/uGfk2tmlbkWtMdSyU6aIAfzsrvumMrULkewi2z1ttt5HCrReYIBYxChVNhbhr9W3SJWopb5A+I5ELkKKZHDR5BZqurDTRZezUoRFJOW2c30dp9Slh51xhCaNZUmDLtOgw5zSygmMefpILS4jS5BhLNwsz0bjTte0xk6kZMYaZ9FX4aXU5VFzDHv2Sw+OeT1Pel+LTO1K6LsSTGtfLbH7IwaIRQwtxiB3boX0etWr7p1UkrVCS0sM0LIVJAVqNS3mFoPV1UPFtLogt3jD/9OCT1zAYSAfOWWUi5mYh5BIFbuFxOXmpSXGJFzTG1/EVa20EExv/+bmhxS8Ow+r01jqFkwBuZOIa1hUhtokaIR9iXAbiEUEiTmn2QjW4kaBlIRrS7t9awqdJFg50hHv4OmnVqs+l79ttdDMy08rtU87VnpMJuNYEVn7OyVxJbs+7tm8NRs0pWDpq9L+TZW3RiCGNPvPO51yipDS+z/ykelV8JTWIed6XmCAWKTIZV9IO2FuccQpad4dpbbz4d6PFSi9uLbElfzia2h1O7wWmnlFlnetjBhbd7S+rQ3O71tK4tJ0WMv4pPPGU0E0fN8a1yHB27+cD9tyAm7fZn+YwcdtTRiKYPZVUG1CALEgxErWokjTUzO57BCL6VkTxNK1LDsiLe6CuwYVXpI+L1kI3va2fMpgX2PFKb9cvQ0NnKtniN2m5Haw1gWRqmeGI+29Sk4LEtagucokYVrqLpDWEQWcztvl0beCrOFiGaObps8skBRDEczaJeAnBhALbvdjzZ+XfLppYFJYyJZaBaUpqQGay0UiCrn0RCk1MHavDKWQteeje+dOoi3ZcfchjLUaIHE6nGUexs9C341dYGksitYPUnCuZUw9yqGLu0BzvQyZ2jd0PEcNF8sY3TQcKUXWzeSx3MRCCjyLBVScXRBPEClVLmfB0FJEgxDSjkLP7YhylQI9rg0iQuE75O/kBID0vlWYepV2rv3euv6568VKvpYw1shRTGbe9CZZiVrTgLVKnZ70acuYWoRpV+WrEcEaMTWlbegznqMGYRmjm0ba5PRt9RwKQ8zFkWK5iYV2qmFcaCjNedZMv7ESkoiHJLi11EGPxYJrG53pIe1KJWUSvy8pQgvZqbmDyillb13/nMWipkkzEB6JXHoyN6zPkCMI0j1KI9tzwrSGu4Cz/NVWkho5HTqeo0afjbG8NDIoFhYgFtLBXJIC9whxaSGnQXZSEa74M8GMbdkRcYI3Notbi3pZlFSpf1TbQWlCXSIWdC1S2CVEgHP10N+5Muse5FJ2pZ2almZcmgJttXBxfdxVWdbyp8cE0mIZiPsrZ9Hi3KPz3P3XqPw5VotFqXVsiLaNLRZlQlhuYsFNbPpbKyjV9ah0OozMuqshgcZZTUp3hamSKCEXnDBPlZ+lop22W9EsDiX9H9chkRBbqOgnWXiktDFPenDINMn1tbZLS8c7taZJcUGWImGSwqlJqmr601OCYLEMSK4eKROL68s0PmUoH7rUHu4Qvin6/ceYQTHGWJSJYbmJBSd0QlyBxO65HRf9/ZrX8CSFWzSSUIgVkRRIZ6ls2NWqIikluqaUW54GDuYWpNSPpa4e7TlyQsJzTevzWUoUS89Y4gZIAxcDubMoE+4zHOnu6gbqmkVU6jqzBmPngkPjz6V1YroqH2mHXNuF0bff37vTH5slZWztmShALLgdYCgwFU+wUGTK6o8Owt0ipDzVLa0TPY014JQERxzIDRQyK6RsEKtylnb30s7Vunux1GuQ/sf1ndWVoCnadCftGUtPUaiSwEXtfW33X3OH21VBlgp8a/q4dp/0c7WVjzdNfayKrnSnPyZLyhhjUSYIEAstUDK309TSHun7WqBhnL3A7d5zL8m8HywHqY9Yqs6ZW9DWgNG3v11X8FpgatxfViEaFCE3TvQ39Y9WzyNXtZF7BmkcS4pcUdty5cvT8bXupmsqgVo73K4KslTgey0WluDQ2ueP5PplTIq3r/Ht25JixZSI3IixfMSCFBEpwWCC9aZ2ehU/xVRwQiq2KHhjHSTzvlQbIQ6K5A4446pxBuSEqNXSkkulDdcjq5Dn/BEpTkYia5KPPRXeaQl0KY6Bxtfi0vEIKknpW/3/YxSegfCWKsgubdbmqBTbogWH1uw/K0kZi+Jdhp3+FIjcyANSl4tYcEpLq1NfGqeQKq8XvGBbIZUrwqW9JLdGzuqRW+AeZabFm5QU/wo77hKB3ZUYpu6MtLhZ+Jv6QxoPaQ7Ev1szGHJ9kLqBuIyFnPCopQS0e8X/S+NNrMdV1xT4tJ65Z9ZiPDRlLmVteeGd85bxHVCBLOxOf4xEbqXDuA4ckLo8xEIiEFT6WFJM6VHehx6aVyKS8orP6fCkB/6//7daKCkETUoZK5oizS1wizLj4k2k5964Ub9enO0Srkf3KFF4mivLGg9jMafnjovXxpD+f9ppq+OYC1a09IEk9Dzuja5KQLtX+r9cIbkhBH4fO+r0lN1SYW0lTJbxnWdGw6Lu9MeATR3GdQ6kb3mIhRQDwCnBWCHQTkQ7pCkISQp67BIgRtfhzOqp8vUoUusCtxT8sbprwoSVhIzmriHy5M1E0EzsaRs4S5FlgUlkLrzIImUJJo3HUXseaxBs7nvas8V9UdMtYYlXiftpKOVXW7j2cb1czI0l1mneVoMx7vSnjpU5xSd1wPIQC+0ETy77IVYElkAqzQrBTQKt8BHFZ2ixEprSjhWc1eQsTdygzDxZE6kvOnUteLI4cgrPYmJP2+AtrGQhFrFFyuJCywVbxuNoKclNkMaIC/JN+81rxtcElbdYV3iuIco4jynLpY/7LVKcAzD/jKoOWB5ikQsMpE6W3AnkAolBQpA+GzIZtMwOTYBJ7F4TzrmywaU7hpSUxMosVsY5BaEJa4/SySmbksWSq6io3StnsUmzQ3Ivi/uFSIGUQWPpj3QcNYuXZ750sVjkLHI1kIv9GEOWSx/3G4PFAqiPlUquywHdVMtFLAgklM85517hHAshekkCMXxeq+IXZxJ4LAZWRTZE5D4pM+6+8bHUIWtCIlIec66mbDTl62XxVsEsKSTNqiW5oqTS6TmLRe4ZJSWcCg/OraRVlfVAE1RSuibNLS3gt8b8HjLGYOiYgtJiZ8D0sanCuA7oplo+YpETQi98IS/0iIzkdmNpkKYFkjJLYxGG8kVrRb1S03mJkuLcNSXnR3hZvCdtViKFYWFyx3NbSpRrpMD6jLlnDW3UDtirtav1WtwsKcpdzPalO7uchUMLMh06psByP8Q5LCZWpjOuy0ssJCGkpaV5q/jloKV4BvcKKYJQCbPv9DJr4F0gUKS8NJO4xxxdwsg93ykx32skwBI/El/fMo7SM5YoYa09fe9qLQqeK2zW1WJR4ouOCXw63vPMsADGi1rydoGxvMRCE0JSLIbFYuGxVHDCN01ho789JzGWul+0PslZMNJgyFKBXMLIPd+pFXjrvX5XlCphrT19737mYbb3Wiw4l2MI1l7WeAUoTR0gmyYsL7HIle1NYzFyQY5ewaiVZ5beT69fstPWkAsA1EhG2I33IZBrCrtgPYjTNyUrlWXHy12/D4VdqoS7tqdL35ea7bvc09NPmrvIUxGz1I0yNkBp6lhWslmA5SQWkkK2pt3FwrBUcEtKXFNw6SSutdPOCeaUTGkCt1ZwYF/Cjrueds5Jmm48T8TZSIuqaGrc07omNWJhUSKeImFjV9KLpjT7IHVI5zVjOYmFJ+e/T6RKnA6mypEL60mM0oS3LDhpFxkO/eIIEQnp+JTYGgKqtrDzxtWEZxuDcPUqqq6CdR6KRrpnXKWztvWKO+E3XDvnSvLE7IxdSS+S0uyL1E1xXOeE5SQW3ASRDvZKv1ebeNC1KC7CUtkyV2jL8lnvguOeWSrgJLW5dGHXFnaeuJoxCVevQKshWOehaLT02nSu1VIYOdeJZP0oKRI273m0DEqz7+dAOq8Jy0kstFgJaTLmMji8AYfxDkwrGpQGRkrXi9MaJQHpXXDaWQghViFnYaHPlGIoi0Uca1E7U6EGPIqqVp+NxWLhJdql9y0JGl4ki8WiKM0hSF3fgc8LgOUlFvEEycUFSIIirkhp3UFxWRw5xWydxNqE97p/6NlygjyXRWJxI+SIWYmw066Zu94YhatHUdUUrPPoC0s8z1isAFr/jHEeLYPSnCqpWzAsN7GwTsacidY6gaX7SK6EmgvC4/7hfM+cIM/tMHN1IGIXkEbMPMLO4gbIXW+MwtWqqKSg4NKAz3n0hRbPo62PPlyV1rZy9xzjPFoGTJXULRBALAK8gVqSwNNM/1p1xjROwlLwyStEre4fLRVWi/HgSFIu1qMmkcqZp2sVEZtXCqFVUXFxN9QvZIUaqu21+imN55HcfVPLwgD6BUjdXAFiYZ2MliO4LTtvTfGFXVpuQXQRohb3j2SJkA7tsrqUpD6oZdq2lNXuonSmpLy4olqWOVoDtfspXpfcGoX5G1gmrIy/PsogxOL000+f3eSVr3xl9YYNilSoSTtvzfTc1Uw3VHBeat2w1PiwtK2P2hva/envGlaMMSovrf25+Je+2j6PfppiFgYALPDmxqq/1zaFuP7665vzzz+/edzjHtdMHuvXN82v//rqz4CtW+/7OXrviU9smgsvXP178+amufrq1Z/HHts0t9yy+jf9pL89uOmm+95zy5am+exn772H9VkuuKBp1q1b/Zt+nn/+vc8Wt/Pb326ak0/mrxM/W+6ahH33bZq1zHSi99LPesHd/4//mO+vc89tmg0bmuaQQ1Z/hrHy9vvNN+t90heovVr7pX6O237ZZfXb6OmnWuCelcb+kY/s754AMDQ2b26a4467d33Rz+OP71fO9I0S1nLHHXe0++67b3vllVe2T3/606dhsbDuYi2pcaWZI33U4OijmqOWgqu5c1KrTZfzTSymc0vAbGngrRY/0teOIteWMIfJdcXVOOnTLTIvy84YAvYmYKIGJoyrpmOZ69UVcvTRR7cnnnji7PccsbjzzjtnjQivlZWV4YlFrBRI8UhHZ9MAS/EE6auPugjeGhxc++ln11iNLi6GVPn3KZA5IlOyQC3FlIZQqpqASceUiC29r5GM2m2sqeS97qp5BexNxEQNTBgrI3THDk0s3vve97b7779/+5Of/MRELDZu3DhrSPoajFhIFohYSKTCw3I4V18M0xMwGZBrv2eS1gqUHEogW6wYXZXXUDsKqf1cemb8XPR/aa720cauSn4qynpCAh+YODaNwDI3L2Lxne98p91tt93aL3/5yz97b/QWi1xQoXRGRpz+9vznb/s3lzliMbl7du9WoWZx3XgUjDdQskvbp7JAh3werv05YuNJI543pqSsJ2SiBhYAK+NPpe2FWFx++eWzi65bt+5nL/p7zZo1s9/vueeeag2rhpzipTgErTJmWv46pGZ6FFjpDo27R0pQclkCJYI7dck87Wl5ARu3a94CuY8FOuSOIm2/JfbCk0Y8T/Q5N2q73qZEggBgqsTi9ttvb2+44YZtXgceeGB75JFHzn6v2bCq0Ao3aWZmi0DPKbCuwim+B0dQchaGUiUo1fPgnoHz/y+iQJ63r99astyaRjwP9KWs+3KvTMREDQALVSBrUlkhcSXMWEhIwsN7SBS3W6q1Q9MEsmTZKFWCFvcK9aXWrjioEAK5DnJjOgFTai/Kum/LwlT6FQB6hlV/b9csC6gWwllnNc0LX9g0n/pU0zzlKU3zq796b22HQw9dzcmnHPlQcyHk0cf5+1wePdUaCHnI9HmquRDqWFiv0aWOgNR+S+0IypWma1M7w+e5e8Wg53nlK/V2HXjgar2MtE1TB9dfQ4Hul96T2vOZz6z+fvDBq/VYxg5pvpZCWxs1xojrdwAAZLQDY+4WC8vhWLVTET07NMny0ceuTKtXIVksLOetLILbYwrZDHT/OANIOxxukbFMc9AC1N0AegLOComhlegeKhXRYk7NKa4SEzLdj1JX6RXfOyeMuTNUrOetLKJyG5vyovtyadHLqlCXYQ5OkfwCCwUQC2u8QIgVqHn9Ps74KD1qXNrRWgiR516L7oeed6aLtT3zbNO8sehzcGrkF1g49H5WyGSQixc455xuNdkt52jUPIuBO9dEqz9P4iWAfqf36H+Wcxis9/J+dooY27kV1J41a+77vqdNQ5x9MiQWfQ6O8TwXAGCw+MTCcmhT14XX9QCyPhSXRKjovRDUVoMQLQvG1l9033e/e1ty4TnwLXfYGTA9jI38AkuLNWS2GPKGt99+e7PLLrs0t912W7PzzjsPE8H/hS80zWtfu0oiUtDC+9u/XY2on7dSJeFOp9pRO4PiKiEp4dlJYaTkggQPnWoanpU+t2iZG31mcIytv6g9dAIu4aCD7JlA6dyg+UakeAzPBIxDhgBAof5eXGKRpoCeccZqeunnP38vyaD3gzcyTRMtVVbx/wlexVZTccV9QKDdLe1y02ecZwplX9BSgBcBXcaMLGtkqeDen0K6KjAt8gssDMz6u13E4E1LxUwq2e09rMuStRGfompJbe07NSw8K72kjI5FiyJf9CC2rmO26P0DAEAvWO7gzVwQE7H4hzxk28DG9DNSMGS4Lv0kk+P116/u9Ohn/P8gsuPPpkFyQ/i56Vlf8ILVF1dciXumqQfzLXIQW40xG1u8CAAAC4W1SxvE5A10kpTVE5+4Sgzop5Z9kiq2oZS6FvlfQwGPMbPAOrZjbPtQpKlGwDEAAMDSEAvLjsy7a5OyS4JVIheqkiq2IXbVOYtI1yjy9Ppnn51X1EMoc8vYTjUrombk/7KnZ9bEFEkqAPSFdpELZFlPH00/I8U9pCdIcsWJ4hgL7YTRIQ5Oslyfq7BpifnQCo9Jfv+h4zmk8R8qxqBr/IxlHpZWmfS2DWWiZSxinBIAMFjuyptdhKAmJEJ5bAqElI5bp/eDMssRmz7LEHtPZqX34+POcwJSq/zIKeoxBQwOUUWzq7LJfb9LlUlv26A4ZYxpXgNAz1heYtFFCOaOJk+vW2vnWLMMcSBVEvHRjtxOP09/p2eMaJ/XFPWYSmKPxVo0j/Z5rw3FqWNM8xoAesZyZoV0DYiU4h6oABF3XTr6uWsAXE0/dxw38KQnNc1RR9ljSLhnp78PP5yPQUjjGFJ0DZbtE31nRXSNn+kz/sZ77UXOsKmBMc1rABgJFotYdBWCkpCgPYh03bEEwHGk6pJLVkmRhfhopc8lghZnFpx5Zt1g2b7RZ1ZEV2XTp7LyXhuKU8fY5jUAjAHtIrlCuKOkvWZbCl5Mgy6nYA6uYZKNXTsl1yoNlu0T8wo67Oom6zP+xnvtsRxJPuYA0mU/WRVYCty2lDEW2jHh1u/HWR0UzGgRrmMQeDWPb6fg1LETKUu/zzvosKuy6VNZea89b8U577EEAKBdPmLRR8Ac/Z1mNqTC1SLwhiIeNXeWY9mldsmamAI5AvLAWALAKLB8wZt9BMzR3+eee+/faTyFJVh0yEJMNeMGxlyZ0dLvCDpcHGAsAWBSWBxiUSNgjk7/THHOOXJWSU7gzeMsjprBpGMJTC1RNAg6XBxgLAFgUlgcYtE1Ops+9+pX3/d9bWeUE3jYac1P0SBaf3FKYmMsAWBSWEP+kFGe514KEkykuEnJeAUPfZfcFTEZICFGrgDpWuTaICsEEYYg8ILboOR6gA1av9eaD8BwYxkse0QYiURgLAFgdLDq78UjFkMpLKvAK7leH6A2kgWFdvuLIpShaKYPkG8AmAxALMaksOatAK07QgAYGuT+oMBm7n2K7wEAYDQAsQBWgR0hMGZgfgLAZGDV34sTvAnwQAApMGYgMBMAFg7bzbsBwEAZFOmOsDRVbxFjNYD5gtxydKAf4mUAYCEAi8Wio+aOcMhiX8ByYaw1UwAAcAMxFsuCrgGk8IUDAAAsNW436m+4QpYFpPy7EAAtVgPEAgAAAPg/wBUC2ICyygAAAIABIBaADYjeBwAAAGoTi3e9613N4x73uJlvhV4HHXRQ8/d///eeSwBTxphPPO3zrAoAAACgH2Kxfv365owzzmi+8IUvNJ///OebQw45pHnuc5/bfPWrX/VcBpgyFjF6H9kuAAAA48kK2XXXXZuzzjqrOda4e0VWCDAqINsFAABgHFkhW7ZsaS677LLmxz/+8cwlIuGuu+6aveKGzQ1DFXdCEanpANkuAAAA8w3evOGGG5oHPvCBzQ477NCccMIJzeWXX9780i/9kvj5008/fcZwwmuvvfZqFtrcDbP6tIBsFwAAgPm6Qn7605823/nOd2amkA984APNpk2bmk9+8pMiueAsFkQuBnWFDGXuhll9mhjL0fYAAADL6ArZfvvtm0f+327ugAMOaK6//vrm3HPPbc4nYcyALBv0WgpzN8zq0wTOqgAAAKiGzpU3t27duo1FYikO4pr3fYDxVSYFAAAA/DEWr3vd65prr722ueWWW2axFvT3Nddc0xxxxBHNqDFUcScUkQIAAACWHC6LxQ9+8IPm6KOPbm699daZn4WKZV1xxRXNb/zGbzSjx1DmbpjVhwUycAAAAEYFnG4KTDvo8rjjVl1P5IIiaxGCLgEAAOaqv3FWCDBdS0UgFQT6SZkdKMkNAAAwV4BYANOEloEDAAAAzA0gFsA0gcJWAAAAowSIBTBNIAMHAABgMetYAMDcgAwcAACA0QHEApg2UNgKAABgVIArBAAAAACAagCxAAAAAACgGkAsAAAAAACoBhALAAAAAACqAcQCAAAAAIBqALEAAAAAAKAaQCwIdL7E1VdP75yJqbYbAAAAWFiAWNAJmRs2NM0hh6z+pL+ngKm2GwAAAFhoLPex6bTTJ6UcH2ZFpaFvuWXcRZem2m4AAABgssCx6Yt8QuZU2w0AAAAsPJabWEz1hMypthsAAABYeCw3sZjqCZlTbTcAAACw8FjuGIs4ZmGKJ2ROtd0AAADA5GDV3zjddMonZE613QAAAMDCYrldIQAAAAAAVAWIBQAAAAAA1QBiAQAAAABANYBYAAAAAABQDSAWgA6cRwIAAAA4AGIByMB5JAAAAIATIBYAD7JQHHfcvaXD6efxx8NyAQAAAKgAsQB44DwSAAAAoAAgFgAPnEcyPBDPAgDAAgDEAuCB80iGBeJZAABYEOCsEEAHziMZpo+JTMSuJyJyt9yCPgcAYDTAWSFAHeA8kvnGs6DvAQBYZFfI6aef3vzqr/5qs9NOOzW77bZb87znPa+58cYb+2sdACwDEM8CAMCyEotPfvKTzcte9rLmc5/7XHPllVc2d999d/OsZz2r+fGPf9xfCwFg0YF4FgAAFgidYix++MMfziwXRDie9rSnmb6DGAsAEIB4FgAAlj3Ggi5O2HXXXbtcBgAAAuJZAABYABQTi61btzYnnnhi8+QnP7nZf//9xc/ddddds1fMeAAAAAAAWEwU17GgWIuvfOUrzfve975swCeZTsJrr732Kr0lAAAAAACLGGPx8pe/vPnwhz/cXHvttc3DH/5w9bOcxYLIBWIsAAAAAGDJYyyIg7ziFa9oLr/88uaaa67JkgrCDjvsMHsBAAAAALD42M7r/vjbv/3bmbWCall873vfm71PDOb+979/X20EAAAAAGARXSFr1qxh37/ooouaF7/4xaZrIN0UAAAAAKaH3lwhAAAAAAAAEnC6KQAAAAAA1QBiAQAAAABANYBYAAAAAABQDSAWAAAAAABUA4gFAAAAAADVAGIBAAAAAEA1gFgAAAAAAFANIBYAAAAAAFQDiAUAAAAAANUAYgEAAAAAQDWAWAAAAAAAUA0gFgAAAAAAVAOIxdDYvLlprr569ScAAAAALBhALIbEhRc2zYYNTXPIIas/6W8AAAAAWCCAWAwFslAcd1zTbN26+jf9PP54WC4AAACAhQKIxVC46aZ7SUXAli1Nc/PN82oRAAAAAFQHiMVQ2HffplmbdPe6dU3zyEfOq0UAAAAAUB0gFkNh/fqmueCCVTJBoJ/nn7/6PgAAAAAsCLabdwOWCsce2zSHHrrq/iBLBUgFAAAAsGAAsRgaRCZAKAAAAIAFBVwhAAAAAABUA4gFAAAAAADVAGIBAAAAAEA1gFgAAAAAAFANIBYAAAAAAFQDiAUAAAAAANUAYgEAAAAAQDWAWAAAAAAAUA0gFgAAAAAAVAOIBQAAAAAA1QBiAQAAAADAdM8Kadt29vP2228f+tYAAAAAABQi6O2gx0dDLO64447Zz7322mvoWwMAAAAAUEGP77LLLuL/17Q56lEZW7dubb773e82O+20U7NmzZqqTIrIysrKSrPzzjtXuy6wLdDPwwF9PQzQz8MA/Tz9fia6QKRijz32aNauXTseiwU1Zn2Px4ZTR2LS9g/083BAXw8D9PMwQD9Pu581S0UAgjcBAAAAAKgGEAsAAAAAAKphYYjFDjvs0GzcuHH2E+gP6OfhgL4eBujnYYB+Xp5+Hjx4EwAAAACAxcXCWCwAAAAAAJg/QCwAAAAAAKgGEAsAAAAAAKoBxAIAAAAAgOUkFu985zubhz3sYc2OO+7YPPGJT2yuu+469fOXXXZZ8+hHP3r2+V/+5V9uPv7xjw/W1inD08/vfve7m6c+9anNgx70oNnrmc98ZnZcgLL5HPC+971vVrX2ec97Xu9tXNa+/u///u/mZS97WbP77rvPousf9ahHQX700M9/9md/1uy3337N/e9//1m1yFe96lXNnXfeOVh7p4hrr722ec5znjOrfkly4EMf+lD2O9dcc03zhCc8YTaXH/nIRzYXX3xxv41sJ4L3ve997fbbb9/+1V/9VfvVr361/cM//MP253/+59vvf//77Oc//elPt+vWrWvPPPPM9mtf+1r7hje8ob3f/e7X3nDDDYO3fUrw9vOLXvSi9p3vfGf7L//yL+3Xv/719sUvfnG7yy67tJs3bx687YvczwHf+ta32j333LN96lOf2j73uc8drL3L1Nd33XVXe+CBB7aHHXZY+6lPfWrW59dcc037pS99afC2L3I/v+c972l32GGH2U/q4yuuuKLdfffd21e96lWDt31K+PjHP96eeuqp7Qc/+EHK6Gwvv/xy9fPf/OY32wc84AHtH//xH8904Z//+Z/PdOMnPvGJ3to4GWLxa7/2a+3LXvayn/29ZcuWdo899mhPP/109vMvfOEL22c/+9nbvPfEJz6xPf7443tv65Th7ecU99xzT7vTTju1f/3Xf91jK5ezn6lvDz744HbTpk3tMcccA2LRU1+/613vah/xiEe0P/3pTwds5fL1M332kEMO2eY9Un5PfvKTe2/roqAxEIvXvOY17WMf+9ht3jv88MPbQw89tLd2TcIV8tOf/rT5whe+MDOzx2eO0N+f/exn2e/Q+/HnCYceeqj4eaCsn1P87//+b3P33Xc3u+66a48tXc5+fvOb39zstttuzbHHHjtQS5ezr//u7/6uOeigg2aukF/8xV9s9t9//+Ztb3tbs2XLlgFbvvj9fPDBB8++E9wl3/zmN2fupsMOO2ywdi8DPjsHXTj4IWQl+M///M/ZoqZFHoP+/rd/+zf2O9/73vfYz9P7QL1+TnHKKafMfH/pRAa69fOnPvWp5sILL2y+9KUvDdTK5e1rUnBXXXVVc8QRR8wU3c0339y89KUvnRFmqmgI1OnnF73oRbPvPeUpT5mdmnnPPfc0J5xwQvP6179+oFYvB74n6EI6BfUnP/nJLL6lNiZhsQCmgTPOOGMWWHj55ZfPgreAOqBjio866qhZoOxDHvKQeTdn4bF169aZZeiCCy5oDjjggObwww9vTj311OYv//Iv5920hQIFFJIl6Lzzzmu++MUvNh/84Aebj33sY81b3vKWeTcNWAaLBQnTdevWNd///ve3eZ/+fuhDH8p+h973fB4o6+eAs88+e0Ys/vEf/7F53OMe13NLl6ufv/GNbzS33HLLLBI8Vn6E7bbbrrnxxhubffbZZ4CWL8ecpkyQ+93vfrPvBTzmMY+Z7fzI5L/99tv33u5l6Oc3vvGNM8L8B3/wB7O/KXPvxz/+cXPcccfNiBy5UoDukHQhHaneh7WCMImRo4VMO4d/+qd/2kaw0t/kC+VA78efJ1x55ZXi54GyfiaceeaZs13GJz7xiebAAw8cqLXL08+UMn3DDTfM3CDh9du//dvNM57xjNnvlKYH1JvTT37yk2fuj0DeCP/+7/8+IxwgFfX6meKxUvIQyByOsKqHuejCdkKpTJSadPHFF89SZo477rhZKtP3vve92f+POuqo9rWvfe026abbbbdde/bZZ8/SIDdu3Ih00x76+YwzzpilmH3gAx9ob7311p+97rjjjjk+xeL1cwpkhfTX19/5zndmmU0vf/nL2xtvvLH96Ec/2u62227tW9/61jk+xeL1M8lk6uf3vve9s5TIf/iHf2j32WefWUYfIINkK6X304tU+Dve8Y7Z79/+9rdn/6c+pr5O001PPvnkmS6k8gBIN41A+bd77733TJFRatPnPve5n/3v6U9/+kzYxrj00kvbRz3qUbPPU7rNxz72sTm0enrw9POGDRtmkzt9kdAA6s7nGCAW/fb1Zz7zmVl6OilKSj097bTTZum+QL1+vvvuu9s/+ZM/mZGJHXfcsd1rr73al770pe2PfvSjObV+Grj66qtZmRv6ln5SX6ffefzjHz8bF5rPF110Ua9txLHpAAAAAAAsV4wFAAAAAADTAIgFAAAAAADVAGIBAAAAAEA1gFgAAAAAAFANIBYAAAAAAFQDiAUAAAAAANUAYgEAAAAAQDWAWAAAAAAAUA0gFgAAAAAAVAOIBQAAAAAA1QBiAQAAAABANYBYAAAAAADQ1ML/B1ReBFMvTU81AAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Normal Equation"
   ],
   "metadata": {
    "id": "zoFxk-JT78yS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import add_dummy_feature"
   ],
   "metadata": {
    "id": "E5-alQFlK3WT",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.007660Z",
     "start_time": "2025-04-12T19:24:09.899453Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# ساخت نرمال ایکوئشن یا ساخت تتا هت،که از تابع هزینه  MSE ثابت به دست امد \n",
    "Xnew = add_dummy_feature(X)\n",
    "theta_hat = np.linalg.inv(Xnew.T @ Xnew) @ Xnew.T @ \n",
    "\n",
    "#  np.linalg.inv برای اینورس کردن\n",
    "# عبارت دات .T یعنی ترنسپوز\n",
    "# ضرب ماتریسی را به صورت @ میگذارند"
   ],
   "metadata": {
    "id": "AhSu_geZL0Hf",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.020883Z",
     "start_time": "2025-04-12T19:24:17.007660Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2286133673.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mtheta_hat = np.linalg.inv(Xnew.T @ Xnew) @ Xnew.T @\u001B[39m\n                                                        ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "theta_hat"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gg-SU1CQL6su",
    "outputId": "30d85f88-aad4-4b46-cfde-a0f16f9df43e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_test = np.array([[1.5], [2.5],[3.5]])\n",
    "X_test = add_dummy_feature(X_test)\n",
    "X_test @ theta_hat"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tt_ZJbiSMmBw",
    "outputId": "513f114e-1eee-4848-9fc9-6f4f097dcb5b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_test = np.array([[0], [1]])\n",
    "X_test_new = add_dummy_feature(X_test)\n",
    "y_pred = X_test_new @ theta_hat"
   ],
   "metadata": {
    "id": "JTIebnVMN2Zk"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZx5QJjPOXQ9",
    "outputId": "fb43dcfc-5723-4fda-a14c-a0b7687dacde"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(X, y, \"r.\")\n",
    "plt.plot(X_test, y_pred, lw=2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "hwmB447UNFhi",
    "outputId": "3838749e-17fa-49ba-bcf5-6c78e863c584"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # کار بالا را سایکیت لرن به راحتی انجام میده\n",
    " #### البته از روش سریع تری استفاده میکنه"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ],
   "metadata": {
    "id": "j2JoLdi-OC-S",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.029689Z",
     "start_time": "2025-04-12T19:24:17.029689Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "cY3aUyiUOe1i",
    "outputId": "800715a6-ba70-4744-e5dd-c1bd77a5fd71"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.intercept_, lr.coef_\n",
    "# intercept همان عرض از مبدأ است"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uScAvz3SOnYj",
    "outputId": "c57c3694-5e03-4ede-924f-0296b9fa5585",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.033246Z",
     "start_time": "2025-04-12T19:24:17.032231Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.predict(X_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6BjeTz7Oqjd",
    "outputId": "0758b60b-9cca-4835-e93e-740bc6723735",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.034249Z",
     "start_time": "2025-04-12T19:24:17.033246Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "m = Xnew.shape[0]\n",
    "eta = 0.1"
   ],
   "metadata": {
    "id": "pzX7shF_9Tjh"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(40)\n",
    "theta = np.random.randn(2, 1)\n",
    "\n",
    "number_of_epochs = 1000\n",
    "# تعداد ایپاک یعنی تعداد ایترشن و یا تکرار انجام فرمول\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "  grad_ = 2/m * Xnew.T @ (Xnew @ theta - y)\n",
    "  theta = theta - eta*grad_"
   ],
   "metadata": {
    "id": "J9WksvJE9dVC",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.036289Z",
     "start_time": "2025-04-12T19:24:17.035271Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "theta"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kg6hYYwm95of",
    "outputId": "4a1bfa04-9f3f-4d89-d53f-0b90550ed637",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.036289Z",
     "start_time": "2025-04-12T19:24:17.036289Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Stochastic Gradient Descent\n",
    "# دستی\n",
    "\"\"\"\n",
    "- معمولا این روش سریع تر از بچ گرادیانت دیسنت است\n",
    "- بی نظم بودن تابع هزینه را حل میکنه\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "TQlIr5QvJqP8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def learning_rate_schedule(t):\n",
    "  t0, t1 = 2, 40\n",
    "  return t0 / (t + t1)"
   ],
   "metadata": {
    "id": "Ne4i10wlLf2Y"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(40)\n",
    "theta = np.random.randn(2, 1)\n",
    "\n",
    "number_of_epochs = 100\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "  for instance in range(m):\n",
    "    random_index = np.random.randint(m)\n",
    "    x_index = Xnew[random_index : random_index + 1]\n",
    "    y_index = y[random_index : random_index + 1]\n",
    "    grad_ = 2 * x_index.T @ (x_index @ theta - y_index)\n",
    "    eta = learning_rate_schedule(epoch * m + instance)\n",
    "    theta = theta - eta * grad_\n",
    "      \n",
    "# learning_rate_schedule برنام های نرخ یادگیری است که  کمک کنند است تا.."
   ],
   "metadata": {
    "id": "H1nHuvUf-zmD"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "theta"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cF_cyyBNrpB",
    "outputId": "d8c74774-641c-4557-a51e-833c9268862e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Stochastic Gradient Descent\n",
    "# توسط سایکیت لرن"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ],
   "metadata": {
    "id": "IRy47FGGNvKf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sgd = SGDRegressor(max_iter=1000, tol=0.0001, early_stopping=True,\n",
    "             n_iter_no_change=10, random_state=40, penalty=None)\n",
    "\n",
    "# زمانی که early_stopping=True باشه در اینصورت میاد تعدادی از ایترشن ها را در نظر میگره و (این تعداد را با مقداری که در n_iter_no_change دادیم در نظر میگیره) که اگر در این تعداد ایترشن پشت سر هم بهبودی نبینه . و معیار تغییر هم تولارنس tol است. در اینصورت پروسه را متوقف کن\n",
    "# عبارت random_state هم که برای قابل تکرار بودنش هست\n",
    "# عبارت penalty=None\n",
    "# توجه شود که پارشال فیت یه دونه از ایپاک ها رو اجرا میکنه برای زمانی که بخواهیم چیز خاصی را چک کنید و کنترل بیشتری داشته باشیم   "
   ],
   "metadata": {
    "id": "u_9Xu1JNYamS"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sgd.fit(X, y.flatten())\n",
    "# توجه که ایکس باید به صورت ستون باشه که هست میتوایند  با کد X.shape ببینیدش\n",
    "# ولی وای باید یک بردار باشه برای همین فلتش کردیم"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "f8iQAtYxYq_L",
    "outputId": "83c80386-b108-405c-b182-215c372941a6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sgd.coef_\n",
    "# ضریب را با کد coef_ میتونیم ببینیمش"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9412aBRY_JE",
    "outputId": "cb8bfbc7-81d5-44eb-fa35-b9b55877972e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sgd.intercept_\n",
    "# همان عرض از مبدأ را میده"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6vu1fjbZCRJ",
    "outputId": "95b07ac9-19e7-440b-eb47-772bda9ae32a"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Polynomial Regression\n",
    "\"\"\"\n",
    "رگرسیون چند جمله‌ای (Polynomial Regression) یک تکنیک قدرتمند در یادگیری ماشین است که برای مدل‌سازی روابط غیرخطی بین متغیرها استفاده می‌شود. این روش، رگرسیون خطی را با افزودن جملات چند جمله‌ای به مدل گسترش می‌دهد و به آن امکان می‌دهد الگوهای پیچیده‌تر در داده‌ها را ثبت کند.\n",
    "\n",
    "مفهوم رگرسیون چند جمله‌ای:\n",
    "\n",
    "در رگرسیون خطی، فرض می‌کنیم که رابطه بین متغیرهای مستقل و وابسته خطی است. با این حال، در بسیاری از موارد، این فرض صادق نیست و رابطه بین متغیرها می‌تواند غیرخطی باشد. رگرسیون چند جمله‌ای با افزودن جملات چند جمله‌ای (مانند x^2، x^3 و غیره) به مدل، این امکان را فراهم می‌کند که روابط غیرخطی را مدل‌سازی کنیم.\n",
    "\n",
    "مزایای رگرسیون چند جمله‌ای:\n",
    "\n",
    "    انعطاف‌پذیری: رگرسیون چند جمله‌ای می‌تواند طیف گسترده‌ای از الگوهای داده را مدل‌سازی کند.\n",
    "    دقت: در مواردی که رابطه بین متغیرها غیرخطی است، رگرسیون چند جمله‌ای می‌تواند دقت پیش‌بینی بهتری نسبت به رگرسیون خطی ارائه دهد.\n",
    "    تفسیرپذیری: ضرایب مدل رگرسیون چند جمله‌ای قابل تفسیر هستند و می‌توانند اطلاعات مفیدی در مورد رابطه بین متغیرها ارائه دهند.\n",
    "\n",
    "معایب رگرسیون چند جمله‌ای:\n",
    "\n",
    "    بیش‌برازش (Overfitting): افزایش درجه چند جمله‌ای می‌تواند منجر به بیش‌برازش شود، به این معنی که مدل به داده‌های آموزشی بسیار نزدیک می‌شود و عملکرد آن بر روی داده‌های جدید کاهش می‌یابد.\n",
    "    پیچیدگی محاسباتی: با افزایش درجه چند جمله‌ای، پیچیدگی محاسباتی مدل افزایش می‌یابد.\n",
    "    حساسیت به داده‌های پرت: رگرسیون چند جمله‌ای می‌تواند به داده‌های پرت حساس باشد.\n",
    "\n",
    "کاربردهای رگرسیون چند جمله‌ای:\n",
    "\n",
    "    پیش‌بینی روند: رگرسیون چند جمله‌ای می‌تواند برای پیش‌بینی روندهای غیرخطی در داده‌ها، مانند رشد جمعیت یا تغییرات قیمت، استفاده شود.\n",
    "    برازش منحنی: رگرسیون چند جمله‌ای می‌تواند برای برازش منحنی‌های پیچیده به داده‌ها استفاده شود.\n",
    "    مهندسی: رگرسیون چند جمله‌ای در مهندسی برای مدل‌سازی روابط غیرخطی بین متغیرها در فرآیندهای مختلف استفاده می‌شود.\n",
    "    اقتصاد: رگرسیون چند جمله‌ای در اقتصاد برای مدل‌سازی روابط غیرخطی بین متغیرهای اقتصادی استفاده می‌شود.\n",
    "    علوم اجتماعی: رگرسیون چند جمله‌ای در علوم اجتماعی برای مدل‌سازی روابط غیرخطی بین متغیرهای اجتماعی استفاده می‌شود.\n",
    "\n",
    "نکات مهم:\n",
    "\n",
    "    انتخاب درجه مناسب برای چند جمله‌ای بسیار مهم است. درجه بسیار پایین می‌تواند منجر به کم‌برازش شود، در حالی که درجه بسیار بالا می‌تواند منجر به بیش‌برازش شود.\n",
    "    برای جلوگیری از بیش‌برازش، می‌توان از تکنیک‌های منظم‌سازی (regularization) استفاده کرد.\n",
    "    رگرسیون چند جمله‌ای یک ابزار قدرتمند است، اما باید با دقت و با در نظر گرفتن محدودیت‌های آن استفاده شود. \n",
    "\"\"\""
   ],
   "metadata": {
    "id": "dg3ccPTph8z2"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\"\"\"\n",
    "PolynomialFeatures جزئی از\n",
    "   Polynomial Regression است \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(40)\n",
    "m = 1000\n",
    "X = 5 * np.random.rand(m, 1) - 4\n",
    "y = 0.7 * X**2 + X + 3 + np.random.randn(m, 1)"
   ],
   "metadata": {
    "id": "_GJa-XYIZErD"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(X, y, \"r.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "fseb26x3iUEZ",
    "outputId": "aefdaf38-6b6e-4a60-88c3-cfd93bfaba64",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.045987Z",
     "start_time": "2025-04-12T19:24:17.044969Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ],
   "metadata": {
    "id": "L36D3LmDiWXA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "polynomial_X = PolynomialFeatures(degree=2, include_bias=False)\n",
    "#آیا ویژگی ثابت ۱ (bias) رو به عنوان اولین ستون اضافه کنه یا نه؟\n",
    "    # True → ستون اول همیشه 1 هست (برای θ0θ0​)\n",
    "    # False → ستون 1 حذف می‌شه. اغلب در Scikit-learn باید False بذاری چون مدل‌هایش خودشون bias دارن.\n",
    "\n",
    "#interaction_only=True/False\n",
    "# اگر True باشه، فقط ترکیب ضرب دوتایی بین ویژگی‌ها رو می‌ده — بدون توان‌های بالا:\n",
    "\n",
    "#حالت interaction_only=False\n",
    "# خروجی شامل همه‌ی ترکیبات ممکن چندجمله‌ای از ویژگی‌ها می‌شود:\n",
    "# x1, x2, x1^2, x2^2, x1*x2, x1^3, x1^2*x2, x1*x2^2, x2^3, ...\n",
    "\n",
    "# حالت interaction_only=True:\n",
    "# فقط ضرب ویژگی‌های متفاوت (بدون توان‌های تکراری):\n",
    "# x1, x2, x1*x2, x1*x2*x3, ...\n",
    "\n",
    "\n",
    "# 📌هدف اصلی PolynomialFeatures چیه؟\n",
    "#     تبدیل کردن یک مدل خطی ساده به مدلی که بتونه روابط غیرخطی رو مدل کنه\n",
    "        # - بدون اینکه خود مدل غیرخطی بشه\n",
    "        # - فقط با اضافه کردن ویژگی‌های مشتق‌شده\n",
    "        \n",
    "# 📌 در واقع PolynomialFeatures فقط یک مرحله پیش‌پردازش (feature engineering) است. خودش به‌تنهایی هیچ مدل‌سازی انجام نمی‌ده.\n",
    "# یعنی فقط X (ورودی) رو تبدیل می‌کنه — ولی هیچ کاری با y (هدف) و یادگیری پارامترها نمی‌کنه.\n",
    "\n",
    "# پس📌  \"Polynomial Regression\" شامل چه اجزاییه؟\n",
    "# Polynomial Regression = PolynomialFeatures + LinearRegression\n",
    "    #1. PolynomialFeatures:\n",
    "    # ورودی‌ها رو به ویژگی‌های چندجمله‌ای تبدیل می‌کنه\n",
    "    \n",
    "    #2. LinearRegression:\n",
    "    # مدل\tروی اون ویژگی‌های جدید، یک مدل خطی می‌سازه و پارامترها رو یاد می‌گیره\n",
    "    \n",
    "     #3. Pipeline:\n",
    "    # این دوتا رو به هم می‌چسبونه برای راحتی کار. که اختیاری است\n",
    "\n",
    "\n",
    "X_polynomial = polynomial_X.fit_transform(X)"
   ],
   "metadata": {
    "id": "GMFHPje3jhO3",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.048011Z",
     "start_time": "2025-04-12T19:24:17.048011Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\"\"\"\n",
    " هدف اصلی PolynomialFeatures چیه؟\n",
    "    تبدیل کردن یک مدل خطی ساده به مدلی که بتونه روابط غیرخطی رو مدل کنه\n",
    " \n",
    "_____________________\n",
    "   \n",
    "آیا «تبدیل ورودی‌ها به غیرخطی ولی استفاده از مدل خطی» مزیت محسوب میشه؟\n",
    "        ✅ بله، مزیت مهمیه. چون:\n",
    "        \n",
    "        🔹 مزیت ۱: سادگی مدل\n",
    "        \n",
    "            مدل همچنان خطی از نظر پارامترها می‌مونه.\n",
    "        \n",
    "            یعنی حلش سریع و پایدار می‌مونه (convex optimization)\n",
    "        \n",
    "        🔹 مزیت ۲: قابلیت مدل‌سازی روابط غیرخطی\n",
    "        \n",
    "            حتی اگر yy رابطه‌ای غیرخطی با xx داشته باشه، ما اون رابطه رو از طریق چندجمله‌ای‌ها مدل می‌کنیم.\n",
    "        \n",
    "        🔹 مزیت ۳: تحلیل‌پذیر بودن\n",
    "        \n",
    "            چون مدل خطی باقی می‌مونه، فهمیدن تأثیر هر ویژگی (interpretability) ساده‌تره نسبت به مدل‌های غیرخطی پیچیده مثل Neural Networks.\n",
    "\n",
    "_____________________\n",
    "\n",
    "📦 تشبیه شهودی: فرض کن فقط بلدیم با خط‌کش (مدل خطی) کار کنیم، اما داده‌هامون منحنی‌ن. با خم‌کردن محور xها (ویژگی‌سازی غیرخطی)، کاری می‌کنیم که تو فضای جدید، همون منحنی‌ها مثل خط به‌نظر برسن → حالا خط‌کش‌مون (مدل خطی) جواب می‌ده!\n",
    "\n",
    "_____________________  \n",
    "\n",
    "آیا باعث Overfitting میشه؟\n",
    "🔥 بله، اگر حواست نباشه شدیداً مستعد overfittingـه!\n",
    "چرا؟\n",
    "\n",
    "    وقتی degree بزرگ بشه، تعداد ویژگی‌ها خیلی زیاد می‌شن.\n",
    "\n",
    "    برای مثال با 5 ویژگی اولیه و degree=3، تعداد ویژگی‌ها می‌تونه به 35 برسه!\n",
    "    \n",
    "_____________________\n",
    "\n",
    "آیا برای Classification هم کاربرد داره؟\n",
    "✅ بله! اتفاقاً خیلی هم مهمه در بعضی مسائل:\n",
    "\n",
    "    اگر داده‌ها در فضای اصلی خطی جدانشدنی باشن (non-linearly separable)، با چندجمله‌ای کردن ویژگی‌ها می‌تونی فضای داده رو تغییر بدی تا بشه خطی جداسازی کرد.\n",
    "\n",
    " مثلاً مثل کاری که SVM با kernel polynomial انجام می‌ده، ولی با ویژگی‌های واقعی.\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_polynomial.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8r1LC7G2jwiv",
    "outputId": "61d2d835-e057-4b5c-8def-9d81a75042ec"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_polynomial[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7ugrFVzjyN8",
    "outputId": "e2cf330b-0482-46fb-bf4a-38d1b329b6a0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_polynomial, y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "hkllvtQ_j4c1",
    "outputId": "2877e6a6-8a64-4ee9-b1e7-a79e3052bb7d",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.051029Z",
     "start_time": "2025-04-12T19:24:17.051029Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lin_reg.intercept_, lin_reg.coef_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkpzwtmbkFQv",
    "outputId": "4aeac74d-b609-462f-9cb6-df0bd9302e3e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_new = np.linspace(-4, 1, 1000).reshape(1000, 1)\n",
    "X_new_polynomial = polynomial_X.transform(X_new)\n",
    "y_new = lin_reg.predict(X_new_polynomial)"
   ],
   "metadata": {
    "id": "aARakPVKkq5Z",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.052547Z",
     "start_time": "2025-04-12T19:24:17.052547Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(X, y, \"r.\")\n",
    "plt.plot(X_new, y_new, \"b-\", lw=2.5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "3lkPS0-JkJh8",
    "outputId": "e8fe600a-05f5-4ff5-8e0c-222928c925b6",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.053558Z",
     "start_time": "2025-04-12T19:24:17.053558Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ------------"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import learning_curve"
   ],
   "metadata": {
    "id": "mgJexM3QklB1",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.054598Z",
     "start_time": "2025-04-12T19:24:17.054598Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_size, train_score, validation_score = learning_curve(\n",
    "    LinearRegression(), X, y,\n",
    "    train_sizes=np.linspace(0.01, 1.0, 100), \n",
    "    cv = 5,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")"
   ],
   "metadata": {
    "id": "zXNKOtj1qkHZ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_error = -train_score.mean(axis=1)\n",
    "validation_error = -validation_score.mean(axis=1)"
   ],
   "metadata": {
    "id": "F7RQbyH6rcDJ",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.056618Z",
     "start_time": "2025-04-12T19:24:17.056618Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(train_size, train_error, \"b-\", lw=2.5, label=\"train\")\n",
    "plt.plot(train_size, validation_error, \"r-\", lw=2.5, label=\"validation\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "TslO0gBTrk_G",
    "outputId": "012f437f-7917-4baa-d1a4-8bcdb31171c5",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.057626Z",
     "start_time": "2025-04-12T19:24:17.056618Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "polynomial_reg = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "train_size, train_score, validation_score = learning_curve(\n",
    "    polynomial_reg, X, y,\n",
    "    train_sizes=np.linspace(0.01, 1.0, 100), \n",
    "    cv = 5,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")"
   ],
   "metadata": {
    "id": "6JNxXuJNsK8T",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.058636Z",
     "start_time": "2025-04-12T19:24:17.057626Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_error = -train_score.mean(axis=1)\n",
    "validation_error = -validation_score.mean(axis=1)"
   ],
   "metadata": {
    "id": "f5FZzgCitx6I"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(train_size, train_error, \"b-\", lw=2.5, label=\"train\")\n",
    "plt.plot(train_size, validation_error, \"r-\", lw=2.5, label=\"validation\")\n",
    "plt.axis([0, 800, 0, 2])\n",
    "plt.legend()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "wqIDoTb0t1hh",
    "outputId": "7e270f95-0d69-493f-d8e5-3d5f674f8a32"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\"\"\"\n",
    "در یادگیری ماشین، هدف ساخت مدلی است که بتواند به خوبی داده‌های جدید را پیش‌بینی کند. خطای پیش‌بینی مدل از سه جزء تشکیل شده است: بایاس (Bias)، واریانس (Variance) و خطای کاهش‌ناپذیر (Irreducible Error).\n",
    "\n",
    "    بایاس (Bias):\n",
    "        بایاس به خطای ناشی از ساده‌سازی بیش از حد مدل اشاره دارد.\n",
    "        مدل با بایاس بالا، فرضیات ساده‌ای را در مورد داده‌ها در نظر می‌گیرد و نمی‌تواند الگوهای پیچیده را به خوبی یاد بگیرد.\n",
    "        مدل‌های با بایاس بالا معمولاً دچار کم‌برازش (Underfitting) می‌شوند.\n",
    "        به زبان ساده تر یعنی مدل ما به اندازه کافی خوب نیست که بتواند الگو هارا یاد بگیرد.\n",
    "    واریانس (Variance):\n",
    "        واریانس به خطای ناشی از حساسیت بیش از حد مدل به نوسانات داده‌های آموزشی اشاره دارد.\n",
    "        مدل با واریانس بالا، الگوهای تصادفی و نویز موجود در داده‌های آموزشی را نیز یاد می‌گیرد و نمی‌تواند به خوبی به داده‌های جدید تعمیم پیدا کند.\n",
    "        مدل‌های با واریانس بالا معمولاً دچار بیش‌برازش (Overfitting) می‌شوند.\n",
    "        به زبان ساده تر یعنی مدل ما داده های اموزش را خیلی خوب یادگرفته و در داده های جدید عملکرد خوبی ندارد.\n",
    "    خطای کاهش‌ناپذیر (Irreducible Error):\n",
    "        این خطا ناشی از نویز و عدم قطعیت ذاتی در داده‌ها است و نمی‌توان آن را با بهبود مدل کاهش داد.\n",
    "        این خطا یک حد پایین برای خطای پیش‌بینی مدل تعیین می‌کند.\n",
    "        یعنی حتی بهترین مدل هم این خطا را دارد.\n",
    "\n",
    "موازنه بایاس-واریانس (Bias-Variance Tradeoff):\n",
    "\n",
    "    هدف در یادگیری ماشین، یافتن موازنه مناسب بین بایاس و واریانس است.\n",
    "    کاهش بایاس معمولاً منجر به افزایش واریانس و بالعکس می‌شود.\n",
    "    انتخاب مدل مناسب، به پیچیدگی داده‌ها و هدف مسئله بستگی دارد.\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\"\"\"\n",
    "\n",
    "نرم در ریاضی چیست؟\n",
    "\n",
    "    نرم (Norm) مفهومی در ریاضیات است که به عنوان تابعی برای سنجش «اندازه» یا «طول» بردارها در فضاهای برداری تعریف می‌شود. به بیان ساده، نرم یک بردار، مقدار مثبتی است که نشان‌دهنده فاصله آن بردار از مبدأ مختصات است.\n",
    "    \n",
    "\n",
    "_______________\n",
    "\n",
    "L در نرم به انواع مختلف نرم‌ها اشاره دارد، مانند:\n",
    "\n",
    "    نرم L1: مجموع قدر مطلق مقادیر بردار.\n",
    "    نرم L2: ریشه دوم مجموع مربعات مقادیر بردار (نرم اقلیدسی).\n",
    "\n",
    "این نمادها برای تمایز بین انواع مختلف نرم‌ها استفاده می‌شوند، زیرا هر کدام ویژگی‌ها و کاربردهای متفاوتی دارند. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\"\n",
    "---\n",
    "# Ridge\n",
    "Ridge در سایکیت‌لِرن (Scikit-learn):\n",
    "\n",
    "    رگرسیون Ridge یک روش بهینه‌سازی است که برای بهبود عملکرد مدل‌های رگرسیون خطی در شرایط خاص استفاده می‌شود. \n",
    "    Ridge یک مدل رگرسیون خطی است که از روش تنظیم L2 برای جلوگیری از بیش‌برازش (overfitting) استفاده می‌کند.\n",
    "\n",
    "_____________________    \n",
    "\n",
    "ویژگی‌های کلیدی Ridge:\n",
    "\n",
    "        تنظیم L2: Ridge با افزودن یک عبارت جریمه به تابع زیان رگرسیون خطی، ضرایب مدل را کوچک می‌کند. این کار از بزرگ شدن بیش از حد ضرایب و در نتیجه، از بیش‌برازش جلوگیری می‌کند.\n",
    "        \n",
    "_____________________\n",
    "\n",
    "پارامتر آلفا (alpha):\n",
    "\n",
    "     پارامتر آلفا، قدرت تنظیم L2 را کنترل می‌کند. هر چه آلفا بزرگ‌تر باشد، تنظیم قوی‌تر است و ضرایب کوچک‌تر می‌شوند.\n",
    "\n",
    "fit_intercept:\n",
    "\n",
    "    این پارامتر یک مقدار بولی (True یا False) می‌گیرد.\n",
    "    اگر مقدار آن True باشد (مقدار پیش‌فرض)، یک عرض از مبدأ (intercept) برای مدل محاسبه می‌شود.\n",
    "    اگر مقدار آن False باشد، عرض از مبدأ محاسبه نمی‌شود و مدل از مبدأ مختصات عبور می‌کند.\n",
    "\n",
    "normalize:\n",
    "\n",
    "    این پارامتر نیز یک مقدار بولی می‌گیرد.\n",
    "    اگر مقدار آن True باشد، ویژگی‌های ورودی قبل از آموزش مدل نرمال‌سازی می‌شوند.\n",
    "    نرمال سازی به این معنی هست که همه ویژگی ها در یک مقیاس یکسان قرار بگیرند.\n",
    "\n",
    "solver:\n",
    "\n",
    "    این پارامتر الگوریتم حل مسئله بهینه‌سازی را مشخص می‌کند.\n",
    "    مقادیر مختلفی را می‌تواند بپذیرد، مانند 'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', و 'saga'.\n",
    "    انتخاب الگوریتم مناسب به اندازه داده‌ها و ویژگی‌های آن‌ها بستگی دارد.\n",
    "\n",
    "random_state:\n",
    "\n",
    "    این پارامتر برای کنترل تصادفی بودن الگوریتم‌هایی است که از اعداد تصادفی استفاده می‌کنند.\n",
    "    با تعیین یک مقدار ثابت برای این پارامتر، می‌توان نتایج را قابل تکرار کرد.\n",
    "        \n",
    "_____________________\n",
    "\n",
    "        کاربردها: Ridge برای داده‌هایی که دارای همبستگی بالا بین ویژگی‌ها هستند، مناسب است. همچنین، در مواردی که تعداد ویژگی‌ها بیشتر از تعداد نمونه‌ها است، می‌تواند مفید باشد.\n",
    "        \n",
    "_____________________\n",
    "        مزایا: جلوگیری از بیش‌برازش، پایداری مدل، عملکرد خوب در داده‌های همبسته.\n",
    "        \n",
    "\n",
    "        معایب: ممکن است دقت مدل را در مقایسه با رگرسیون خطی ساده، کاهش دهد.\n",
    "        \n",
    "\"\"\""
   ],
   "metadata": {
    "id": "mpkTQ3ty8ln8"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# تابع هدف رگرسیون Ridge\n",
    "#  یا فرمول کمینه‌سازی Ridge\n",
    "\"\"\"\n",
    "||y - Xw||^2_2 + alpha * ||w||^2_2\n",
    "علامت دو خط عمودی پشت سر هم، نشان‌دهنده «نرم» (norm) یک بردار است.\n",
    "||...||^2_2: نرم L2 (اقلیدسی) خطاهای پیش‌بینی، که به توان دو رسیده است.\n",
    "||w||^2 در واقع نرم L2 (اقلیدسی) یک بردار، طول آن بردار را نشان می‌دهد\n",
    "\n",
    "این فرمول شامل دو بخش است:\n",
    "\n",
    "    بخش اول (||y - Xw||^2_2): این بخش، خطای مربعات میانگین (MSE) را نشان می‌دهد و هدف آن کمینه‌سازی خطای پیش‌بینی مدل است.\n",
    "    بخش دوم (alpha * ||w||^2_2): این بخش، عبارت تنظیم L2 (Ridge) است و هدف آن جلوگیری از بیش‌برازش مدل با کوچک کردن ضرایب است.\n",
    "\n",
    "در واقع، رگرسیون Ridge با اضافه کردن عبارت تنظیم L2 به تابع هدف رگرسیون خطی ساده، سعی می‌کند موازنه مناسبی بین خطای پیش‌بینی و پیچیدگی مدل ایجاد کند.\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# کاربردهای اصلی رگرسیون Ridge:\n",
    "\n",
    "کاهش بیش‌برازش:\n",
    "\n",
    "        وقتی مدل‌های رگرسیون خطی با تعداد زیادی متغیر مواجه می‌شوند، ممکن است به جای یادگیری الگوهای کلی، نویز موجود در داده‌های آموزشی را نیز یاد بگیرند. این موضوع منجر به بیش‌برازش می‌شود، یعنی مدل روی داده‌های آموزشی عملکرد بسیار خوبی دارد، اما روی داده‌های جدید عملکرد ضعیفی ارائه می‌دهد.\n",
    "        رگرسیون Ridge با اضافه کردن یک عبارت جریمه (penalty) به تابع هزینه، ضرایب مدل را کوچک می‌کند و از بیش‌برازش جلوگیری می‌کند.\n",
    "        \n",
    "\n",
    "حل مشکل هم‌خطی چندگانه:\n",
    "\n",
    "        هم‌خطی چندگانه زمانی رخ می‌دهد که بین متغیرهای مستقل در داده‌ها همبستگی بالایی وجود داشته باشد. این موضوع می‌تواند باعث ناپایدار شدن ضرایب مدل رگرسیون خطی شود.\n",
    "        رگرسیون Ridge با کوچک کردن ضرایب، تأثیر هم‌خطی چندگانه را کاهش می‌دهد و مدل را پایدارتر می‌کند.\n",
    "\n",
    "\n",
    "\n",
    "مسائل با تعداد متغیرهای زیاد:\n",
    "\n",
    "        در مسائلی که تعداد متغیرهای مستقل بیشتر از تعداد نمونه‌ها است، رگرسیون خطی معمولی نمی‌تواند ضرایب مدل را به طور منحصر به فرد تخمین بزند.\n",
    "        رگرسیون Ridge در این شرایط می‌تواند ضرایب مدل را تخمین بزند و مدل را پایدار کند.\n",
    "        \n",
    "\n",
    "\n",
    "پیش‌بینی‌های پایدار:\n",
    "\n",
    "        رگرسیون Ridge به دلیل کوچک کردن ضرایب مدل، پیش‌بینی‌های پایدارتری را ارائه می‌دهد. این موضوع در مواردی که داده‌ها دارای نویز هستند، اهمیت زیادی دارد."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import Ridge"
   ],
   "metadata": {
    "id": "Z2GhJu-28oaV",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.061192Z",
     "start_time": "2025-04-12T19:24:17.061192Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3waBLCWSBINs",
    "outputId": "533f4f45-b6ce-4af7-f948-66ba2253d120",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.062221Z",
     "start_time": "2025-04-12T19:24:17.062221Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "ridge_regression = Ridge(alpha=0.1)\n",
    "ridge_regression.fit(X, y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "bOELTUdrAwwO",
    "outputId": "631660fd-5eec-4dd1-beb1-8b82244ceb18"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\"\"\"\n",
    " 1. مدل Lasso چیست؟\n",
    "\n",
    "    رگرسیون Lasso (Least Absolute Shrinkage and Selection Operator) یک روش تنظیم (Regularization) در رگرسیون خطی است که برای جلوگیری از بیش‌برازش (Overfitting) و انتخاب ویژگی‌های مهم (Feature Selection) استفاده می‌شود.\n",
    "    Lasso با اضافه کردن یک عبارت جریمه L1 به تابع هزینه (Loss Function)، ضرایب مدل را کوچک می‌کند و برخی از آن‌ها را به صفر می‌رساند. این ویژگی باعث می‌شود که Lasso بتواند ویژگی‌های غیرضروری را حذف کند و مدل را ساده‌تر کند.\n",
    "\n",
    "\n",
    "2. فرق Ridge با Lasso:\n",
    "\n",
    "        نوع تنظیم:\n",
    "        Ridge از تنظیم L2 استفاده می‌کند، که ضرایب را کوچک می‌کند اما آن‌ها را به صفر نمی‌رساند.\n",
    "        Lasso از تنظیم L1 استفاده می‌کند، که ضرایب را کوچک می‌کند و برخی از آن‌ها را به صفر می‌رساند.\n",
    "        \n",
    "        انتخاب ویژگی:\n",
    "            Ridge نمی‌تواند ویژگی‌ها را حذف کند.\n",
    "            Lasso می‌تواند ویژگی‌های غیرضروری را حذف کند و مدل را ساده‌تر کند.\n",
    "    \n",
    "        کاربرد:\n",
    "            Ridge برای کاهش بیش‌برازش در شرایطی که تعداد زیادی ویژگی همبسته وجود دارد، مناسب است.\n",
    "            Lasso برای انتخاب ویژگی‌های مهم و ساده‌سازی مدل در شرایطی که تعداد زیادی ویژگی غیرضروری وجود دارد، مناسب است.\n",
    "\n",
    "3. فرق کاربردشان چیست؟\n",
    "\n",
    "        Ridge:\n",
    "            زمانی که تمام متغیرها به نوعی در پیش بینی ها تاثیرگذار هستند کاربرد دارد.\n",
    "            زمانی که هم خطی چندگانه وجود دارد کاربرد دارد.\n",
    "        Lasso:\n",
    "            زمانی که تعداد زیادی متغیر غیرضروری وجود دارد کاربرد دارد.\n",
    "            برای ساده سازی مدل و کاهش پیچیدگی مدل کاربرد دارد.\n",
    "            برای انتخاب ویژگی های مهم و حذف ویژگی های غیرضروری کاربرد دارد.\n",
    "\n",
    "4. فرمول Lasso \n",
    "\n",
    "||y - Xw||^2_2 + alpha * ||w||_1\n",
    "\n",
    "    در این فرمول:\n",
    "        ||y - Xw||^2_2 مجموع مربعات خطا (MSE) را نشان می‌دهد.\n",
    "        alpha * ||w||_1 عبارت جریمه L1 است.\n",
    "        ||w||_1 نرم L1 بردار ضرایب (w) را نشان می‌دهد.\n",
    "\"\"\"        "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Elastic Net \n",
    "\"\"\"\n",
    " Elastic Net چیست و چیزهای لازم را بگو؟\n",
    "\n",
    "    Elastic Net یک روش تنظیم (Regularization) در رگرسیون خطی است که ترکیبی از تنظیم L1 (Lasso) و تنظیم L2 (Ridge) است.\n",
    "    این روش با اضافه کردن یک عبارت جریمه ترکیبی از L1 و L2 به تابع هزینه (Loss Function)، ضرایب مدل را کوچک می‌کند و برخی از آن‌ها را به صفر می‌رساند.\n",
    "    Elastic Net مزایای هر دو روش Lasso و Ridge را ترکیب می‌کند و می‌تواند مشکلاتی مانند هم‌خطی چندگانه (Multicollinearity) و وجود ویژگی‌های غیرضروری را به طور همزمان حل کند.\n",
    "    پارامتر l1_ratio در Elastic Net، موازنه بین تنظیم L1 و L2 را کنترل می‌کند.\n",
    "        اگر l1_ratio برابر با 1 باشد، Elastic Net معادل Lasso است.\n",
    "        اگر l1_ratio برابر با 0 باشد، Elastic Net معادل Ridge است.\n",
    "        مقادیر بین 0 و 1، ترکیبی از تنظیم L1 و L2 را اعمال می‌کنند.\n",
    "        \n",
    "Elastic Net در شرایطی که تعداد زیادی ویژگی همبسته و غیرضروری وجود دارد، عملکرد خوبی ارائه می‌دهد.\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# بهینه سازی ها در رگرشن و کلسیفیکشن\n",
    "\"\"\"\n",
    "SGD (گرادیان کاهشی تصادفی):\n",
    "\n",
    "    هم برای رگرسیون و هم برای طبقه‌بندی قابل استفاده است.\n",
    "    برای کمینه‌سازی تابع هزینه مدل‌های یادگیری ماشین استفاده می‌شود.\n",
    "    در طبقه‌بندی، معمولاً با توابع فعال‌سازی مانند سیگموئید یا سافتمکس ترکیب می‌شود.\n",
    "\n",
    "گرادیان کاهشی معمولی (Gradient Descent):\n",
    "\n",
    "    هم برای رگرسیون و هم برای طبقه بندی استفاده میشود.\n",
    "    روش پایه برای بهینه سازی مدل است که اس جی دی هم از ان گرفته شده است.\n",
    "\n",
    "آدام (Adam):\n",
    "\n",
    "    هم برای رگرسیون و هم برای طبقه بندی استفاده میشود.\n",
    "    یک الگوریتم بهینه سازی تطبیقی است که به طور گسترده در یادگیری عمیق استفاده میشود.\n",
    "\n",
    "RMSprop:\n",
    "\n",
    "    هم برای رگرسیون و هم برای طبقه بندی استفاده میشود.\n",
    "    یک الگوریتم بهینه سازی تطبیقی است که برای حل مشکلات نرخ یادگیری در اس جی دی طراحی شده است.\n",
    "\n",
    "Ridge:\n",
    "\n",
    "    هم برای رگرسیون و هم برای طبقه‌بندی قابل استفاده است.\n",
    "    با اضافه کردن تنظیم L2 به تابع هزینه، از بیش‌برازش جلوگیری می‌کند.\n",
    "    برای طبقه‌بندی، معمولاً با رگرسیون لجستیک Ridge ترکیب می‌شود.\n",
    "\n",
    "Lasso:\n",
    "\n",
    "    هم برای رگرسیون و هم برای طبقه‌بندی قابل استفاده است.\n",
    "    با اضافه کردن تنظیم L1 به تابع هزینه، از بیش‌برازش جلوگیری می‌کند و انتخاب ویژگی را انجام می‌دهد.\n",
    "    برای طبقه‌بندی، معمولاً با رگرسیون لجستیک Lasso ترکیب می‌شود.\n",
    "\n",
    "Elastic Net:\n",
    "\n",
    "    هم برای رگرسیون و هم برای طبقه‌بندی قابل استفاده است.\n",
    "    ترکیبی از تنظیم L1 و L2 است و مزایای هر دو روش را ارائه می‌دهد.\n",
    "    برای طبقه‌بندی، معمولاً با رگرسیون لجستیک Elastic Net ترکیب می‌شود.\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "دیتاست آیریس (Iris dataset) یک مجموعه داده چند متغیره است که توسط رونالد فیشر، آماردان و گیاه‌شناس بریتانیایی، در سال 1936 معرفی شد. این مجموعه داده به دلیل سادگی و کاربرد فراوانش، به یکی از محبوب‌ترین مجموعه‌های داده در حوزه یادگیری ماشین و آمار تبدیل شده است.\n",
    "\n",
    "ویژگی‌های اصلی دیتاست آیریس:\n",
    "\n",
    "    محتوا: این مجموعه داده شامل 150 نمونه از گل‌های زنبق است که به سه گونه مختلف تقسیم می‌شوند:\n",
    "        Setosa (سِتوسا)\n",
    "        Versicolor (وِرسی‌کالِر)\n",
    "        Virginica (ویرجینیکا)\n",
    "    ویژگی‌ها: برای هر نمونه گل، چهار ویژگی اندازه‌گیری شده است:\n",
    "        طول کاسبرگ (Sepal Length)\n",
    "        عرض کاسبرگ (Sepal Width)\n",
    "        طول گلبرگ (Petal Length)\n",
    "        عرض گلبرگ (Petal Width)\n",
    "    کاربرد: از این مجموعه داده به طور گسترده برای آموزش و آزمایش الگوریتم‌های طبقه‌بندی در یادگیری ماشین استفاده می‌شود.\n",
    "    سادگی: دیتاست آیریس به دلیل تعداد کم ویژگی‌ها و نمونه‌ها، برای شروع کار با الگوریتم‌های یادگیری ماشین بسیار مناسب است.\n",
    "\n",
    "کاربردهای رایج دیتاست آیریس:\n",
    "\n",
    "    آموزش الگوریتم‌های طبقه‌بندی مانند k-نزدیک‌ترین همسایه (k-NN)، ماشین بردار پشتیبان (SVM) و درخت تصمیم (Decision Tree)\n",
    "    ارزیابی عملکرد الگوریتم‌های طبقه‌بندی\n",
    "    آشنایی با مفاهیم پایه‌ای یادگیری ماشین و داده‌کاوی"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Logistic regression\n",
    "\"\"\"\n",
    "در نامش رگرشن امده اما برای کلسیفیکشن استفاده میشه \n",
    "یعنی برای گسسته است نه پیوسته\n",
    "\n",
    "تخمین احتمال است\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "iIJq6_AEhsUp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_iris"
   ],
   "metadata": {
    "id": "bIJb9JybBOQ3",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.064243Z",
     "start_time": "2025-04-12T19:24:17.063233Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "iris_df = load_iris(as_frame=True)\n",
    "# چون میخواهیم به صورت دیتا فریم برگرداند as_frame=True را قرار دادیم"
   ],
   "metadata": {
    "id": "za4Q4B3gh42B"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "list(iris_df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84r_pcxfiCuK",
    "outputId": "d5c30bd8-32e5-44ef-d348-bb4d900e4f4c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "iris_df.target_names"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqQ1emKgiGe1",
    "outputId": "41c46b45-b9a8-4bb7-c547-2406de695c84"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X = iris_df.data[[\"petal length (cm)\"]].values\n",
    "y = iris_df.target_names\n",
    "\n",
    "#iris_df.data:\n",
    "    # این متد به بخش ویژگی‌های ورودی (features) دیتاست آیریس دسترسی پیدا می‌کند.\n",
    "    \n",
    "    \n",
    "# iris_df.target:\n",
    "#     این متد به بخش متغیر هدف (target variable) دیتاست آیریس دسترسی پیدا می‌کند.\n",
    "#     متغیر هدف، گونه گل زنبق را برای هر نمونه مشخص می‌کن"
   ],
   "metadata": {
    "id": "0J1YT-GriYOT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y = iris_df.target_names[iris_df.target] == \"setosa\"\n",
    "y.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6HtfAHBirCI",
    "outputId": "97e87a88-c7ef-44d6-8c26-f5eabd92449d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "id": "kaszN0MzjZgb"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40)"
   ],
   "metadata": {
    "id": "D7pBJ23NiycT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "id": "w4T9eAdhjgg3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(random_state=40)"
   ],
   "metadata": {
    "id": "s8OMdIQnjn-H"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.fit(X_train, y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "0NlrEIwPjwsq",
    "outputId": "a38de775-9460-43ec-9b53-62f04d443c35"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "iris_df.data[\"petal length (cm)\"].max()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4G6zGM0jzKA",
    "outputId": "33e8baec-21d3-4d04-a601-205e31d28070"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "iris_df.data[\"petal width (cm)\"].min()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7p9dmWTOTrQb",
    "outputId": "533dc345-0bbc-41fc-b6a3-cb1341ba363d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_pred = np.linspace(0, 7, 1000).reshape(-1, 1)\n",
    "y_prob = lr.predict_proba(X_pred)"
   ],
   "metadata": {
    "id": "lZe6Vyhcj_8z"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_prob"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "px28xpT2CAy0",
    "outputId": "676ea26c-100b-421b-999f-40923beb75e0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.classes_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BaavYZ0BDh5A",
    "outputId": "e5b50a17-a041-461f-8c7e-631929a5281e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "db = X_pred[y_prob[:, 0] >= 0.5][0, 0]\n",
    "#مرز تصمیم"
   ],
   "metadata": {
    "id": "lcKRzzZvCCKE"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "db"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vp3QATmEwUj",
    "outputId": "155cc1e9-baa0-437f-b591-b221a2a39c37"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(X_pred, y_prob[:, 0], \"--r\", lw=2, label=\"Not Setosa\")\n",
    "plt.plot(X_pred, y_prob[:, 1], \"--b\", lw=2, label=\"Setosa\")\n",
    "plt.plot([db, db], [0, 1], \"k:\", lw=2, label=\"db\")\n",
    "plt.xlabel(\"petal length (cm)\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "t7KkXMx3DDME",
    "outputId": "5786943c-e3b6-4742-8c5d-215a244596fc"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.predict([[2.5], [2.8], [3.5]])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZLd024XELwR",
    "outputId": "155dcc6d-2da1-4a59-f88a-d3667e112407"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\"\"\"حالا کار قبل را که با یک فیچر بود را میخواهیم با دوتا فیچر انجام دهیم\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X = iris_df.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = iris_df.target_names[iris_df.target] == \"setosa\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40)"
   ],
   "metadata": {
    "id": "ncBvii4kFYKF",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.081990Z",
     "start_time": "2025-04-12T19:24:17.081990Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(random_state=40)\n",
    "lr.fit(X, y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "bCb0ew9QSv4u",
    "outputId": "0a025a84-554e-44d1-df24-060f81ebc07d",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.083004Z",
     "start_time": "2025-04-12T19:24:17.083004Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "petal_length, petal_width = np.meshgrid(\n",
    "    np.linspace(0, 7, 1000).reshape(-1, 1),\n",
    "    np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    ")"
   ],
   "metadata": {
    "id": "lV1vEbsASw4r",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.084043Z",
     "start_time": "2025-04-12T19:24:17.084043Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "petal_length.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnYnd_wBPkIr",
    "outputId": "5863bb12-7aee-4893-ee21-18a66788ed38",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.085057Z",
     "start_time": "2025-04-12T19:24:17.085057Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "petal_length.flatten().shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkr6qSy7UFdY",
    "outputId": "653a5a67-b810-473b-bcfc-4855d047c197"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_pred = np.c_[petal_length.flatten(), petal_width.flatten()]"
   ],
   "metadata": {
    "id": "M80BHu6eT-bF"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_pred.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2R1d7z2tUNig",
    "outputId": "1cbd6281-4de5-4961-df5b-eb05d3d2a24b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_prob = lr.predict_proba(X_pred)"
   ],
   "metadata": {
    "id": "5Yb---nrUP8O"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_prob.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9KIfKsEkgZj",
    "outputId": "72470e54-2b1d-42d1-e123-d1f949a8a6e9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_prob_2d = y_prob[:, 1].reshape(petal_length.shape)"
   ],
   "metadata": {
    "id": "pvTKdq0DPWhG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib as mpl"
   ],
   "metadata": {
    "id": "LWNqvdA_UQmN"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.classes_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EVgdyluUbDf",
    "outputId": "9d22b88f-8356-4989-aa58-9e2648055d12"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_pred[y_prob[:, 0] >= 0.5]"
   ],
   "metadata": {
    "id": "8cCrzDY9UjVV",
    "outputId": "09b8fa71-3ab6-4909-e825-0f10468681e3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.coef_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPEFVs0cnCe7",
    "outputId": "13015d75-1b68-48c2-d236-8d0e7fe5d37b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.intercept_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjHkrIytZbvj",
    "outputId": "c801cc4f-ccf1-4448-a6d3-adce6353dff6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "petal_length_vector = np.array([0, 7])\n",
    "db = -((lr.intercept_ + lr.coef_[0, 0]*petal_length_vector)/lr.coef_[0, 1])\n",
    "\n",
    "# در خط قبلی معادله خطی که مدل رگرسیون لجستیک برای طبقه‌بندی استفاده می‌کند به صورت زیر است:\n",
    "# که اورده اونطرف تساوی برای همین منفی شده\n",
    "# z = lr.intercept_ + lr.coef_[0, 0] * petal_length + lr.coef_[0, 1] * petal_width"
   ],
   "metadata": {
    "id": "KinlnavKZWXt"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "db"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORc2fMVpaFYP",
    "outputId": "4bff710f-6ac1-40bd-b5e2-3144f2e63b83",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.096741Z",
     "start_time": "2025-04-12T19:24:17.096741Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.097752Z",
     "start_time": "2025-04-12T19:24:17.097752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax1 = ax.contour(petal_length,\n",
    "                 petal_width,\n",
    "                 y_prob[:, 1].reshape(petal_length.shape),\n",
    "                 )\n",
    "plt.colorbar(ax1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax1 = ax.contour(petal_length,\n",
    "                 petal_width,\n",
    "                 y_prob[:, 1].reshape(petal_length.shape),\n",
    "                 cmap=plt.cm.brg)\n",
    "plt.clabel(ax1)\n",
    "# لیبل میزنه روی خط ها، یعنی مقادیر را مینویسه\n",
    "\n",
    "plt.plot(petal_length_vector, db, \"k\", lw=3)\n",
    "plt.axis([0, 7, 0, 3])\n",
    "\n",
    "plt.plot(X_train[y_train == 1, 0], X_train[y_train == 1, 1], \"gs\")\n",
    "# با صفر و یک دادن ایکس و ایگرگ را تعیین میکنه\n",
    "# که X_train[y_train == 1, 0] ایکس ما است و\n",
    "#  X_train[y_train == 1, 1] ایگرگ ما است\n",
    "#  که نتیچه نقاط سبز در سمت چپ است\n",
    " \n",
    "plt.plot(X_train[y_train == 0, 0], X_train[y_train == 0, 1], \"rs\")"
   ],
   "metadata": {
    "id": "JCuJQkxwQA3E",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "outputId": "22005593-5a7b-4b1f-de37-43b09e27ec15"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Softmax\n",
    "#### حالا میخواهیم باینری نباشه و هر سه کلاس را داشته باشیم\n",
    "\n",
    "\"\"\"\n",
    "در این کد، مسئله طبقه‌بندی چند کلاسه است، زیرا دیتاست آیریس شامل سه گونه گل زنبق است.\n",
    "مدل رگرسیون لجستیک، احتمالات تعلق هر نمونه به هر سه کلاس را محاسبه می‌کند.\n",
    "مدل، کلاسی را که بیشترین احتمال را دارد، به عنوان کلاس پیش‌بینی‌شده اعلام می‌کند.\n",
    "این کد یک مثال ساده از نحوه استفاده از رگرسیون لجستیک برای طبقه‌بندی چند کلاسه در پایتون است\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "byRwLjBi0V1H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = iris_df.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "#این خط، ویژگی‌های ورودی (طول گلبرگ و عرض گلبرگ) را از دیتاست آیریس استخراج می‌کند.\n",
    "# این ویژگی‌ها برای پیش‌بینی گونه گل زنبق استفاده می‌شوند.\n",
    "\n",
    "y = iris_df[\"target\"]\n",
    "# این خط، کلاس گل زنبق را برای یک نمونه جدید با طول گلبرگ 2 سانتی‌متر و عرض گلبرگ 2 سانتی‌متر پیش‌بینی می‌کند.\n",
    "# این متغیر، گونه واقعی گل زنبق را برای هر نمونه مشخص می‌کند.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40)"
   ],
   "metadata": {
    "id": "zbqGUfmaakF2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(random_state=40)\n",
    "lr.fit(X_train, y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "lyCaARVc0ccK",
    "outputId": "7d6752b6-4efe-4352-c7f8-6ca30cd9b8ab"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.predict([[2, 2]])\n",
    "# این خط، کلاس گل زنبق را برای یک نمونه جدید با طول گلبرگ 2 سانتی‌متر و عرض گلبرگ 2 سانتی‌متر پیش‌بینی می‌کند.\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8ztD57D0lzg",
    "outputId": "f38d8bb6-ba0e-4fec-d494-1e57a42a3efa",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.101991Z",
     "start_time": "2025-04-12T19:24:17.100799Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lr.predict_proba([[2, 2]])\n",
    "# این خط، احتمالات تعلق نمونه جدید به هر کلاس را پیش‌بینی می‌کند."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gngpj9Rf1Hb7",
    "outputId": "b4205457-f497-4a99-ee35-1ce629fe978e",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.103005Z",
     "start_time": "2025-04-12T19:24:17.101991Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "VJfvLEPi1SHc",
    "ExecuteTime": {
     "end_time": "2025-04-12T19:24:17.103005Z",
     "start_time": "2025-04-12T19:24:17.103005Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\"\"\"\n",
    "آنتروپی (Entropy) در یادگیری ماشین، به ویژه در الگوریتم‌های درخت تصمیم (Decision Tree)، یک مفهوم کلیدی برای اندازه‌گیری ناخالصی یا عدم قطعیت در یک مجموعه داده است. به عبارت دیگر، آنتروپی نشان می‌دهد که چقدر داده‌ها در یک گره از درخت تصمیم، مخلوط یا ناهمگن هستند.\n",
    "\n",
    "مفهوم آنتروپی در یادگیری ماشین:\n",
    "\n",
    "    ناخالصی داده‌ها:\n",
    "        در یک مسئله طبقه‌بندی، هدف این است که نمونه‌ها را به کلاس‌های مختلف تقسیم کنیم.\n",
    "        اگر در یک گره از درخت تصمیم، نمونه‌ها به طور مساوی بین کلاس‌های مختلف توزیع شده باشند، آن گره ناخالص است و آنتروپی بالایی دارد.\n",
    "        اگر تمام نمونه‌های یک گره به یک کلاس تعلق داشته باشند، آن گره خالص است و آنتروپی پایینی دارد (یا صفر است).\n",
    "    اندازه‌گیری عدم قطعیت:\n",
    "        آنتروپی به ما کمک می‌کند تا میزان عدم قطعیت در مورد کلاس یک نمونه را اندازه‌گیری کنیم.\n",
    "        هرچه آنتروپی بیشتر باشد، عدم قطعیت در مورد کلاس نمونه بیشتر است.\n",
    "\n",
    "فرمول آنتروپی:\n",
    "\n",
    "برای یک مجموعه داده با دو کلاس (باینری)، فرمول آنتروپی به صورت زیر است:\n",
    "\n",
    "Entropy(S) = -p(+)log2(p(+)) - p(-)log2(p(-))\n",
    "\n",
    "که در آن:\n",
    "\n",
    "    S: مجموعه داده\n",
    "    p(+): احتمال تعلق یک نمونه به کلاس مثبت\n",
    "    p(-): احتمال تعلق یک نمونه به کلاس منفی\n",
    "\n",
    "برای مجموعه‌های داده با چندین کلاس، فرمول آنتروپی به صورت زیر تعمیم داده می‌شود:\n",
    "\n",
    "Entropy(S) = -Σ(pi * log2(pi))\n",
    "\n",
    "که در آن:\n",
    "\n",
    "    pi: احتمال تعلق یک نمونه به کلاس i\n",
    "\n",
    "کاربرد آنتروپی در درخت تصمیم:\n",
    "\n",
    "    انتخاب ویژگی‌ها:\n",
    "        الگوریتم‌های درخت تصمیم از آنتروپی برای انتخاب بهترین ویژگی‌ها برای تقسیم داده‌ها در هر گره استفاده می‌کنند.\n",
    "        هدف این است که ویژگی‌ای را انتخاب کنیم که بیشترین کاهش را در آنتروپی ایجاد کند.\n",
    "        این کاهش آنتروپی به عنوان «بهره اطلاعاتی» (Information Gain) شناخته می‌شود.\n",
    "    ساخت درخت:\n",
    "        درخت تصمیم به صورت بازگشتی ساخته می‌شود، به این صورت که در هر گره، ویژگی‌ای انتخاب می‌شود که بیشترین بهره اطلاعاتی را داشته باشد.\n",
    "        این فرآیند تا زمانی ادامه می‌یابد که گره‌ها خالص شوند یا یک معیار توقف برآورده شود.\n",
    "\n",
    "مزایای استفاده از آنتروپی:\n",
    "\n",
    "    اندازه‌گیری ناخالصی: آنتروپی یک معیار کمی برای اندازه‌گیری ناخالصی داده‌ها است.\n",
    "    انتخاب ویژگی‌های مهم: آنتروپی به الگوریتم‌های درخت تصمیم کمک می‌کند تا ویژگی‌های مهم را برای طبقه‌بندی انتخاب کنند.\n",
    "    ساخت درخت‌های کارآمد: با استفاده از آنتروپی، می‌توان درخت‌های تصمیم کارآمدی ساخت که دقت بالایی در طبقه‌بندی دارند.\n",
    "    \n",
    "\"\"\""
   ]
  }
 ]
}
