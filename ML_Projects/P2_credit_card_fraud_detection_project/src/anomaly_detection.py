#
# # در این فایل، تشخیص ناهنجاری‌ها با الگوریتم Isolation Forest انجام می‌شود.
# #
# # تشخیص ناهنجاری (Anomaly Detection) که به آن تشخیص پرت (Outlier Detection) نیز گفته می‌شود،
# فرآیند شناسایی مواردی در یک مجموعه داده است که با رفتار مورد انتظار یا الگوهای غالب داده‌ها تفاوت قابل توجهی دارند.
# این موارد غیرعادی می‌توانند نشان‌دهنده تقلب، خطا، رویدادهای نادر یا موارد غیرمنتظره باشند که نیاز به بررسی دارند.
#
# # عددی که در خروجی نمایش داده خواهد شد نشان‌دهنده تعداد ناهنجاری‌های (موارد غیرعادی) شناسایی شده توسط الگوریتم Isolation Forest در مجموعه داده X_test است.


# خیر، Anomaly Detection (تشخیص ناهنجاری)، مانند الگوریتم Isolation Forest، همانند تابع ضرر یا بهینه‌سازی یا گرادیان نیست.
#
# اینها مفاهیم مربوط به وظایف (Tasks) و الگوریتم‌های متفاوتی در یادگیری ماشین هستند:
#
#     تشخیص ناهنجاری (Anomaly Detection):
#
#         این یک وظیفه در یادگیری ماشین است که اغلب زیرمجموعه یادگیری بدون نظارت (Unsupervised Learning) قرار می‌گیرد.
#
#         هدف آن شناسایی نقاط داده‌ای است که به طور قابل توجهی از الگوی اصلی یا اکثریت داده‌ها منحرف می‌شوند (یعنی "ناهنجاری" یا "پرت").
#
#         Isolation Forest یک الگوریتم برای این کار است. این الگوریتم با ساخت درختان تصمیم (مانند Random Forest) و اندازه‌گیری "عمق" مورد نیاز برای جداسازی یک نقطه، ناهنجاری‌ها را شناسایی می‌کند. نقاطی که سریع‌تر جدا می‌شوند، به احتمال زیاد ناهنجاری هستند.
#
#         ویژگی بارز: در Anomaly Detection، معمولاً برچسب‌های واقعی برای ناهنجاری‌ها نداریم (بدون نظارت است)، بنابراین نمی‌توانیم یک loss را با مقایسه پیش‌بینی و واقعیت محاسبه کنیم و سپس از گرادیان برای به‌روزرسانی پارامترهای مدل استفاده کنیم.




# Anomaly Detection مخصوص مدلهای نظارت نشده است اما سوال پیش میاد که چرا 
# چرا Anomaly Detection در پروژه‌ای با مدل‌های نظارت‌شده استفاده می‌شود؟ (به‌ویژه در تشخیص تقلب)
#
# پروژه‌هایی مانند تشخیص تقلب کارت اعتباری دارای ویژگی‌های خاصی هستند که استفاده از رویکردهای ترکیبی (هیبرید) را بسیار مفید می‌کند:
#
#     عدم تعادل داده‌ای شدید (Extreme Data Imbalance):
#
#         در داده‌های تقلب، تعداد تراکنش‌های عادی بسیار بسیار بیشتر از تراکنش‌های تقلبی است (مثلاً 99.9% عادی در مقابل 0.1% تقلبی).
#
#         مدل‌های نظارت‌شده کلاسیک (مانند Logistic Regression, Random Forest, SVM) برای کار با داده‌های نامتعادل چالش‌هایی دارند و ممکن است کلاس اقلیت (تقلب) را نادیده بگیرند، زیرا بهینه‌سازی آن‌ها بر روی کاهش خطای کلی است و نه لزوماً تشخیص کلاس اقلیت.
#
#         نقش Anomaly Detection: الگوریتم‌های تشخیص ناهنجاری، مانند Isolation Forest، به طور ذاتی برای شناسایی نقاط "غیرعادی" طراحی شده‌اند، حتی اگر تعداد آن‌ها بسیار کم باشد. آن‌ها سعی می‌کنند الگوهای "عادی" را یاد بگیرند و هر چیزی را که به وضوح از این الگو خارج است، به عنوان ناهنجاری علامت‌گذاری کنند.
#
#     الگوهای تقلب جدید و ناشناخته (Evolving/Novel Fraud Patterns):
#
#         کلاهبرداران دائماً روش‌های خود را تغییر می‌دهند. مدل‌های نظارت‌شده فقط می‌توانند الگوهای تقلبی را که قبلاً در داده‌های آموزشی دیده‌اند، شناسایی کنند.
#
#         نقش Anomaly Detection: این الگوریتم‌ها می‌توانند تراکنش‌هایی را که با هیچ یک از الگوهای عادی یا تقلبی شناخته‌شده (موجود در داده‌های آموزشی) مطابقت ندارند، پرچم‌گذاری کنند. این به کشف الگوهای تقلب کاملاً جدید کمک می‌کند که مدل‌های نظارت‌شده هرگز آن‌ها را "یاد نگرفته‌اند".
#
#     رویکرد هیبرید (Hybrid Approach) و تکمیلی:
#
#         در بسیاری از موارد، Anomaly Detection به عنوان یک مرحله مکمل برای مدل‌های نظارت‌شده استفاده می‌شود. این می‌تواند به چند شکل باشد:
#
#             Feature Engineering: امتیاز ناهنجاری (anomaly score) که توسط یک الگوریتم Anomaly Detection تولید می‌شود (مثلاً scores در detect_anomalies برای Isolation Forest)، می‌تواند به عنوان یک ویژگی جدید به داده‌ها اضافه شود و سپس به مدل‌های نظارت‌شده (Logistic Regression, Random Forest, SVM) داده شود. این به مدل‌های نظارت‌شده کمک می‌کند تا از اطلاعات مربوط به "غیرعادی بودن" تراکنش‌ها نیز استفاده کنند.
#
#             Multi-layered Detection: ابتدا مدل‌های نظارت‌شده پیش‌بینی‌های خود را انجام می‌دهند. سپس، الگوریتم‌های Anomaly Detection تراکنش‌هایی را که توسط مدل‌های نظارت‌شده به عنوان "عادی" طبقه‌بندی شده‌اند اما رفتار مشکوکی دارند، بررسی می‌کنند تا از نشت تقلب‌های پنهان جلوگیری شود.
#
#             Semisupervised Learning: در برخی موارد، Anomaly Detection می‌تواند در یک سناریوی نیمه‌نظارت‌شده استفاده شود، جایی که فقط برچسب‌های "عادی" در دسترس هستند، و هر چیزی که از این حالت منحرف شود، "ناهنجاری" در نظر گرفته می‌شود.



# مربوط به گام یازدهم
# src/anomaly_detection.py

from sklearn.ensemble import IsolationForest
import numpy as np
import pandas as pd


def detect_anomalies(X, model=None, threshold=0.1):
    """
    اگر مدل داده نشود، از Isolation Forest استفاده می‌شود.
    اگر مدل داده شود، ناهنجاری‌ها بر اساس احتمال یا برچسب تعیین می‌شوند.

    ورودی:
        X: ویژگی‌های تست
        model: یکی از مدل‌های آموزش‌داده‌شده (یا None)
        threshold: آستانه‌ای برای تعیین ناهنجاری از روی احتمال

    خروجی:
        DataFrame با ستون‌های ['Index', 'Anomaly', 'Score']
    """
    if model is None:
        iso_forest = IsolationForest(contamination=0.01, random_state=42)
        scores = -iso_forest.decision_function(X)  # نمره ناهنجاری (بزرگتر → ناهنجارتر)
        preds = iso_forest.predict(X)
        is_anomaly = (preds == -1).astype(int)

        print(f"🔍 Anomalies detected by IsolationForest: {np.sum(is_anomaly)}")

    else:
        if hasattr(model, "predict_proba"):
            probs = model.predict_proba(X)[:, 1]  # احتمال کلاس ۱
            is_anomaly = (probs < threshold).astype(int)
            scores = probs  # اینجا score همان احتمال است

            print(f"🔍 Anomalies detected by {model.__class__.__name__}: {np.sum(is_anomaly)} (threshold={threshold})")

        else:
            preds = model.predict(X)
            is_anomaly = (preds == 1).astype(int)
            scores = preds  # در اینجا score همون برچسبه چون probability نداریم

            print(f"⚠️ Model {model.__class__.__name__} does not support predict_proba(). Using label==1 as anomaly.")

    results_df = pd.DataFrame({
        "Index": np.arange(len(X)),
        "Anomaly": is_anomaly,
        "Score": scores
    })

    return results_df
