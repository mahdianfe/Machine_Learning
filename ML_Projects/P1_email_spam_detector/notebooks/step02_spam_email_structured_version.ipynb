{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import os  #Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø± Ø¨Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "#  Ø¯Ø± Ù…Ø¯Ù„ Ù…Ø§ØŒ Ø§Ø² TfidfVectorizer Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ÛŒÙ… Ú©Ù‡ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù…ØªÙ† Ù‡Ø³ØªØ´ Ùˆ\n",
    "#  Ù…Ù‚Ø¯Ø§Ø±Ù‡Ø§ÛŒÛŒ Ù…Ø«Ù„ 0.32ØŒ 0.05ØŒ ... ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ (ÛŒØ¹Ù†ÛŒ ØºÛŒØ±Ø¨Ø§ÛŒÙ†Ø±ÛŒÙ‡).\n",
    "from sklearn.model_selection import train_test_split #Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§ Ø¨Ù‡ ØªØ³Øª Ùˆ ØªØ±ÛŒÙ†\n",
    "from sklearn.metrics import classification_report # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„\n",
    "import joblib #Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„\n"
   ],
   "id": "45a2fce56cd2c7cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# main file"
   ],
   "id": "1c7d49f7bce878b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ©\n",
    "# Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ù…Ø§ Ú†Ù†Ø¯ Ù…Ø¯Ù„ Ø±Ø§ ÛŒØ§Ø¯ Ø®ÙˆØ§Ù‡Ø¯ Ú¯Ø±ÙØª\n",
    "model_name = sys.argv[1] if len(sys.argv) > 1 else \"nb\"  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Naive Bayes\n",
    "#Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² sys.argvØŒ Ø§Ø² Ø¨ÛŒØ±ÙˆÙ† ÙØ§ÛŒÙ„ Ù‡Ù… Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒ Ù…Ø¯Ù„ Ø±Ø§ ØªØ¹ÛŒÛŒÙ† Ú©Ù†ÛŒ.\n",
    "#Ø§ÛŒÙ† Ø®Ø· ØªØ¹ÛŒÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ú©Ù‡ Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ú†ÛŒ Ø¨Ø§Ø´Ù‡ØŒ Ù†Ù‡ Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù‡ ØªØ§ Ø§ÛŒÙ†Ú©Ù‡ Ø¨Ù‡ Ø®Ø·Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ø³Ù‡.\n",
    "\n",
    "# Ø¨Ø¯ÙˆÙ† Ø§ÛŒÙ† Ø®Ø· Ù…ÛŒØ´Ø¯ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ Ù‡Ø± Ø¨Ø§Ø± Ù†Ø§Ù… Ù…Ø¯Ù„ Ø±Ø§ Ù‚Ø±Ø§Ø± Ø¨Ø¯ÛŒÙ… Ù…Ø«Ù„Ø§\n",
    "# model_name = \"svm\"\n",
    "# Ø§Ù…Ø§ Ø¯Ø± Ø§ÛŒÙ† ØµÙˆØ±Øª Ù†Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø§Ø² Ø¨ÛŒØ±ÙˆÙ† (ÛŒØ¹Ù†ÛŒ Ø§Ø² Ø·Ø±ÛŒÙ‚ ØªØ±Ù…ÛŒÙ†Ø§Ù„) Ù…Ø¯Ù„ Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯ÛŒ\n",
    "# Ùˆ Ù…Ø¬Ø¨ÙˆØ± Ù…ÛŒâ€ŒØ´ÛŒ Ù‡Ø± Ø¨Ø§Ø± Ø¨ÛŒØ§ÛŒ ØªÙˆÛŒ ÙØ§ÛŒÙ„ main.py Ùˆ Ø¯Ø³ØªÛŒ Ú©Ø¯ Ø±Ùˆ Ø¹ÙˆØ¶ Ú©Ù†ÛŒ.\n",
    "\n",
    "# Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø³Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯:\n",
    "#     Ø§Ú¯Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù…Ø¯Ù„ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù‡ (ÛŒØ¹Ù†ÛŒ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù† Ø¯ÙˆÙ… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)ØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†.\n",
    "#     ÙˆÚ¯Ø±Ù†Ù‡ØŒ Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ Ø¨Ø°Ø§Ø± 'nb' (ÛŒØ¹Ù†ÛŒ Naive Bayes).\n",
    "\n",
    "# #sys.argv[0] â†’ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø§Ø¬Ø±Ø§ÛŒÛŒ: 'main.py'\n",
    "# sys.argv[1] â†’ Ø§ÙˆÙ„ÛŒÙ† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù† Ù†Ø§Ù… Ù…Ø¯Ù„ Ù…Ø§ Ø§Ø³Øª: 'svm'\n",
    "\n",
    " # Ú†Ø±Ø§ > 1ØŸ\n",
    "# Ú†ÙˆÙ† Ù‡Ù…ÛŒØ´Ù‡:\n",
    "#     sys.argv[0] â†’ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ù¾Ø§ÛŒØªÙˆÙ† Ù‡Ø³Øª.\n",
    "#     Ù¾Ø³ Ø§Ú¯Ø± ÙÙ‚Ø· Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ Ø¨Ø´Ù‡ (Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†ÛŒ)ØŒ Ø·ÙˆÙ„ Ù„ÛŒØ³Øª sys.argv ÙÙ‚Ø· Û± Ù‡Ø³Øª:\n",
    "# ['main.py']\n",
    "# Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ†:\n",
    "#     ÙˆÙ‚ØªÛŒ Ø·ÙˆÙ„ sys.argv Ø¨ÛŒØ´ØªØ± Ø§Ø² 1 Ø¨Ø§Ø´Ù‡ØŒ ÛŒØ¹Ù†ÛŒ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù† Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø³Ù… ÙØ§ÛŒÙ„ Ù‡Ù… ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡.\n",
    "\n",
    "if model_name == \"nb\":\n",
    "    from models.train_nb_model import train_model\n",
    "    #  Ø§Ú¯Ø± ÙØ§ÛŒÙ„ train_nb_model.py ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡\n",
    "    # Ú©Ù‡ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù‡Ù… Ù‡Ù…ÛŒÙ†Ù‡ØŒ Ø§ÙˆÙ†â€ŒÙˆÙ‚Øª Ø¯Ø± Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ Ø§Ø±ÙˆØ± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒ (Ù…Ø«Ù„Ø§Ù‹: ModuleNotFoundError).\n",
    "elif model_name == \"svm\":\n",
    "    from models.train_svm_model import train_model\n",
    "elif model_name == \"lr\":\n",
    "    from models.train_lr_model import train_model\n",
    "else:\n",
    "    raise ValueError(\"Unsupported model\")"
   ],
   "id": "2cb1aea974c69768"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§\n",
    "# # ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„Ù‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø±Ø§ Ù…ÛŒØ®ÙˆØ§Ù†Ø¯ Ùˆ Ø¯Ø§Ø®Ù„ Ù„ÛŒØ³ØªÛŒ Ù…ÛŒØ±ÛŒØ²Ø¯\n",
    "def load_emails_from_folder(folder):\n",
    "    emails = []\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "        with open(path, 'r', encoding='latin-1') as f:\n",
    "            emails.append(f.read())\n",
    "    return emails\n",
    "# Ø®ÙˆØ§Ù†Ø¯Ù† Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ù¾Ù… Ùˆ Ù…Ø¹Ù…ÙˆÙ„ÛŒØ§Ø² Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒØ´Ø§Ù† Ø¯Ø± data/ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯.\n",
    "spam_emails = load_emails_from_folder('data/spam')\n",
    "ham_emails = load_emails_from_folder('data/easy_ham')"
   ],
   "id": "f3defaa98999aec3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ùˆ Ø¯Ø§Ø¯Ù† Ù„ÛŒØ¨Ù„ Ø¨Ù‡ Ø§Ù†Ù‡Ø§\n",
    "# # Ø³ØªÙˆÙ† text Ø´Ø§Ù…Ù„ Ù…ØªÙ† Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§.\n",
    "# # Ø³ØªÙˆÙ† label: Ø¹Ø¯Ø¯ Û± Ø¨Ø±Ø§ÛŒ Ø§Ø³Ù¾Ù…ØŒ Ø¹Ø¯Ø¯ Û° Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ.\n",
    "df = pd.DataFrame({'text': spam_emails + ham_emails,\n",
    "                   'label': [1]*len(spam_emails) + [0]*len(ham_emails)})\n",
    "# #ÙØ±Ø¶ Ú©Ù† 3 Ø§ÛŒÙ…ÛŒÙ„ Ø§Ø³Ù¾Ù… Ø¯Ø§Ø±ÛŒÙ…\n",
    "# # Ø§ÙˆÙ†â€ŒÙˆÙ‚Øª len(spam_emails) Ù…ÛŒâ€ŒØ´Ù‡ 3. Ø­Ø§Ù„Ø§: [1] * 3\n",
    "# # Ù…Ø³Ø§ÙˆÛŒ Ù…ÛŒâ€ŒØ´Ù‡ Ø¨Ø§: [1, 1, 1]\n",
    "# # # ÛŒØ¹Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Û³ Ø§ÛŒÙ…ÛŒÙ„ Ø§Ø³Ù¾Ù…ØŒ Û³ Ø¹Ø¯Ø¯ Û± ØªÙˆÙ„ÛŒØ¯ Ú©Ø±Ø¯ÛŒÙ…. Ù‡Ù…ÛŒÙ† Ú©Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ:\n",
    "# # [0] * len(ham_emails)\n",
    "# # Ø¯Ø± Ù†ØªÛŒØ¬Ù‡:\n",
    "# # y = [1, 1, 1, 0, 0, 0]"
   ],
   "id": "d01d6430d93f8a58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ØªØ¨Ø¯ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Ø§ÛŒÙ…ÛŒÙ„ Ø¨Ù‡ Ø¹Ø¯Ø¯\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "# #Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ Ú©Ù‡ Ú©Ù„Ù…Ø§Øª ØªÙˆÙ‚Ù (stop words) Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±Ø¯.Ù…Ø§Ù†Ù†Ø¯ \"the\"ØŒ \"a\"ØŒ \"is\"ØŒ \"are\" Ùˆ ØºÛŒØ±Ù‡.\n",
    "# Ø¨Ø§ Ø­Ø°Ù Ø§ÛŒÙ† Ú©Ù„Ù…Ø§ØªØŒ ØªÙ…Ø±Ú©Ø² Ù…Ø¯Ù„ Ø¨Ø± Ø±ÙˆÛŒ Ú©Ù„Ù…Ø§Øª Ù…Ù‡Ù…â€ŒØªØ± Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.\n",
    "# #ÙÙ‚Ø· Û±Û°Û°Û° Ú©Ù„Ù…Ù‡â€ŒÛŒ Ù…Ù‡Ù…â€ŒØªØ± Ùˆ Ù¾Ø±ØªÚ©Ø±Ø§Ø±ØªØ± Ø±Ø§ Ø§Ø² Ø¨ÛŒÙ† ØªÙ…Ø§Ù… Ú©Ù„Ù…Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù‡Ù…Ù‡ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ Ù†Ú¯Ù‡ Ø¯Ø§Ø± Ùˆ Ø¨Ù‚ÛŒÙ‡ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "#fit() ÛŒØ¹Ù†ÛŒ: Ø§Ø² Ø±ÙˆÛŒ ØªÙ…Ø§Ù… Ù…ØªÙ†â€ŒÙ‡Ø§ØŒ Ú©Ù„Ù…Ø§Øª Ù¾Ø±ØªÚ©Ø±Ø§Ø± Ùˆ Ù…Ù‡Ù… (Ø·Ø¨Ù‚ TF-IDF) Ø±Ùˆ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±\n",
    "# Ùˆ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡ØŒ ÛŒÚ© Ø¹Ø¯Ø¯ Ø´Ø§Ø®Øµ Ù…Ø´Ø®Øµ Ú©Ù†.\n",
    "# transform() ÛŒØ¹Ù†ÛŒ: Ø­Ø§Ù„Ø§ Ø¨ÛŒØ§ÛŒÙ… Ù‡Ø± Ù…ØªÙ† Ø±Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ Ú©Ù†ÛŒÙ… Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¢Ù† Ú†ÛŒØ²ÛŒ Ú©Ù‡ Ø¯Ø± fit() ÛŒØ§Ø¯ Ú¯Ø±ÙØªÛŒÙ….\n",
    "y = df['label']"
   ],
   "id": "a392bef357ca301a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Ø¯Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ Ø¯ÛŒØªØ§ Ø¨Ù‡ ØªØ³Øª Ùˆ ØªØ±ÛŒÙ†\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "fb0ec84e7939e48a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
    "model = train_model(X_train, y_train)"
   ],
   "id": "d4d2f0141ca168c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#  Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª Ùˆ Ú†Ø§Ù¾ Ú¯Ø²Ø§Ø±Ø´ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„.\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "e97bfc116e293daf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ ÙÙˆÙ„Ø¯Ø± models\n",
    "os.makedirs('models', exist_ok=True)\n"
   ],
   "id": "248f6fdcd0106bfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ùˆ Ø¨Ø±Ø¯Ø§Ø±â€ŒØ³Ø§Ø²\n",
    "joblib.dump(model, f'models/{model_name}_classifier.pkl')\n",
    "joblib.dump(vectorizer, 'models/vectorizer.pkl')\n",
    "\n"
   ],
   "id": "6cc40115499eec46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Ù…Ù‡Ù…:\n",
    "1. Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¨Ù‡ ÙØ§ÛŒÙ„ main Ù…ÛŒØ±ÙˆÛŒÙ…\n",
    "2. Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§ÛŒÙ†Ú©Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ú†Ù‡ Ù…Ø¯Ù„ÛŒ Ø±Ø§ Ù…ÛŒØ®ÙˆØ§Ù‡ÛŒÙ… ÛŒÚ©ÛŒ Ø§Ø² Ú©Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ Ù…ÛŒØ²Ù†ÛŒÙ…\n",
    "python main.py nb    \n",
    "python main.py svm\n",
    "python main.py lr\n",
    "\n",
    "\"\"\""
   ],
   "id": "535d8087b9d712fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø´Ù…Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ models/ Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ§Ù‡Ù†Ø¯ Ø´Ø¯.\n",
    "# Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ø«Ø§Ù„ØŒ Ø§Ú¯Ø± Ù…Ø¯Ù„ SVM Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ØŒ ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ù‡ Ù†Ø§Ù… svm_classifier.pkl Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.\n"
   ],
   "id": "210a40acdcef33a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ù‡ Ù…Ø§Ø´ÛŒÙ†\n"
   ],
   "id": "7e5cdd2ce215285c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train_nb_model.py\n",
    "#################################\n",
    "# Training code goes here\n",
    "#ğŸ”¹ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ Ø¬Ø¯Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ\n",
    "# Ù…Ø«Ù„Ø§Ù‹ Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒØ¯ ÙÙ‚Ø· Ù…Ø¯Ù„ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯ Ø¨Ø¯ÙˆÙ† Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ù‚ÛŒÙ‡ Ú†ÛŒØ²Ù‡Ø§.\n",
    "# ğŸ”¹ Ø¨Ù‡ØªØ±Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø¯Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØŒ Ù…Ø«Ù„:\n",
    "#     train_nb.py (Ø¨Ø±Ø§ÛŒ Naive Bayes)\n",
    "#     train_lr.py (Ø¨Ø±Ø§ÛŒ Logistic Regression)\n",
    "#     train_svm.py (Ø¨Ø±Ø§ÛŒ SVM)\n",
    "\n",
    "#################################\n",
    "# train_nb_model.py\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Ù…Ù‡Ù…:\n",
    "1. Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¨Ù‡ ÙØ§ÛŒÙ„ main Ù…ÛŒØ±ÙˆÛŒÙ…\n",
    "2. Ú©Ø¯ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ Ù…ÛŒØ²Ù†ÛŒÙ… Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø¹Ù„Ø§Ù…Øª Ù¾Ù„ÛŒ Ø±Ø§ Ù†ÛŒÙ…Ø²Ù†ÛŒÙ…\n",
    "python main.py nb\n",
    "\n",
    "\"\"\"\n"
   ],
   "id": "fe127d2009cce668"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train_svm_model.py\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Ù…Ù‡Ù…:\n",
    "1. Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¨Ù‡ ÙØ§ÛŒÙ„ main Ù…ÛŒØ±ÙˆÛŒÙ…\n",
    "2. Ú©Ø¯ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ Ù…ÛŒØ²Ù†ÛŒÙ… Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø¹Ù„Ø§Ù…Øª Ù¾Ù„ÛŒ Ø±Ø§ Ù†ÛŒÙ…Ø²Ù†ÛŒÙ…\n",
    "python main.py svm\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø´Ù…Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ models/ Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ§Ù‡Ù†Ø¯ Ø´Ø¯.\n",
    "# Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ø«Ø§Ù„ØŒ Ø§Ú¯Ø± Ù…Ø¯Ù„ SVM Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ØŒ ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ù‡ Ù†Ø§Ù… svm_classifier.pkl Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.\n"
   ],
   "id": "7b761b24a55eac93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train_lr_model.py\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "Ù…Ù‡Ù…:\n",
    "1. Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¨Ù‡ ÙØ§ÛŒÙ„ main Ù…ÛŒØ±ÙˆÛŒÙ…\n",
    "2. Ú©Ø¯ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ Ù…ÛŒØ²Ù†ÛŒÙ… Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø¹Ù„Ø§Ù…Øª Ù¾Ù„ÛŒ Ø±Ø§ Ù†ÛŒÙ…Ø²Ù†ÛŒÙ…\n",
    "python main.py lr\n",
    "\n",
    "\"\"\""
   ],
   "id": "6f3808f417a06037"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "82de51e38904b72f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3ca4fbaaf68190a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n"
   ],
   "id": "fe2311d793614b9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate_nb_model.py\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_nb_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Ú†Ø§Ù¾ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
    "    print(\"Naive Bayes Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"Naive Bayes Confusion Matrix:\")\n",
    "    print(matrix)\n",
    "\n",
    "    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„\n",
    "    output_path = os.path.join(\"evaluation_outputs\", \"nb_report.txt\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"Naive Bayes Classification Report:\\n\")\n",
    "        f.write(report + \"\\n\\n\")\n",
    "        f.write(\"Naive Bayes Confusion Matrix:\\n\")\n",
    "        f.write(str(matrix))\n",
    "\n",
    "\"\"\"\n",
    "Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø§Ø² ÙØ§ÛŒÙ„ evaluate_models.py Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø±ÙØªÙ‡ Ø´ÙˆØ¯  \n",
    "\"\"\""
   ],
   "id": "3cc982174f4af0cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate_lr_model.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_lr_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Logistic Regression Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"Logistic Regression Confusion Matrix:\")\n",
    "    print(matrix)\n",
    "\n",
    "    output_path = os.path.join(\"evaluation_outputs\", \"lr_report.txt\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"Logistic Regression Classification Report:\\n\")\n",
    "        f.write(report + \"\\n\\n\")\n",
    "        f.write(\"Logistic Regression Confusion Matrix:\\n\")\n",
    "        f.write(str(matrix))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø§Ø² ÙØ§ÛŒÙ„ evaluate_models.py Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø±ÙØªÙ‡ Ø´ÙˆØ¯  \n",
    "\"\"\""
   ],
   "id": "69ac6281353719b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # evaluate_svm_model.py\n",
    "# # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ø§Ø³ ÙˆÛŒ Ø§Ù…\n",
    "#\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "#\n",
    "# def evaluate_svm_model(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#\n",
    "#     # Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ\n",
    "#     print(\"SVM Classification Report:\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#\n",
    "#     # Ù…Ø§ØªØ±ÛŒØ³ Ø³Ø±Ø¯Ø±Ú¯Ù…ÛŒ\n",
    "#     print(\"SVM Confusion Matrix:\")\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#########\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_svm_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Ú†Ø§Ù¾ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„\n",
    "    print(\"SVM Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"SVM Confusion Matrix:\")\n",
    "    print(matrix)\n",
    "\n",
    "    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„\n",
    "    output_path = os.path.join(\"evaluation_outputs\", \"svm_report.txt\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"SVM Classification Report:\\n\")\n",
    "        f.write(report + \"\\n\\n\")\n",
    "        f.write(\"SVM Confusion Matrix:\\n\")\n",
    "        f.write(str(matrix))\n",
    "\n",
    "\"\"\"\n",
    "Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø§Ø² ÙØ§ÛŒÙ„ evaluate_models.py Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø±ÙØªÙ‡ Ø´ÙˆØ¯  \n",
    "\"\"\""
   ],
   "id": "104b266bf63ec934"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# compare_models.py\n",
    "# ÙØ§ÛŒÙ„ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§ÛŒ Ø§Ø³Øª ØªØ§ Ø³Ù‡ Ù…Ø¯Ù„ Naive Bayes Ùˆ  SVM Ùˆ Logistic Regression Ø±Ø§ Ø¨Ø§ Ù‡Ù… Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ù†Ø¯\n",
    "\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#  Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
    "def plot_model_comparison(results, save_path):\n",
    "    labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "    model_names = [r[0] for r in results]\n",
    "    #Ø§ÛŒÙ† ÛŒÚ© Ù„ÛŒØ³Øªâ€ŒØ³Ø§Ø² (list comprehension) Ø§Ø³Øª\n",
    "    #Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¹Ù†ØµØ± rØŒ Ø§ÙˆÙ„ÛŒÙ† Ø¢ÛŒØªÙ… Ø¢Ù† (Ø¨Ø§ Ø§Ù†Ø¯ÛŒØ³ 0) Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "    #Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ ÛŒÚ© Ù„ÛŒØ³Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù†Ø§Ù… model_names Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù†Ø§Ù… ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± results Ø§Ø³Øª.\n",
    "\n",
    "    scores = [r[1:] for r in results]\n",
    "    # ÛŒÚ© Ø¨Ø±Ø´ (slice) Ø§Ø² Ø¢Ù† Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ø§Ø² Ø§Ù†Ø¯ÛŒØ³ 1 Ø¨Ù‡ Ø¨Ø¹Ø¯ Ø§Ø³Øª.\n",
    "    #Ø¯Ø± Ù†Ù‡Ø§ÛŒØª ÛŒÚ© Ù„ÛŒØ³Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù†Ø§Ù… scores Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø¯Ø± Ø¢Ù† Ù‡Ø± Ø¹Ù†ØµØ±ØŒ Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ù†Ù…Ø±Ø§Øª Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù…Ø¯Ù„ Ø®Ø§Øµ Ø§Ø³Øª.\n",
    "    scores = np.array(scores)\n",
    "    # Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ³Øª scores Ø¨Ù‡ ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ NumPy Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "    # Ø¢Ø±Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ NumPy Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¹Ø¯Ø¯ÛŒ Ú©Ø§Ø±Ø¢Ù…Ø¯ØªØ± Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ø§ matplotlib Ù…Ù†Ø§Ø³Ø¨â€ŒØªØ±Ù†Ø¯.\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    #Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² np.arange ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ NumPy Ø§Ø² Ø§Ø¹Ø¯Ø§Ø¯ ØµØ­ÛŒØ­ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "\n",
    "    width = 0.25 # Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ù¾Ù‡Ù†Ø§ÛŒ Ù…ÛŒÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for i in range(len(model_names)):\n",
    "        ax.bar(x + i * width, scores[i], width, label=model_names[i])\n",
    "        #x + i * width: Ù…ÙˆÙ‚Ø¹ÛŒØª x Ø¨Ø±Ø§ÛŒ Ù…ÛŒÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ (i).\n",
    "        # Ø¨Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† i * widthØŒ Ù…ÛŒÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù‡Ø± Ù…Ø¯Ù„ Ú©Ù…ÛŒ Ø¨Ù‡ Ø³Ù…Øª Ø±Ø§Ø³Øª Ø¬Ø§Ø¨Ø¬Ø§ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ ØªØ§ Ø§Ø² Ù‡Ù… Ø¬Ø¯Ø§ Ø¨Ø§Ø´Ù†Ø¯.\n",
    "\n",
    "    ax.set_ylabel('Score') #Ø¹Ù†ÙˆØ§Ù† Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­ÙˆØ± y Ø§Ø³Øª Ú©Ù‡ 'Score' Ø±Ø§ Ú¯Ø°Ø§Ø´ØªÙ‡.\n",
    "    ax.set_title('Model Comparison')\n",
    "    ax.set_xticks(x + width)\n",
    "    #Ù…Ú©Ø§Ù† Ù‚Ø±Ø§Ø±Ú¯ÛŒØ±ÛŒ Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­ÙˆØ± x ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "    # Ø§Ø² x + width Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§ Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ÙˆØ³Ø· Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ù…ÛŒÙ„Ù‡â€ŒÙ‡Ø§ Ù‚Ø±Ø§Ø± Ø¨Ú¯ÛŒØ±Ù†Ø¯.\n",
    "\n",
    "    ax.set_xticklabels(labels) #Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­ÙˆØ± x Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„ÛŒØ³Øª labels ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒØ´Ùˆ\n",
    "    ax.legend() #Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #ÛŒÚ© ØªØ§Ø¨Ø¹ Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± ÙØ§ØµÙ„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨ÛŒÙ† Ø¹Ù†Ø§ØµØ± Ù†Ù…ÙˆØ¯Ø§Ø± (Ù…Ø§Ù†Ù†Ø¯ Ø¹Ù†ÙˆØ§Ù†ØŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§) Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø§Ø² Ù‡Ù…Ù¾ÙˆØ´Ø§Ù†ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø´ÙˆØ¯.\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    #Ù†Ù…ÙˆØ¯Ø§Ø± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ÛŒ Ø¨Ø§ Ù…Ø³ÛŒØ±ÛŒ Ú©Ù‡ Ø¯Ø± Ù¾Ø§Ø±Ø§Ù…ØªØ± save_path Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø§Ø³ØªØŒ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "\n",
    "    plt.close()\n",
    "    #Ø´Ú©Ù„ (figure) Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ø³ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§ Ù…Ù†Ø§Ø¨Ø¹ Ø³ÛŒØ³ØªÙ… Ø¢Ø²Ø§Ø¯ Ø´ÙˆÙ†Ø¯.\n",
    "\n",
    "    print(f\"âœ… Ù†Ù…ÙˆØ¯Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {save_path}\")\n",
    "\n",
    "\n",
    "#  Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ + ØªÙˆÙ„ÛŒØ¯ Ø®Ø±ÙˆØ¬ÛŒ Ù…ØªÙ†ÛŒ Ùˆ ØªØµÙˆÛŒØ±ÛŒ\n",
    "def compare_models(X_test, y_test, models_dir):\n",
    "    model_files = {\n",
    "        \"SVM\": \"svm_classifier.pkl\",\n",
    "        \"Naive Bayes\": \"nb_classifier.pkl\",\n",
    "        \"Logistic Regression\": \"lr_classifier.pkl\"\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model_name, filename in model_files.items():\n",
    "        try:\n",
    "            model_path = os.path.join(models_dir, filename)\n",
    "            model = joblib.load(model_path)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            results.append((model_name, acc, prec, rec, f1))\n",
    "\n",
    "            print(f\"\\nğŸ“Š {model_name} Scores:\")\n",
    "            print(f\"Accuracy: {acc:.4f}\")\n",
    "            print(f\"Precision: {prec:.4f}\")\n",
    "            print(f\"Recall: {rec:.4f}\")\n",
    "            print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ {model_name}: {e}\")\n",
    "\n",
    "    #  Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§: Ø¯Ø§Ø®Ù„ src/evaluation_outputs\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    outputs_dir = os.path.join(base_dir, 'evaluation_outputs')\n",
    "    os.makedirs(outputs_dir, exist_ok=True)\n",
    "\n",
    "    #  Ú¯Ø²Ø§Ø±Ø´ Ù…ØªÙ†ÛŒ\n",
    "    report_path = os.path.join(outputs_dir, 'compare_models_report.txt')\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Model Comparison:\\n\")\n",
    "        f.write(f\"{'Model':<20}{'Accuracy':<10}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}\\n\")\n",
    "        for model_name, acc, prec, rec, f1 in results:\n",
    "            line = f\"{model_name:<20}{acc:<10.2f}{prec:<10.2f}{rec:<10.2f}{f1:<10.2f}\\n\"\n",
    "            f.write(line)\n",
    "            print(line, end='')\n",
    "\n",
    "    print(f\"\\nâœ… Ú¯Ø²Ø§Ø±Ø´ Ù…ØªÙ†ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {os.path.abspath(report_path)}\")\n",
    "\n",
    "    # ğŸ–¼ï¸ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±\n",
    "    chart_path = os.path.join(outputs_dir, 'compare_models_chart.png')\n",
    "    plot_model_comparison(results, chart_path)\n",
    "\n",
    "#  ØªØ§Ø¨Ø¹ main ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ØªØ³Øª (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\n",
    "def main():\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'processed_data.csv')\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    X = df.drop('label', axis=1)\n",
    "    y = df['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models_dir = os.path.join(os.path.dirname(__file__), '..', 'models')\n",
    "    compare_models(X_test, y_test, models_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\"\"\"\n",
    "Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø§Ø² ÙØ§ÛŒÙ„ evaluate_models.py Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø±ÙØªÙ‡ Ø´ÙˆØ¯  \n",
    "\"\"\""
   ],
   "id": "afdd20b364794648"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate_models.py\n",
    "##################\n",
    "from evaluate_svm_model import evaluate_svm_model\n",
    "from evaluate_nb_model import evaluate_nb_model\n",
    "from evaluate_lr_model import evaluate_lr_model\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from compare_models import compare_models\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# ___________________________________\n",
    "\n",
    "# Ù…Ø³ÛŒØ± Ù†Ø³Ø¨ÛŒ Ø¨Ù‡ ÙÙˆÙ„Ø¯Ø± data\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "#os.path.abspath(__file__): Ø§ÛŒÙ† Ù‚Ø³Ù…ØªØŒ Ù…Ø³ÛŒØ± Ù…Ø·Ù„Ù‚ (Ú©Ø§Ù…Ù„) ÙØ§ÛŒÙ„ Ø¬Ø§Ø±ÛŒ (evaluate_models.py) Ø±Ø§ Ø¯Ø± Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.\n",
    "\n",
    "spam_dir = os.path.join(base_dir, '..', 'data', 'spam')\n",
    "#os.path.join(...): Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªÙ† ÛŒÚ© Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ÛŒØ§ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ Ùˆ Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø² Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ù…Ø³ÛŒØ± (Ù…Ø«Ù„ / Ø¯Ø± Ù„ÛŒÙ†ÙˆÚ©Ø³ Ùˆ \\ Ø¯Ø± ÙˆÛŒÙ†Ø¯ÙˆØ²) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
    "# '..': Ø§ÛŒÙ† Ø¹Ù„Ø§Ù…Øª Ø¯Ø± Ù…Ø³ÛŒØ± Ø¨Ù‡ Ù…Ø¹Ù†Ø§ÛŒ \"Ø±ÙØªÙ† Ø¨Ù‡ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ ÙˆØ§Ù„Ø¯\" Ø§Ø³Øª.\n",
    "# 'data', 'spam', 'easy_ham': Ø§ÛŒÙ†Ù‡Ø§ Ù†Ø§Ù… Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§ ÛŒØ§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ù‡Ø³ØªÙ†Ø¯.\n",
    "\n",
    "ham_dir = os.path.join(base_dir, '..', 'data', 'easy_ham')\n",
    "\n",
    "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§\n",
    "def load_emails_from_folder(folder):\n",
    "    emails = []\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "        with open(path, 'r', encoding='latin-1') as f:\n",
    "            emails.append(f.read())\n",
    "    return emails\n",
    "\n",
    "# Ø®ÙˆØ§Ù†Ø¯Ù† Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§\n",
    "spam_emails = load_emails_from_folder(spam_dir)\n",
    "ham_emails = load_emails_from_folder(ham_dir)\n",
    "df = pd.DataFrame({'text': spam_emails + ham_emails,\n",
    "                   'label': [1]*len(spam_emails) + [0]*len(ham_emails)})\n",
    "\n",
    "\n",
    "models_dir = os.path.join(base_dir, '..', 'models')\n",
    "vectorizer_path = os.path.join(models_dir, 'vectorizer.pkl')\n",
    "\n",
    "# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª Ø¨Ø¯ÙˆÙ† ÙÛŒØª\n",
    "vectorizer = joblib.load(vectorizer_path)\n",
    "X = vectorizer.transform(df['text'])   # ÙÙ‚Ø· transform (Ø¨Ø¯ÙˆÙ† fit)\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ___________________________________\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Evaluating SVM Model:\")\n",
    "        svm_path = os.path.join(models_dir, 'svm_classifier.pkl')\n",
    "        model_svm = joblib.load(svm_path)\n",
    "        evaluate_svm_model(model_svm, X_test, y_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating SVM model: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(\"\\nEvaluating Naive Bayes Model:\")\n",
    "        nb_path = os.path.join(models_dir, 'nb_classifier.pkl')\n",
    "        model_nb = joblib.load(nb_path)\n",
    "        evaluate_nb_model(model_nb, X_test, y_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating Naive Bayes model: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(\"\\nEvaluating Logistic Regression Model:\")\n",
    "        lr_path = os.path.join(models_dir, 'lr_classifier.pkl')\n",
    "        model_lr = joblib.load(lr_path)\n",
    "        evaluate_lr_model(model_lr, X_test, y_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating Logistic Regression model: {e}\")\n",
    "\n",
    "    print(\"\\nComparing all models:\")\n",
    "    compare_models(X_test, y_test, models_dir)  # Ø§ÛŒÙ†Ø¬Ø§ Ù…Ù†ØªÙ‚Ù„ Ø´ÙˆØ¯ Ø¯Ø§Ø®Ù„ main\n",
    "\n",
    "\n",
    "\n",
    "#_________________________________________\n",
    "\n",
    "# Ù…Ø³ÛŒØ± ÙÙˆÙ„Ø¯Ø± evaluation_outputs\n",
    "outputs_dir = \"evaluation_outputs\"\n",
    "\n",
    "# Ø§Ú¯Ø± ÙÙˆÙ„Ø¯Ø± evaluation_outputs ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø¢Ù† Ø±Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "    print(f\"Folder '{outputs_dir}' created.\")\n",
    "else:\n",
    "    print(f\"Folder '{outputs_dir}' already exists.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "## ____________________________________________\n",
    "\"\"\"\n",
    "1. Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø±Ø§ Ù…ÛŒØªÙˆØ§Ù† Ø¨Ø§ Ø¯Ú©Ù…Ù‡ Ù¾Ù„ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø±ÙØª\n",
    "2. Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ ÙØ§ÛŒÙ„Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ù…ÛŒÚ¯ÛŒØ±Ø¯ Ùˆ Ø¯Ø± Ù¾ÙˆØ´Ù‡ src/evaluation_outputs Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒÚ©Ù†Ø¯\n",
    "evaluate_lr_model.py Ùˆ evaluate_nb_model Ùˆ evaluate_svm_model.py Ùˆ compare_models.py  \n",
    "\"\"\""
   ],
   "id": "49dab80b47fdb792"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# predict Ù¾ÛŒØ´ Ø¨ÛŒÙ†ÛŒ"
   ],
   "id": "d49a7a32c3a0318a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# predict.py\n",
    "\n",
    "\n",
    "#ğŸ”¹ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ø§ÛŒÙ…ÛŒÙ„ Ø¬Ø¯ÛŒØ¯:\n",
    "# ğŸ”¹ Ù…ØªÙ† Ø§ÛŒÙ…ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¹Ø¯Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù†ØªÛŒØ¬Ù‡ (Û° ÛŒØ§ Û±) Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.\n",
    "# predict.py: ÙÙ‚Ø· ÛŒÚ© Ù…Ø§Ú˜ÙˆÙ„ Ú©Ù…Ú©ÛŒ Ø§Ø³Øª Ú©Ù‡ ØªØ§Ø¨Ø¹ predict_email(text) Ø±Ø§ ØªØ¹Ø±ÛŒÙ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
    "# Ùˆ Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ÛŒÚ© Ù…ØªÙ† Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ Ùˆ Ù†ØªÛŒØ¬Ù‡â€ŒÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±Ø§ (Û° ÛŒØ§ Û±) Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯. Ø®ÙˆØ¯Ø´ Ø¨Ù‡â€ŒØªÙ†Ù‡Ø§ÛŒÛŒ Ú†ÛŒØ²ÛŒ Ú†Ø§Ù¾ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
    "#  Ø§Ù…Ø§ ÙØ§ÛŒÙ„ predict_email.py: ÛŒÚ© Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª Ú©Ù‡ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø±Ø§ Ø¨Ù‡ ØªØ§Ø¨Ø¹ predict_email() Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ú†Ø§Ù¾ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
    "\n",
    "# ØªÙˆØ¶ÛŒØ­ Ø¨ÛŒØ´ØªØ±\n",
    "#  Ù¾Ø³:\n",
    "#     predict.py = ØªØ§Ø¨Ø¹ Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ø¬Ø§Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±.\n",
    "#     predict_email.py = Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø§ Ú†Ø§Ù¾ Ø®Ø±ÙˆØ¬ÛŒ.\n",
    "\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "def predict_email(model_name, text):\n",
    "    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ Ø¨Ø±Ø¯Ø§Ø±â€ŒØ³Ø§Ø² Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù… Ù…Ø¯Ù„\n",
    "    model = load(f'models/{model_name}_classifier.pkl')\n",
    "    vectorizer = load('models/vectorizer.pkl')\n",
    "    # Ú†ÙˆÙ† Ù‡Ø± Ù…ØªÙ† Ø±Ùˆ Ø¨Ù‡ ÛŒÚ© Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒ (feature vector) ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ù‡.\n",
    "    # Ùˆ Ø¯Ø± Ø±ÛŒØ§Ø¶ÛŒØ§Øª Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†ØŒ Ø¨Ù‡ Ú†Ù†ÛŒÙ† Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² Ø§Ø¹Ø¯Ø§Ø¯ Â«Ø¨Ø±Ø¯Ø§Ø±Â» Ú¯ÙØªÙ‡ Ù…ÛŒâ€ŒØ´Ù‡.\n",
    "\n",
    "    # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø§ÛŒÙ…ÛŒÙ„ Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "    X = vectorizer.transform([text])\n",
    "\n",
    "    #Ù¾ÛŒØ´ Ø¨ÛŒÙ†ÛŒ\n",
    "    prediction = model.predict(X)[0]\n",
    "    # [0]\n",
    "    # Ø§ÛŒÙ† ÛŒØ¹Ù†ÛŒ:\n",
    "    #     Â«Ø§Ø² Ø¨ÛŒÙ† Ù‡Ù…Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ØŒ ÙÙ‚Ø· Ø§ÙˆÙ„ÛŒÙ† (Ùˆ ØªÙ†Ù‡Ø§) Ù…ÙˆØ±Ø¯ Ø±Ø§ Ø¨Ø±Ø¯Ø§Ø±.Â»\n",
    "    # Ú†Ø±Ø§ØŸ Ú†ÙˆÙ† Ù…Ø§ ÙÙ‚Ø· ÛŒÚ© Ø§ÛŒÙ…ÛŒÙ„ Ø±Ø§ Ø¯Ø§Ø±ÛŒÙ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….\n",
    "    # ÙˆÙ„ÛŒ Ú†ÙˆÙ† vectorizer.transform([text]) Ø®Ø±ÙˆØ¬ÛŒâ€ŒØ§Ø´ ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ Ø¨Ø§ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªØŒ\n",
    "    # Ù…Ø¯Ù„ Ù‡Ù… Ø®Ø±ÙˆØ¬ÛŒâ€ŒØ§Ø´ ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ Ø¨Ø§ ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.\n",
    "\n",
    "    # Ø¯Ø± Ø¨ÛŒØ´ØªØ± Ù…Ø¯Ù„Ù‡Ø§ÛŒ Ø¯Ùˆ Ú©Ù„Ø§Ø³Ù‡ model.predict(X) ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ Ø¨Ù‡ Ù†Ø§Ù… array([1])  ÛŒØ§ array([0])Ø¨Ø±Ù…ÛŒÚ¯Ø±Ø¯ÙˆÙ†Ù‡\n",
    "    #Ø§Ú¯Ø± array([0]) Ø¨Ø§Ø´Ø¯ØŒ Ø§ÙˆÙ„ÛŒÙ† Ø¹Ù†ØµØ± ØµÙØ± Ø§Ø³Øª Ùˆ Ø§Ú¯Ø± array([1]) Ø¨Ø§Ø´Ø¯ØŒ Ø§ÙˆÙ„ÛŒÙ† Ø¹Ù†ØµØ± ÛŒÚ© Ø§Ø³Øª.\n",
    "    # ÛŒØ¹Ù†ÛŒ Ø§Ú¯Ø± Ø§ÛŒÙ…ÛŒÙ„ Ø§Ø³Ù¾Ù… Ø§Ø³ØªØŒ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ù‡ Ø´Ú©Ù„ array([1]) Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯ Ùˆ..\n",
    "\n",
    "\n",
    "    # Ø¨Ø§Ø²Ú¯Ø´Øª Ù†ØªÛŒØ¬Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ\n",
    "    return \"This email **IS SPAM** âŒ \" if prediction == 1 else \"This email is **NOT SPAM** âœ…\"\n"
   ],
   "id": "4fb2d337edd6c6b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# predict_email.py\n",
    "# # ğŸ”¹ Ø¨Ø¹Ø¯ Ø§Ø² Ø³Ø§Ø®Øª Ùˆ Ø§Ù…ÙˆØ²Ø´ Ùˆ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ\n",
    "# # Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø³Ø§Ø®ØªÛŒÙ… ØªØ§ Ø¨Ø±Ø§ÛŒÙ…Ø§Ù† Ø¨Ú¯ÙˆÛŒØ¯ Ú©Ù‡ Ø§ÛŒÙ…ÛŒÙ„ Ù‡Ø§ÛŒ Ø¯Ø³ØªÛŒ Ø²ÛŒØ± Ø§Ø³Ù¾Ù… Ù‡Ø³ØªÙ†Ø¯ ÛŒØ§ Ø®ÛŒØ±\n",
    "# #         \"Congratulations! You won a free ticket to Bahamas!\",\n",
    "# #         \"Hi John, can we meet at the cafe tomorrow?\",\n",
    "# #         \"URGENT: Update your banking information immediately.\",\n",
    "# #         \"Here is the report you asked for. Let me know your thoughts.\"\n",
    "\n",
    "##______________________\n",
    "# # ØªÙˆØ¶ÛŒØ­ Ø¨ÛŒØ´ØªØ±:\n",
    "# # Ø¢ÛŒØ§ Ù†Ù…ÛŒâ€ŒØ´Ø¯ ÙØ§ÛŒÙ„Ù‡Ø§ÛŒ   predict_email.py Ùˆ  predict.py Ø±Ø§ ÛŒÚ©ÛŒ Ú©Ø±Ø¯ØŸ\n",
    "# #\n",
    "# # 1. ÙØ§ÛŒÙ„ predict.py Ù‚Ø±Ø§Ø±Ù‡ Ù…Ø«Ù„ Ù…ØºØ²Ù Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ Ø¨Ø§Ø´Ù‡. Ù…ÛŒâ€ŒØªÙˆÙ†Ù‡ ØªÙˆØ³Ø· FlaskØŒ ØªØ³ØªØŒ ÛŒØ§ Ù‡Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯ÛŒÚ¯Ù‡ import Ø¨Ø´Ù‡.\n",
    "# # ÙˆÙ„ÛŒ predict_email.py ÙÙ‚Ø· ÛŒÙ‡ ØªØ³Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø³Ø§Ø¯Ù‡ Ø§Ø³Øª. ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø³Ø§Ù†â€ŒÙ‡Ø§ØŒ Ù†Ù‡ Ù…Ø§Ø´ÛŒÙ† ÛŒØ§ Ø³ÛŒØ³ØªÙ….\n",
    "#\n",
    "# # 2Ø§Ú¯Ø± Ø§ÛŒÙ† Ø¯Ùˆ ÙØ§ÛŒÙ„ Ø±Ø§ ÛŒÚ©ÛŒ Ú©Ù†ÛŒÙ… Ø§Ø² Ù†Ø¸Ø± Ø·Ø±Ø§Ø­ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª. Ø§Ú¯Ù‡ Ø§ÛŒÙ† Ú©Ø§Ø±Ùˆ Ø¨Ú©Ù†ÛŒ:\n",
    "# #     Ù‡Ø± Ø¨Ø§Ø± Ú©Ù‡ ÛŒÙ‡ ÙØ§ÛŒÙ„ Ú©Ø¯ÛŒ import predict Ú©Ù†Ù‡ØŒ Ú©Ù„ Ø§ÙˆÙ† Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØ³Øª Ù‡Ù… Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´Ù†! âŒ\n",
    "# #     ÙØ§ÛŒÙ„ Ø³Ù†Ú¯ÛŒÙ†ØŒ Ø¯Ø±Ù‡Ù…ØŒ Ùˆ ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù…ÛŒØ´\n",
    "\n",
    "\n",
    "\n",
    "# predict_email.py\n",
    "\n",
    "from predict import predict_email\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    emails = [\n",
    "        \"Congratulations! You won a free ticket to Bahamas!\",\n",
    "        \"Meeting confirmed at 3pm with the HR team.\",\n",
    "        \"Claim your prize now! Click here.\"\n",
    "    ]\n",
    "\n",
    "    model_name = 'svm'  # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ù‡ 'svm', 'nb', ÛŒØ§ 'lr' ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯.\n",
    "\n",
    "    for i, email in enumerate(emails):\n",
    "        print(f\"Sample {i+1}:\\n{email}\")\n",
    "        print(predict_email(model_name, email))\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "#____________________________________________\n",
    "# # Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø¯:\n",
    "# # Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ ÙˆØ§Ø±Ø¯ Ù¾ÙˆØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø´Ùˆ Ùˆ Ø¨Ù†ÙˆÛŒØ³:\n",
    "\"\"\"\n",
    " python src/predict_email.py\n",
    " \n",
    " \"\"\"\n",
    "# # Ú†ÙˆÙ† ÙˆÙ‚ØªÛŒ Ø¨Ø§ Ø¯Ú©Ù…Ù‡ â–¶ï¸ Ù¾Ù„ÛŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŒ PyCharm ÙØ§ÛŒÙ„ Ø±Ùˆ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù‡\n",
    "# ÙˆÙ„ÛŒ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø¬Ø§Ø±ÛŒ (Current Working Directory) Ù…Ù…Ú©Ù†Ù‡ Ù¾ÙˆØ´Ù‡â€ŒÛŒ src Ø¨Ø§Ø´Ù‡.\n",
    "# # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ Ø´Ù…Ø§ (models/spam_classifier.pkl) Ø¯Ø± Ù¾ÙˆØ´Ù‡â€ŒÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ù‡Ø³ØªÙ†Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ù¾ÛŒØ¯Ø§ Ù†Ù…ÛŒâ€ŒØ´Ù†.\n"
   ],
   "id": "a594cf2d9318784d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# predict_from_file.py\n",
    "\n",
    "from joblib import load\n",
    "from predict import predict_email\n",
    "\n",
    "\n",
    "def predict_emails_from_file(filepath, model_name):\n",
    "    # Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # ØªÙ‚Ø³ÛŒÙ… Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§\n",
    "    emails = content.split('---')\n",
    "\n",
    "    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø§ÛŒÙ…ÛŒÙ„\n",
    "    for i, email in enumerate(emails):\n",
    "        email = email.strip()\n",
    "        if not email:\n",
    "            continue\n",
    "\n",
    "        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ predict_email Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§ÛŒÙ…ÛŒÙ„\n",
    "        result = predict_email(model_name, email)\n",
    "\n",
    "        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡\n",
    "        print(f\"\\nEmail {i + 1}:\")\n",
    "        print(email)\n",
    "        print(\"Result:\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = 'svm'  # Ù…Ø¯Ù„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯: 'svm', 'nb', ÛŒØ§ 'lr'\n",
    "    predict_emails_from_file(\"test_emails.txt\", model_name)\n",
    "\n",
    "## ____________________________________________\n",
    "# Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø¯:\n",
    "# Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ ÙˆØ§Ø±Ø¯ Ù¾ÙˆØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø´Ùˆ Ùˆ Ø¨Ù†ÙˆÛŒØ³:\n",
    "\"\"\"\n",
    "python src/predict_from_file.py\n",
    "\"\"\"\n",
    "# Ú†ÙˆÙ† ÙˆÙ‚ØªÛŒ Ø¨Ø§ Ø¯Ú©Ù…Ù‡ â–¶ï¸ Ù¾Ù„ÛŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŒ PyCharm ÙØ§ÛŒÙ„ Ø±Ùˆ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ ÙˆÙ„ÛŒ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø¬Ø§Ø±ÛŒ (Current Working Directory) Ù…Ù…Ú©Ù†Ù‡ Ù¾ÙˆØ´Ù‡â€ŒÛŒ src Ø¨Ø§Ø´Ù‡.\n",
    "# ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ Ø´Ù…Ø§ (models/spam_classifier.pkl) Ø¯Ø± Ù¾ÙˆØ´Ù‡â€ŒÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ù‡Ø³ØªÙ†Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ù¾ÛŒØ¯Ø§ Ù†Ù…ÛŒâ€ŒØ´Ù†.\n"
   ],
   "id": "ec870e2003fe7d89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
