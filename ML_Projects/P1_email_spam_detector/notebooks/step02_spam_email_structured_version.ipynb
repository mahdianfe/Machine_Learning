{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import os  #برای کار با فایل‌ها و مسیرها\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #تبدیل متن به ویژگی‌های عددی\n",
    "#  در مدل ما، از TfidfVectorizer استفاده کردیم که مربوط به متن هستش و\n",
    "#  مقدارهایی مثل 0.32، 0.05، ... تولید می‌کنه (یعنی غیرباینریه).\n",
    "from sklearn.model_selection import train_test_split #جداسازی دیتا به تست و ترین\n",
    "from sklearn.metrics import classification_report # ارزیابی مدل\n",
    "import joblib #ذخیره مدل\n"
   ],
   "id": "45a2fce56cd2c7cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# main file"
   ],
   "id": "1c7d49f7bce878b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ایمپورت کردن مدل‌ها به صورت داینامیک\n",
    "# زمانی که پروژه ما چند مدل را یاد خواهد گرفت\n",
    "model_name = sys.argv[1] if len(sys.argv) > 1 else \"nb\"  # پیش‌فرض: Naive Bayes\n",
    "#با استفاده از sys.argv، از بیرون فایل هم می‌توانی مدل را تعیین کنی.\n",
    "#این خط تعیین می‌کنه که مدل پیش‌فرض چی باشه، نه اینکه مدل واقعاً ایمپورت یا استفاده شده باشه تا اینکه به خطهای بعدی برسه.\n",
    "\n",
    "# بدون این خط میشد به صورت دستی هر بار نام مدل را قرار بدیم مثلا\n",
    "# model_name = \"svm\"\n",
    "# اما در این صورت نمی‌تونی از بیرون (یعنی از طریق ترمینال) مدل رو تغییر بدی\n",
    "# و مجبور می‌شی هر بار بیای توی فایل main.py و دستی کد رو عوض کنی.\n",
    "\n",
    "# به زبان ساده می‌گوید:\n",
    "#     اگه کاربر مدلی را وارد کرده (یعنی آرگومان دوم وجود دارد)، از آن استفاده کن.\n",
    "#     وگرنه، مدل پیش‌فرض را بذار 'nb' (یعنی Naive Bayes).\n",
    "\n",
    "# #sys.argv[0] → نام فایل اجرایی: 'main.py'\n",
    "# sys.argv[1] → اولین آرگومان نام مدل ما است: 'svm'\n",
    "\n",
    " # چرا > 1؟\n",
    "# چون همیشه:\n",
    "#     sys.argv[0] → نام فایل پایتون هست.\n",
    "#     پس اگر فقط برنامه اجرا بشه (بدون هیچ آرگومانی)، طول لیست sys.argv فقط ۱ هست:\n",
    "# ['main.py']\n",
    "# بنابراین:\n",
    "#     وقتی طول sys.argv بیشتر از 1 باشه، یعنی حداقل یک آرگومان بعد از اسم فایل هم وارد شده.\n",
    "\n",
    "if model_name == \"nb\":\n",
    "    from models.train_nb_model import train_model\n",
    "    #  اگر فایل train_nb_model.py وجود نداشته باشه\n",
    "    # که پیش‌فرض هم همینه، اون‌وقت در زمان اجرا ارور می‌گیری (مثلاً: ModuleNotFoundError).\n",
    "elif model_name == \"svm\":\n",
    "    from models.train_svm_model import train_model\n",
    "elif model_name == \"lr\":\n",
    "    from models.train_lr_model import train_model\n",
    "else:\n",
    "    raise ValueError(\"Unsupported model\")"
   ],
   "id": "2cb1aea974c69768"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# تابع برای خواندن ایمیل‌ها\n",
    "# # تمام فایلهای متنی را میخواند و داخل لیستی میریزد\n",
    "def load_emails_from_folder(folder):\n",
    "    emails = []\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "        with open(path, 'r', encoding='latin-1') as f:\n",
    "            emails.append(f.read())\n",
    "    return emails\n",
    "# خواندن ایمیل‌های اسپم و معمولیاز پوشه‌هایشان در data/ می‌خواند.\n",
    "spam_emails = load_emails_from_folder('data/spam')\n",
    "ham_emails = load_emails_from_folder('data/easy_ham')"
   ],
   "id": "f3defaa98999aec3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ساخت دیتافریم و دادن لیبل به انها\n",
    "# # ستون text شامل متن ایمیل‌ها.\n",
    "# # ستون label: عدد ۱ برای اسپم، عدد ۰ برای ایمیل‌های معمولی.\n",
    "df = pd.DataFrame({'text': spam_emails + ham_emails,\n",
    "                   'label': [1]*len(spam_emails) + [0]*len(ham_emails)})\n",
    "# #فرض کن 3 ایمیل اسپم داریم\n",
    "# # اون‌وقت len(spam_emails) می‌شه 3. حالا: [1] * 3\n",
    "# # مساوی می‌شه با: [1, 1, 1]\n",
    "# # # یعنی برای ۳ ایمیل اسپم، ۳ عدد ۱ تولید کردیم. همین کار برای ایمیل‌های معمولی:\n",
    "# # [0] * len(ham_emails)\n",
    "# # در نتیجه:\n",
    "# # y = [1, 1, 1, 0, 0, 0]"
   ],
   "id": "d01d6430d93f8a58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# تبدیل محتوای ایمیل به عدد\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "# #می‌گوید که کلمات توقف (stop words) زبان انگلیسی را نادیده بگیرد.مانند \"the\"، \"a\"، \"is\"، \"are\" و غیره.\n",
    "# با حذف این کلمات، تمرکز مدل بر روی کلمات مهم‌تر خواهد بود.\n",
    "# #فقط ۱۰۰۰ کلمه‌ی مهم‌تر و پرتکرارتر را از بین تمام کلمات موجود در همه ایمیل‌ها نگه دار و بقیه را نادیده بگیر\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "#fit() یعنی: از روی تمام متن‌ها، کلمات پرتکرار و مهم (طبق TF-IDF) رو یاد بگیر\n",
    "# و برای هر کلمه، یک عدد شاخص مشخص کن.\n",
    "# transform() یعنی: حالا بیایم هر متن رو تبدیل به بردار عددی کنیم با توجه به آن چیزی که در fit() یاد گرفتیم.\n",
    "y = df['label']"
   ],
   "id": "a392bef357ca301a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#دسته بندی دیتا به تست و ترین\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "fb0ec84e7939e48a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# آموزش مدل\n",
    "model = train_model(X_train, y_train)"
   ],
   "id": "d4d2f0141ca168c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#  پیش‌بینی روی داده‌های تست و چاپ گزارش عملکرد مدل.\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "e97bfc116e293daf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # اطمینان از وجود فولدر models\n",
    "os.makedirs('models', exist_ok=True)\n"
   ],
   "id": "248f6fdcd0106bfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ذخیره مدل و بردار‌ساز\n",
    "joblib.dump(model, f'models/{model_name}_classifier.pkl')\n",
    "joblib.dump(vectorizer, 'models/vectorizer.pkl')\n",
    "\n"
   ],
   "id": "6cc40115499eec46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "مهم:\n",
    "1. برای اجرا به فایل main میرویم\n",
    "2. با توجه به اینکه خروجی چه مدلی را میخواهیم یکی از کدهای زیر را در ترمینال میزنیم\n",
    "python main.py nb    \n",
    "python main.py svm\n",
    "python main.py lr\n",
    "\n",
    "\"\"\""
   ],
   "id": "535d8087b9d712fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#مدل‌های مختلف شما در پوشه models/ ذخیره خواهند شد.\n",
    "# به عنوان مثال، اگر مدل SVM را انتخاب کنید، فایل مدل ذخیره‌شده به نام svm_classifier.pkl خواهد بود.\n"
   ],
   "id": "210a40acdcef33a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# آموزش مدلهای مختلف به ماشین\n"
   ],
   "id": "7e5cdd2ce215285c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train_nb_model.py\n",
    "#################################\n",
    "# Training code goes here\n",
    "#🔹 معمولاً آموزش مدل از اینجا جدا می‌شود،\n",
    "# مثلاً اگر بخواهید فقط مدل را دوباره آموزش دهید بدون اجرای بقیه چیزها.\n",
    "# 🔹 بهتره برای هر مدل یک فایل جدید آموزشی داشته باشی، مثل:\n",
    "#     train_nb.py (برای Naive Bayes)\n",
    "#     train_lr.py (برای Logistic Regression)\n",
    "#     train_svm.py (برای SVM)\n",
    "\n",
    "#################################\n",
    "# train_nb_model.py\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "مهم:\n",
    "1. برای اجرا به فایل main میرویم\n",
    "2. کد زیر را در ترمینال میزنیم و به صورت مستقیم علامت پلی را نیمزنیم\n",
    "python main.py nb\n",
    "\n",
    "\"\"\"\n"
   ],
   "id": "fe127d2009cce668"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train_svm_model.py\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "مهم:\n",
    "1. برای اجرا به فایل main میرویم\n",
    "2. کد زیر را در ترمینال میزنیم و به صورت مستقیم علامت پلی را نیمزنیم\n",
    "python main.py svm\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#مدل‌های مختلف شما در پوشه models/ ذخیره خواهند شد.\n",
    "# به عنوان مثال، اگر مدل SVM را انتخاب کنید، فایل مدل ذخیره‌شده به نام svm_classifier.pkl خواهد بود.\n"
   ],
   "id": "7b761b24a55eac93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train_lr_model.py\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "مهم:\n",
    "1. برای اجرا به فایل main میرویم\n",
    "2. کد زیر را در ترمینال میزنیم و به صورت مستقیم علامت پلی را نیمزنیم\n",
    "python main.py lr\n",
    "\n",
    "\"\"\""
   ],
   "id": "6f3808f417a06037"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "82de51e38904b72f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3ca4fbaaf68190a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# ارزیابی\n"
   ],
   "id": "fe2311d793614b9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate_nb_model.py\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_nb_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # چاپ در کنسول\n",
    "    print(\"Naive Bayes Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"Naive Bayes Confusion Matrix:\")\n",
    "    print(matrix)\n",
    "\n",
    "    # ذخیره در فایل\n",
    "    output_path = os.path.join(\"evaluation_outputs\", \"nb_report.txt\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"Naive Bayes Classification Report:\\n\")\n",
    "        f.write(report + \"\\n\\n\")\n",
    "        f.write(\"Naive Bayes Confusion Matrix:\\n\")\n",
    "        f.write(str(matrix))\n",
    "\n",
    "\"\"\"\n",
    "برای خروجی این فایل باید از فایل evaluate_models.py خروجی گرفته شود  \n",
    "\"\"\""
   ],
   "id": "3cc982174f4af0cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate_lr_model.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_lr_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Logistic Regression Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"Logistic Regression Confusion Matrix:\")\n",
    "    print(matrix)\n",
    "\n",
    "    output_path = os.path.join(\"evaluation_outputs\", \"lr_report.txt\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"Logistic Regression Classification Report:\\n\")\n",
    "        f.write(report + \"\\n\\n\")\n",
    "        f.write(\"Logistic Regression Confusion Matrix:\\n\")\n",
    "        f.write(str(matrix))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "برای خروجی این فایل باید از فایل evaluate_models.py خروجی گرفته شود  \n",
    "\"\"\""
   ],
   "id": "69ac6281353719b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # evaluate_svm_model.py\n",
    "# # ارزیابی مدل اس وی ام\n",
    "#\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "#\n",
    "# def evaluate_svm_model(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#\n",
    "#     # گزارش طبقه‌بندی\n",
    "#     print(\"SVM Classification Report:\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#\n",
    "#     # ماتریس سردرگمی\n",
    "#     print(\"SVM Confusion Matrix:\")\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "#########\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_svm_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # چاپ در کنسول\n",
    "    print(\"SVM Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"SVM Confusion Matrix:\")\n",
    "    print(matrix)\n",
    "\n",
    "    # ذخیره در فایل\n",
    "    output_path = os.path.join(\"evaluation_outputs\", \"svm_report.txt\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"SVM Classification Report:\\n\")\n",
    "        f.write(report + \"\\n\\n\")\n",
    "        f.write(\"SVM Confusion Matrix:\\n\")\n",
    "        f.write(str(matrix))\n",
    "\n",
    "\"\"\"\n",
    "برای خروجی این فایل باید از فایل evaluate_models.py خروجی گرفته شود  \n",
    "\"\"\""
   ],
   "id": "104b266bf63ec934"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# compare_models.py\n",
    "# فایل ارزیابی ای است تا سه مدل Naive Bayes و  SVM و Logistic Regression را با هم مقایسه کند\n",
    "\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#  رسم نمودار میله‌ای برای مقایسه مدل‌ها\n",
    "def plot_model_comparison(results, save_path):\n",
    "    labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "    model_names = [r[0] for r in results]\n",
    "    #این یک لیست‌ساز (list comprehension) است\n",
    "    #برای هر عنصر r، اولین آیتم آن (با اندیس 0) انتخاب می‌شود.\n",
    "    #در نهایت، یک لیست جدید به نام model_names ایجاد می‌شود که شامل نام تمام مدل‌های موجود در results است.\n",
    "\n",
    "    scores = [r[1:] for r in results]\n",
    "    # یک برش (slice) از آن ایجاد می‌شود که شامل تمام آیتم‌ها از اندیس 1 به بعد است.\n",
    "    #در نهایت یک لیست جدید به نام scores ایجاد می‌شود که در آن هر عنصر، لیستی از نمرات ارزیابی برای یک مدل خاص است.\n",
    "    scores = np.array(scores)\n",
    "    # برای تبدیل لیست scores به یک آرایه NumPy استفاده می‌شود.\n",
    "    # آرایه‌های NumPy برای انجام محاسبات عددی کارآمدتر هستند و برای رسم نمودار با matplotlib مناسب‌ترند.\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    #با استفاده از np.arange یک آرایه NumPy از اعداد صحیح ایجاد می‌شود.\n",
    "\n",
    "    width = 0.25 # این مقدار برای تعیین پهنای میله‌های نمودار\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for i in range(len(model_names)):\n",
    "        ax.bar(x + i * width, scores[i], width, label=model_names[i])\n",
    "        #x + i * width: موقعیت x برای میله‌های مربوط به مدل فعلی (i).\n",
    "        # با اضافه کردن i * width، میله‌های مربوط به هر مدل کمی به سمت راست جابجا می‌شوند تا از هم جدا باشند.\n",
    "\n",
    "    ax.set_ylabel('Score') #عنوان کلی برای محور y است که 'Score' را گذاشته.\n",
    "    ax.set_title('Model Comparison')\n",
    "    ax.set_xticks(x + width)\n",
    "    #مکان قرارگیری نشانه‌های محور x تنظیم می‌شود.\n",
    "    # از x + width استفاده می‌شود تا نشانه‌ها در وسط گروه‌های میله‌ها قرار بگیرند.\n",
    "\n",
    "    ax.set_xticklabels(labels) #برچسب‌های مربوط به نشانه‌های محور x با استفاده از لیست labels تنظیم می‌شو\n",
    "    ax.legend() #راهنمای نمودار\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #یک تابع که به طور خودکار فاصله‌بندی بین عناصر نمودار (مانند عنوان، برچسب‌ها و راهنما) را تنظیم می‌کند تا از همپوشانی جلوگیری شود.\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    #نمودار تولید شده در فایلی با مسیری که در پارامتر save_path مشخص شده است، ذخیره می‌شود.\n",
    "\n",
    "    plt.close()\n",
    "    #شکل (figure) مربوط به نمودار بسته می‌شود تا منابع سیستم آزاد شوند.\n",
    "\n",
    "    print(f\"✅ نمودار ذخیره شد: {save_path}\")\n",
    "\n",
    "\n",
    "#  مقایسه مدل‌ها + تولید خروجی متنی و تصویری\n",
    "def compare_models(X_test, y_test, models_dir):\n",
    "    model_files = {\n",
    "        \"SVM\": \"svm_classifier.pkl\",\n",
    "        \"Naive Bayes\": \"nb_classifier.pkl\",\n",
    "        \"Logistic Regression\": \"lr_classifier.pkl\"\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model_name, filename in model_files.items():\n",
    "        try:\n",
    "            model_path = os.path.join(models_dir, filename)\n",
    "            model = joblib.load(model_path)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            results.append((model_name, acc, prec, rec, f1))\n",
    "\n",
    "            print(f\"\\n📊 {model_name} Scores:\")\n",
    "            print(f\"Accuracy: {acc:.4f}\")\n",
    "            print(f\"Precision: {prec:.4f}\")\n",
    "            print(f\"Recall: {rec:.4f}\")\n",
    "            print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ خطا در بارگذاری یا ارزیابی {model_name}: {e}\")\n",
    "\n",
    "    #  مسیر خروجی‌ها: داخل src/evaluation_outputs\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    outputs_dir = os.path.join(base_dir, 'evaluation_outputs')\n",
    "    os.makedirs(outputs_dir, exist_ok=True)\n",
    "\n",
    "    #  گزارش متنی\n",
    "    report_path = os.path.join(outputs_dir, 'compare_models_report.txt')\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Model Comparison:\\n\")\n",
    "        f.write(f\"{'Model':<20}{'Accuracy':<10}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}\\n\")\n",
    "        for model_name, acc, prec, rec, f1 in results:\n",
    "            line = f\"{model_name:<20}{acc:<10.2f}{prec:<10.2f}{rec:<10.2f}{f1:<10.2f}\\n\"\n",
    "            f.write(line)\n",
    "            print(line, end='')\n",
    "\n",
    "    print(f\"\\n✅ گزارش متنی ذخیره شد: {os.path.abspath(report_path)}\")\n",
    "\n",
    "    # 🖼️ ذخیره نمودار\n",
    "    chart_path = os.path.join(outputs_dir, 'compare_models_chart.png')\n",
    "    plot_model_comparison(results, chart_path)\n",
    "\n",
    "#  تابع main فقط برای تست (اختیاری)\n",
    "def main():\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'processed_data.csv')\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    X = df.drop('label', axis=1)\n",
    "    y = df['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models_dir = os.path.join(os.path.dirname(__file__), '..', 'models')\n",
    "    compare_models(X_test, y_test, models_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\"\"\"\n",
    "برای خروجی این فایل باید از فایل evaluate_models.py خروجی گرفته شود  \n",
    "\"\"\""
   ],
   "id": "afdd20b364794648"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate_models.py\n",
    "##################\n",
    "from evaluate_svm_model import evaluate_svm_model\n",
    "from evaluate_nb_model import evaluate_nb_model\n",
    "from evaluate_lr_model import evaluate_lr_model\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from compare_models import compare_models\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# ___________________________________\n",
    "\n",
    "# مسیر نسبی به فولدر data\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "#os.path.abspath(__file__): این قسمت، مسیر مطلق (کامل) فایل جاری (evaluate_models.py) را در سیستم عامل برمی‌گرداند.\n",
    "\n",
    "spam_dir = os.path.join(base_dir, '..', 'data', 'spam')\n",
    "#os.path.join(...): این تابع برای ساختن یک مسیر فایل یا دایرکتوری به صورت هوشمندانه و سازگار با سیستم عامل‌های مختلف استفاده می‌شود. این تابع به طور خودکار از جداکننده مناسب مسیر (مثل / در لینوکس و \\ در ویندوز) استفاده می‌کند.\n",
    "# '..': این علامت در مسیر به معنای \"رفتن به دایرکتوری والد\" است.\n",
    "# 'data', 'spam', 'easy_ham': اینها نام دایرکتوری‌ها یا فایل‌ها هستند.\n",
    "\n",
    "ham_dir = os.path.join(base_dir, '..', 'data', 'easy_ham')\n",
    "\n",
    "# تابع برای خواندن ایمیل‌ها\n",
    "def load_emails_from_folder(folder):\n",
    "    emails = []\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "        with open(path, 'r', encoding='latin-1') as f:\n",
    "            emails.append(f.read())\n",
    "    return emails\n",
    "\n",
    "# خواندن ایمیل‌ها\n",
    "spam_emails = load_emails_from_folder(spam_dir)\n",
    "ham_emails = load_emails_from_folder(ham_dir)\n",
    "df = pd.DataFrame({'text': spam_emails + ham_emails,\n",
    "                   'label': [1]*len(spam_emails) + [0]*len(ham_emails)})\n",
    "\n",
    "\n",
    "models_dir = os.path.join(base_dir, '..', 'models')\n",
    "vectorizer_path = os.path.join(models_dir, 'vectorizer.pkl')\n",
    "\n",
    "# تقسیم داده‌ها به آموزش و تست بدون فیت\n",
    "vectorizer = joblib.load(vectorizer_path)\n",
    "X = vectorizer.transform(df['text'])   # فقط transform (بدون fit)\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ___________________________________\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Evaluating SVM Model:\")\n",
    "        svm_path = os.path.join(models_dir, 'svm_classifier.pkl')\n",
    "        model_svm = joblib.load(svm_path)\n",
    "        evaluate_svm_model(model_svm, X_test, y_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating SVM model: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(\"\\nEvaluating Naive Bayes Model:\")\n",
    "        nb_path = os.path.join(models_dir, 'nb_classifier.pkl')\n",
    "        model_nb = joblib.load(nb_path)\n",
    "        evaluate_nb_model(model_nb, X_test, y_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating Naive Bayes model: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(\"\\nEvaluating Logistic Regression Model:\")\n",
    "        lr_path = os.path.join(models_dir, 'lr_classifier.pkl')\n",
    "        model_lr = joblib.load(lr_path)\n",
    "        evaluate_lr_model(model_lr, X_test, y_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating Logistic Regression model: {e}\")\n",
    "\n",
    "    print(\"\\nComparing all models:\")\n",
    "    compare_models(X_test, y_test, models_dir)  # اینجا منتقل شود داخل main\n",
    "\n",
    "\n",
    "\n",
    "#_________________________________________\n",
    "\n",
    "# مسیر فولدر evaluation_outputs\n",
    "outputs_dir = \"evaluation_outputs\"\n",
    "\n",
    "# اگر فولدر evaluation_outputs وجود نداشت، آن را ایجاد کن\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "    print(f\"Folder '{outputs_dir}' created.\")\n",
    "else:\n",
    "    print(f\"Folder '{outputs_dir}' already exists.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "## ____________________________________________\n",
    "\"\"\"\n",
    "1. این فایل را میتوان با دکمه پلی خروجی گرفت\n",
    "2. این فایل خروجی فایلهای زیر را میگیرد و در پوشه src/evaluation_outputs ذخیره میکند\n",
    "evaluate_lr_model.py و evaluate_nb_model و evaluate_svm_model.py و compare_models.py  \n",
    "\"\"\""
   ],
   "id": "49dab80b47fdb792"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# predict پیش بینی"
   ],
   "id": "d49a7a32c3a0318a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# predict.py\n",
    "\n",
    "\n",
    "#🔹 برای استفاده از مدل روی ایمیل جدید:\n",
    "# 🔹 متن ایمیل جدید را عددی می‌کند و نتیجه (۰ یا ۱) را برمی‌گرداند.\n",
    "# predict.py: فقط یک ماژول کمکی است که تابع predict_email(text) را تعریف می‌کند.\n",
    "# و این تابع یک متن می‌گیرد و نتیجه‌ی پیش‌بینی را (۰ یا ۱) برمی‌گرداند. خودش به‌تنهایی چیزی چاپ نمی‌کند.\n",
    "#  اما فایل predict_email.py: یک اسکریپت قابل اجرا است که ایمیل‌های نمونه را به تابع predict_email() می‌دهد و نتیجه را چاپ می‌کند.\n",
    "\n",
    "# توضیح بیشتر\n",
    "#  پس:\n",
    "#     predict.py = تابع منطقی برای استفاده در جاهای دیگر.\n",
    "#     predict_email.py = اجرای عملی و نمونه با چاپ خروجی.\n",
    "\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "def predict_email(model_name, text):\n",
    "    # بارگذاری مدل و بردار‌ساز بر اساس نام مدل\n",
    "    model = load(f'models/{model_name}_classifier.pkl')\n",
    "    vectorizer = load('models/vectorizer.pkl')\n",
    "    # چون هر متن رو به یک بردار ویژگی (feature vector) تبدیل می‌کنه.\n",
    "    # و در ریاضیات و یادگیری ماشین، به چنین لیست‌هایی از اعداد «بردار» گفته می‌شه.\n",
    "\n",
    "    # تبدیل متن ایمیل به ویژگی‌های عددی\n",
    "    X = vectorizer.transform([text])\n",
    "\n",
    "    #پیش بینی\n",
    "    prediction = model.predict(X)[0]\n",
    "    # [0]\n",
    "    # این یعنی:\n",
    "    #     «از بین همه پیش‌بینی‌ها، فقط اولین (و تنها) مورد را بردار.»\n",
    "    # چرا؟ چون ما فقط یک ایمیل را داریم پیش‌بینی می‌کنیم.\n",
    "    # ولی چون vectorizer.transform([text]) خروجی‌اش یک آرایه با یک نمونه است،\n",
    "    # مدل هم خروجی‌اش یک آرایه با یک مقدار خواهد بود.\n",
    "\n",
    "    # در بیشتر مدلهای دو کلاسه model.predict(X) یک آرایه به نام array([1])  یا array([0])برمیگردونه\n",
    "    #اگر array([0]) باشد، اولین عنصر صفر است و اگر array([1]) باشد، اولین عنصر یک است.\n",
    "    # یعنی اگر ایمیل اسپم است، خروجی به شکل array([1]) خواهد بود و..\n",
    "\n",
    "\n",
    "    # بازگشت نتیجه پیش‌بینی\n",
    "    return \"This email **IS SPAM** ❌ \" if prediction == 1 else \"This email is **NOT SPAM** ✅\"\n"
   ],
   "id": "4fb2d337edd6c6b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# predict_email.py\n",
    "# # 🔹 بعد از ساخت و اموزش و کارهای اصلی\n",
    "# # این فایل جدید را ساختیم تا برایمان بگوید که ایمیل های دستی زیر اسپم هستند یا خیر\n",
    "# #         \"Congratulations! You won a free ticket to Bahamas!\",\n",
    "# #         \"Hi John, can we meet at the cafe tomorrow?\",\n",
    "# #         \"URGENT: Update your banking information immediately.\",\n",
    "# #         \"Here is the report you asked for. Let me know your thoughts.\"\n",
    "\n",
    "##______________________\n",
    "# # توضیح بیشتر:\n",
    "# # آیا نمی‌شد فایلهای   predict_email.py و  predict.py را یکی کرد؟\n",
    "# #\n",
    "# # 1. فایل predict.py قراره مثل مغزِ پیش‌بینی مدل باشه. می‌تونه توسط Flask، تست، یا هر اسکریپت دیگه import بشه.\n",
    "# # ولی predict_email.py فقط یه تست‌کننده ساده است. فقط برای انسان‌ها، نه ماشین یا سیستم.\n",
    "#\n",
    "# # 2اگر این دو فایل را یکی کنیم از نظر طراحی پروژه اشتباه است. اگه این کارو بکنی:\n",
    "# #     هر بار که یه فایل کدی import predict کنه، کل اون ایمیل‌های تست هم اجرا می‌شن! ❌\n",
    "# #     فایل سنگین، درهم، و غیرقابل نگهداری میش\n",
    "\n",
    "\n",
    "\n",
    "# predict_email.py\n",
    "\n",
    "from predict import predict_email\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    emails = [\n",
    "        \"Congratulations! You won a free ticket to Bahamas!\",\n",
    "        \"Meeting confirmed at 3pm with the HR team.\",\n",
    "        \"Claim your prize now! Click here.\"\n",
    "    ]\n",
    "\n",
    "    model_name = 'svm'  # می‌توانید مدل را به 'svm', 'nb', یا 'lr' تغییر دهید.\n",
    "\n",
    "    for i, email in enumerate(emails):\n",
    "        print(f\"Sample {i+1}:\\n{email}\")\n",
    "        print(predict_email(model_name, email))\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "#____________________________________________\n",
    "# # برای اجرای کد:\n",
    "# # در ترمینال وارد پوشه پروژه شو و بنویس:\n",
    "\"\"\"\n",
    " python src/predict_email.py\n",
    " \n",
    " \"\"\"\n",
    "# # چون وقتی با دکمه ▶️ پلی اجرا می‌کنی، PyCharm فایل رو اجرا می‌کنه\n",
    "# ولی دایرکتوری جاری (Current Working Directory) ممکنه پوشه‌ی src باشه.\n",
    "# # فایل‌های مدل شما (models/spam_classifier.pkl) در پوشه‌ی بالاتر هستند، بنابراین پیدا نمی‌شن.\n"
   ],
   "id": "a594cf2d9318784d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# predict_from_file.py\n",
    "\n",
    "from joblib import load\n",
    "from predict import predict_email\n",
    "\n",
    "\n",
    "def predict_emails_from_file(filepath, model_name):\n",
    "    # خواندن محتوای فایل\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # تقسیم ایمیل‌ها\n",
    "    emails = content.split('---')\n",
    "\n",
    "    # پیش‌بینی برای هر ایمیل\n",
    "    for i, email in enumerate(emails):\n",
    "        email = email.strip()\n",
    "        if not email:\n",
    "            continue\n",
    "\n",
    "        # استفاده از تابع predict_email برای پیش‌بینی ایمیل\n",
    "        result = predict_email(model_name, email)\n",
    "\n",
    "        # نمایش نتیجه\n",
    "        print(f\"\\nEmail {i + 1}:\")\n",
    "        print(email)\n",
    "        print(\"Result:\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = 'svm'  # مدل مورد نظر را انتخاب کنید: 'svm', 'nb', یا 'lr'\n",
    "    predict_emails_from_file(\"test_emails.txt\", model_name)\n",
    "\n",
    "## ____________________________________________\n",
    "# برای اجرای کد:\n",
    "# در ترمینال وارد پوشه پروژه شو و بنویس:\n",
    "\"\"\"\n",
    "python src/predict_from_file.py\n",
    "\"\"\"\n",
    "# چون وقتی با دکمه ▶️ پلی اجرا می‌کنی، PyCharm فایل رو اجرا می‌کنه ولی دایرکتوری جاری (Current Working Directory) ممکنه پوشه‌ی src باشه.\n",
    "# فایل‌های مدل شما (models/spam_classifier.pkl) در پوشه‌ی بالاتر هستند، بنابراین پیدا نمی‌شن.\n"
   ],
   "id": "ec870e2003fe7d89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
